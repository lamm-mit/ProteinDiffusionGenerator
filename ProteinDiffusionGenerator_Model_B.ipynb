{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1999104",
   "metadata": {},
   "source": [
    "# Model B: Protein Generator Diffusion model conditioned on residue-level secondary structure content\n",
    "\n",
    "### Generative method to design novel proteins using a diffusion model \n",
    "\n",
    "B. Ni, D.L. Kaplan, M.J. Buehler, Generative design of de novo proteins based on secondary structure constraints using an attention-based diffusion model, Chem, 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a281c29d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import math\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" #turn off CUDA if needed\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB.DSSP import DSSP\n",
    "from Bio.PDB import PDBList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847a915-167e-4c93-bc56-f4eb9ab8e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e62b3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b85dbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9183943f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16260708",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.cuda.device at 0x7fac7f03c880>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924ee37e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "num_of_gpus = torch.cuda.device_count()\n",
    "print(num_of_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093f91f8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 15 08:53:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.07    Driver Version: 527.27       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:65:00.0  On |                  Off |\n",
      "| 54%   78C    P2   259W / 300W |  22258MiB / 49140MiB |     95%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4574      C   /python3.9                      N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd05726",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Libraries, tools, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed04b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80f92cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR\n",
    "from functools import partial, wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1daa07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.12.0+cu113\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b0d9d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b0ff262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def params (model):\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "    pytorch_total_params_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print (\"Total model parameters: \", pytorch_total_params,\" trainable parameters: \", pytorch_total_params_trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6e4a2",
   "metadata": {},
   "source": [
    "### Data loader/dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3539591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionDataset(Dataset):\n",
    "\n",
    "        def __init__(self, X_data, y_data):\n",
    "            self.X_data = X_data\n",
    "            self.y_data = y_data\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return self.X_data[index], self.y_data[index]\n",
    "\n",
    "        def __len__ (self):\n",
    "            return len(self.X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b80e71f",
   "metadata": {},
   "source": [
    "#### Dataloader for protein data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a25152d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data_set_SS_seq2seq (file_path , \\\n",
    "                   min_length=0, max_length=100, batch_size_=4, output_dim=1, maxdata=9999999999999,\\\n",
    "             remove_longer=False, fill_with_repeats=False,\\\n",
    "                           repeat_same=True,   tokenizer_y=None, split=.2,\n",
    "                           tokenizer_X=None):\n",
    " \n",
    "    \n",
    "    min_length_measured=0\n",
    "    max_length_measured=999999\n",
    "    protein_df=pd.read_csv(file_path)\n",
    "    protein_df\n",
    "\n",
    "    protein_df.describe()\n",
    "\n",
    "    df_isnull = pd.DataFrame(round((protein_df.isnull().sum().sort_values(ascending=False)/protein_df.shape[0])*100,1)).reset_index()\n",
    "    df_isnull.columns = ['Columns', '% of Missing Data']\n",
    "    df_isnull.style.format({'% of Missing Data': lambda x:'{:.1%}'.format(abs(x))})\n",
    "    cm = sns.light_palette(\"skyblue\", as_cmap=True)\n",
    "    df_isnull = df_isnull.style.background_gradient(cmap=cm)\n",
    "    df_isnull\n",
    "     \n",
    "    protein_df.drop(protein_df[protein_df['Seq_Len'] >max_length-2].index, inplace = True)\n",
    "    protein_df.drop(protein_df[protein_df['Seq_Len'] <min_length].index, inplace = True)\n",
    " \n",
    "    protein_df=protein_df.reset_index(drop=True)\n",
    "    \n",
    "    seqs = protein_df.Sequence.values\n",
    "    \n",
    "    test_seqs = seqs[:1]\n",
    "     \n",
    "    lengths = [len(s) for s in seqs]\n",
    "    \n",
    "    print(protein_df.shape)\n",
    "    print(protein_df.head(6))\n",
    "     \n",
    "    min_length_measured =   min (lengths)\n",
    "    max_length_measured =   max (lengths)\n",
    "     \n",
    "    fig_handle =sns.distplot(lengths,  bins=25,kde=False, rug=False,norm_hist=True,axlabel='Length')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    #INPUT - X  \n",
    "    X_v = protein_df.Secstructure.values\n",
    "    if tokenizer_X==None:\n",
    "        tokenizer_X = Tokenizer(char_level=True, filters='!\"$%&()*+,-./:;<=>?[\\\\]^_`{|}\\t\\n' )\n",
    "        tokenizer_X.fit_on_texts(X_v)\n",
    "        \n",
    "    X = tokenizer_X.texts_to_sequences(X_v)\n",
    "    \n",
    "    X= sequence.pad_sequences(X,  maxlen=max_length, padding='post', truncating='post') \n",
    "    \n",
    "    fig_handle =sns.distplot(np.array(X).flatten(), bins=9,kde=False, rug=False,norm_hist=False,axlabel='Amino acid residue code')\n",
    "    fig = fig_handle.get_figure()\n",
    "    fig_handle.set_xlim(1, 9)\n",
    "    fig_handle.set_ylim(0, 400000)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print (\"#################################\")\n",
    "    print (\"DICTIONARY X\")\n",
    "    dictt=tokenizer_X.get_config()\n",
    "    print (dictt)\n",
    "    num_wordsX = len(tokenizer_X.word_index) + 1\n",
    "\n",
    "    print (\"################## X max token: \",num_wordsX )\n",
    "\n",
    "    X=np.array(X)\n",
    "    print (\"sample X data\", X[0])\n",
    "\n",
    "    seqs = protein_df.Sequence.values\n",
    "            \n",
    "    #create and fit tokenizer for AA sequences\n",
    "    if tokenizer_y==None:\n",
    "        tokenizer_y = Tokenizer(char_level=True, filters='!\"$%&()*+,-./:;<=>?[\\\\]^_`{|}\\t\\n' )\n",
    "        tokenizer_y.fit_on_texts(seqs)\n",
    "        \n",
    "    y_data = tokenizer_y.texts_to_sequences(seqs)\n",
    "    \n",
    "    y_data= sequence.pad_sequences(y_data,  maxlen=max_length, padding='post', truncating='post')  \n",
    "    \n",
    "    fig_handle =sns.distplot(np.array(y_data).flatten(), bins=21,kde=False, rug=False,norm_hist=False,axlabel='Secondary structure code')\n",
    "    fig = fig_handle.get_figure()\n",
    "    fig_handle.set_xlim(1, 21)\n",
    "    fig_handle.set_ylim(0, 100000)\n",
    "    plt.xticks(range (1,21))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print (\"#################################\")\n",
    "    print (\"DICTIONARY y_data\")\n",
    "    dictt=tokenizer_y.get_config()\n",
    "    print (dictt)\n",
    "    num_words = len(tokenizer_y.word_index) + 1\n",
    "\n",
    "    print (\"################## y max token: \",num_words )\n",
    "    print (\"y data shape: \", y_data.shape)\n",
    "    print (\"X data shape: \", X.shape)\n",
    "    #revere\n",
    "    print (\"TEST REVERSE: \")\n",
    "\n",
    "    y_data_reversed=tokenizer_y.sequences_to_texts (y_data)\n",
    "    \n",
    "    for iii in range (len(y_data_reversed)):\n",
    "        y_data_reversed[iii]=y_data_reversed[iii].upper().strip().replace(\" \", \"\")\n",
    "        \n",
    "    print (\"Element 0\", y_data_reversed[0])\n",
    "\n",
    "    print (\"Number of y samples\",len (y_data_reversed) )\n",
    "    print (\"Original: \", y_data[:3,:])\n",
    "\n",
    "    print (\"REVERSED TEXT 0..2: \", y_data_reversed[0:3])\n",
    "    \n",
    "    print (\"Len 0 as example: \", len (y_data_reversed[0]) )\n",
    "    print (\"Len 2 as example: \", len (y_data_reversed[2]) )\n",
    "\n",
    "    if maxdata<y_data.shape[0]:\n",
    "        print ('select subset...', maxdata )\n",
    "        X=X[:maxdata]\n",
    "        y_data=y_data[:maxdata]\n",
    "        print (\"new shapes: \", X.shape, y_data.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,  y_data , test_size=split,random_state=235)\n",
    "    \n",
    "    train_dataset = RegressionDataset(torch.from_numpy(X_train).float()/Xnormfac, torch.from_numpy(y_train).float()/ynormfac) #/ynormfac)\n",
    "    \n",
    "    fig_handle = sns.distplot(torch.from_numpy(y_train.flatten()),bins=25,kde=False, \n",
    "                              rug=False,norm_hist=False,axlabel='y labels')\n",
    "    fig = fig_handle.get_figure()\n",
    "    plt.show()\n",
    "    \n",
    "    fig_handle = sns.distplot(torch.from_numpy(X_train.flatten()),bins=25,kde=False, \n",
    "                              rug=False,norm_hist=False,axlabel='X labels')\n",
    "    fig = fig_handle.get_figure()\n",
    "    plt.show()\n",
    " \n",
    "    test_dataset = RegressionDataset(torch.from_numpy(X_test).float()/Xnormfac, torch.from_numpy(y_test).float()/ynormfac)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size_, shuffle=True)\n",
    "    train_loader_noshuffle = DataLoader(dataset=train_dataset, batch_size=batch_size_, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size_)\n",
    "    \n",
    "    return train_loader, train_loader_noshuffle, test_loader, tokenizer_y , tokenizer_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d795d979",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14133, 15)\n",
      "   Unnamed: 0 Name_1  Name_2  Seq_Len  \\\n",
      "0           5   3NJJ    1092      118   \n",
      "1           7   4NXR    2382      102   \n",
      "2          13   1FER     822      106   \n",
      "3          21   2EQW    2466       42   \n",
      "4          26   1K99     774       91   \n",
      "5          32   1IZB    1037      102   \n",
      "\n",
      "                                            Sequence  \\\n",
      "0  GLAQFIKVNVTLENGEPVFIYTDANGQVCQGDITVTQAGTITYLLN...   \n",
      "1  GAMGKVTHSIHIEKSDTAADTYGFSLSSVEEDGIRRLYVNSVKETG...   \n",
      "2  AFVVTDNCIKCKYTDCVEVCPVDCFYEGPNFLVIHPDECIDCALCE...   \n",
      "3         GSSGSSGEKPYVCTECGKAFIRKSHFITHERIHTGESGPSSG   \n",
      "4  MKKLKKHPDFPKKPLTPYFRFFMEKRAKYAKLHPEMSNLDLTKILS...   \n",
      "5  GIVEQCCTSICSLYQLENYCNFVNQHLCGSHLVQALYLVCGERGFF...   \n",
      "\n",
      "                                        Secstructure        AH        BS  \\\n",
      "0  ~~EEEEEEEEEEETTEEEEEEE~TTS~EE~~~EEESSSEEEEEEEE...  0.008475  0.542373   \n",
      "1  ~~~S~EEEEEEEEGGGSSSS~~S~EEEEEEETTEEEEEEE~~~TTS...  0.127451  0.421569   \n",
      "2  ~EEE~GGGTTT~~~HHHHH~SS~~EEE~SS~EEE~TTT~~~~~~SG...  0.179245  0.113208   \n",
      "3         ~~S~~~~~~SEE~SSS~~EESSSSHHHHHHHHH~S~~~SS~~  0.214286  0.095238   \n",
      "4  ~~~~~SSSSS~~~S~~HHHHHHHHHHHHHHTT~ETS~SHHHHHHHH...  0.505495  0.010989   \n",
      "5  ~HHHHHHHS~B~HHHHGGGB~~~~B~~~THHHHHHHHHHHGGG~EE...  0.411765  0.058824   \n",
      "\n",
      "          T  UNSTRUCTURED  BETABRIDGE  310HELIX  PIHELIX      BEND  \\\n",
      "0  0.067797      0.220339    0.000000  0.000000      0.0  0.161017   \n",
      "1  0.098039      0.205882    0.000000  0.058824      0.0  0.088235   \n",
      "2  0.141509      0.330189    0.009434  0.150943      0.0  0.075472   \n",
      "3  0.000000      0.404762    0.000000  0.000000      0.0  0.285714   \n",
      "4  0.054945      0.252747    0.000000  0.054945      0.0  0.120879   \n",
      "5  0.058824      0.274510    0.058824  0.117647      0.0  0.019608   \n",
      "\n",
      "                                                 Seq  \n",
      "0  GLAQFIKVNVTLENGEPVFIYTDANGQVCQGDITVTQAGTITYLLN...  \n",
      "1  GAMGKVTHSIHIEKSDTAADTYGFSLSSVEEDGIRRLYVNSVKETG...  \n",
      "2  AFVVTDNCIKCKYTDCVEVCPVDCFYEGPNFLVIHPDECIDCALCE...  \n",
      "3         GSSGSSGEKPYVCTECGKAFIRKSHFITHERIHTGESGPSSG  \n",
      "4  MKKLKKHPDFPKKPLTPYFRFFMEKRAKYAKLHPEMSNLDLTKILS...  \n",
      "5  GIVEQCCTSICSLYQLENYCNFVNQHLCGSHLVQALYLVCGERGFF...  \n",
      "11 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12203/4292614851.py:41: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  fig_handle =sns.distplot(lengths,  bins=25,kde=False, rug=False,norm_hist=True,axlabel='Length')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12203/4292614851.py:55: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  fig_handle =sns.distplot(np.array(X).flatten(), bins=9,kde=False, rug=False,norm_hist=False,axlabel='Amino acid residue code')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "DICTIONARY X\n",
      "{'num_words': None, 'filters': '!\"$%&()*+,-./:;<=>?[\\\\]^_`{|}\\t\\n', 'lower': True, 'split': ' ', 'char_level': True, 'oov_token': None, 'document_count': 14133, 'word_counts': '{\"~\": 295001, \"e\": 219767, \"t\": 128749, \"s\": 124041, \"h\": 348317, \"g\": 30952, \"b\": 14797, \"i\": 527}', 'word_docs': '{\"t\": 13290, \"~\": 14133, \"e\": 13307, \"h\": 14015, \"s\": 13231, \"g\": 6353, \"b\": 5745, \"i\": 106}', 'index_docs': '{\"4\": 13290, \"2\": 14133, \"3\": 13307, \"1\": 14015, \"5\": 13231, \"6\": 6353, \"7\": 5745, \"8\": 106}', 'index_word': '{\"1\": \"h\", \"2\": \"~\", \"3\": \"e\", \"4\": \"t\", \"5\": \"s\", \"6\": \"g\", \"7\": \"b\", \"8\": \"i\"}', 'word_index': '{\"h\": 1, \"~\": 2, \"e\": 3, \"t\": 4, \"s\": 5, \"g\": 6, \"b\": 7, \"i\": 8}'}\n",
      "################## X max token:  9\n",
      "sample X data [2 2 3 3 3 3 3 3 3 3 3 3 3 4 4 3 3 3 3 3 3 3 2 4 4 5 2 3 3 2 2 2 3 3 3 5 5\n",
      " 5 3 3 3 3 3 3 3 3 3 2 5 5 5 2 2 3 3 3 3 3 3 3 5 5 4 4 5 5 5 2 2 3 3 3 3 2\n",
      " 4 4 5 5 3 3 3 3 3 3 2 2 2 5 2 3 3 3 3 3 3 3 3 3 3 2 5 5 2 5 5 2 3 1 2 2 2\n",
      " 2 3 3 3 3 2 2 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12203/4292614851.py:84: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  fig_handle =sns.distplot(np.array(y_data).flatten(), bins=21,kde=False, rug=False,norm_hist=False,axlabel='Secondary structure code')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAahElEQVR4nO3de7SkVX3m8e+TblFEpMELwW4Uoh2VuIxCBzrRGBQHG+ISTYzxkoiGCWuiJupkJsE4K5rozGhMYmISySJCAIMiwRsxMdjiLTORlm7uDRI6KtAdLmpz8bJGhPzmj3cfrRzPPt1Vdfr0ofl+1qpVb+1693531XlPPfVear+pKiRJmssP7e4OSJKWLkNCktRlSEiSugwJSVKXISFJ6jIkJEldOwyJJGckuS3J1SNlByRZn+T6dr9/K0+SdyXZkuTKJIeP1DmxzX99khNHyo9IclWr864kmW8ZkqTFszNbEmcC62aVnQJcVFWrgYvaY4DjgNXtdjJwKgwf+MCbgKOAI4E3jXzonwr86ki9dTtYhiRpkewwJKrqc8D2WcUnAGe16bOA54+Un12Di4EVSQ4CngOsr6rtVXU7sB5Y1557aFVdXMOv+s6e1dZcy5AkLZLlE9Y7sKpubtO3AAe26ZXATSPzbW1l85VvnaN8vmX8gCQnM2y5sM8++xzxhCc8YdzXI0n3a5s2bfpaVT1idvmkIfE9VVVJdunYHjtaRlWdBpwGsGbNmtq4ceOu7I4k7XGS3DBX+aRnN93adhXR7m9r5duAg0fmW9XK5itfNUf5fMuQJC2SSUPiAmDmDKUTgY+OlL+8neW0Friz7TK6EDg2yf7tgPWxwIXtubuSrG1nNb18VltzLUOStEh2uLspyfuBo4GHJ9nKcJbS24DzkpwE3AC8qM3+D8DxwBbg28ArAapqe5K3AJe0+X6/qmYOhr+K4QyqvYGPtxvzLEOStEiypw0V7jEJSRpfkk1VtWZ2ub+4liR1GRKSpC5DQpLUZUhIkrqm/jHdUrP9W3fzvg03TlT3pUc9eoF7I0n3bW5JSJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXct3dweWkvdtuHGq+i896tEL1BNJWhoMiQVkyEja07i7SZLUZUhIkrrc3bSEuLtK0lLjloQkqcuQkCR1GRKSpC5DQpLUZUhIkrqmCokkr0+yOcnVSd6f5EFJDk2yIcmWJB9Isleb94Ht8Zb2/CEj7byhlV+X5Dkj5eta2ZYkp0zTV0nS+CYOiSQrgd8A1lTVk4BlwIuBtwPvrKrHAbcDJ7UqJwG3t/J3tvlIclir92PAOuDdSZYlWQb8BXAccBjwkjavJGmRTPs7ieXA3km+CzwYuBl4FvDS9vxZwJuBU4ET2jTA+cCfJ0krP7eqvgN8OckW4Mg235aq+hJAknPbvNdM2ec9lr+zkLTQJt6SqKptwB8CNzKEw53AJuCOqrqnzbYVWNmmVwI3tbr3tPkfNlo+q06v/AckOTnJxiQbv3HH9klfkiRplml2N+3P8M3+UOBRwD4Mu4sWXVWdVlVrqmrNvisO2B1dkKQ90jQHrp8NfLmqvlpV3wU+BDwNWJFkZjfWKmBbm94GHAzQnt8P+Ppo+aw6vXJJ0iKZJiRuBNYmeXA7tnAMw/GCTwMvbPOcCHy0TV/QHtOe/1RVVSt/cTv76VBgNfAF4BJgdTtbai+Gg9sXTNFfSdKYJj5wXVUbkpwPXArcA1wGnAb8PXBukre2stNbldOB97YD09sZPvSpqs1JzmMImHuAV1fVvQBJXgNcyHDm1BlVtXnS/kqSxpfhy/ye40ee+OR665kf293duE/y7Cbp/ivJpqpaM7vcocL1PZ5CK2k2h+WQJHUZEpKkLkNCktTlMQktGI9pSHsetyQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLy5dqyfDyp9LS45aEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy19ca4/hL7alhTfVlkSSFUnOT/LFJNcm+ckkByRZn+T6dr9/mzdJ3pVkS5Irkxw+0s6Jbf7rk5w4Un5EkqtanXclyTT9lSSNZ9rdTX8K/GNVPQH4ceBa4BTgoqpaDVzUHgMcB6xut5OBUwGSHAC8CTgKOBJ400ywtHl+daTeuin7K0kaw8QhkWQ/4BnA6QBVdXdV3QGcAJzVZjsLeH6bPgE4uwYXAyuSHAQ8B1hfVdur6nZgPbCuPffQqrq4qgo4e6QtSdIimGZL4lDgq8BfJ7ksyXuS7AMcWFU3t3luAQ5s0yuBm0bqb21l85VvnaP8ByQ5OcnGJBu/ccf2KV6SJGnUNCGxHDgcOLWqngp8i+/vWgKgbQHUFMvYKVV1WlWtqao1+644YFcvTpLuN6YJia3A1qra0B6fzxAat7ZdRbT729rz24CDR+qvamXzla+ao1yStEgmPgW2qm5JclOSx1fVdcAxwDXtdiLwtnb/0VblAuA1Sc5lOEh9Z1XdnORC4H+NHKw+FnhDVW1PcleStcAG4OXAn03aX2lHpjmF1tNntaea9ncSvw6ck2Qv4EvAKxm2Ts5LchJwA/CiNu8/AMcDW4Bvt3lpYfAW4JI23+9X1cyBhVcBZwJ7Ax9vN0nSIpkqJKrqcmDNHE8dM8e8Bby6084ZwBlzlG8EnjRNHyVJk3NYDklSl8NySAvAIUG0p3JLQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpdjN0lLgGM/aalyS0KS1GVISJK6DAlJUpfHJKQ9gMc0tKu4JSFJ6jIkJEldhoQkqcuQkCR1GRKSpC7PbpLk2VHqcktCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroclkPS1BzWY8819ZZEkmVJLkvysfb40CQbkmxJ8oEke7XyB7bHW9rzh4y08YZWfl2S54yUr2tlW5KcMm1fJUnjWYjdTa8Frh15/HbgnVX1OOB24KRWfhJweyt/Z5uPJIcBLwZ+DFgHvLsFzzLgL4DjgMOAl7R5JUmLZKqQSLIK+FngPe1xgGcB57dZzgKe36ZPaI9pzx/T5j8BOLeqvlNVXwa2AEe225aq+lJV3Q2c2+aVJC2SaY9J/AnwW8C+7fHDgDuq6p72eCuwsk2vBG4CqKp7ktzZ5l8JXDzS5midm2aVHzVXJ5KcDJwM8PAfXjnXLJKWMI9pLF0Tb0kkeS5wW1VtWsD+TKSqTquqNVW1Zt8VB+zu7kjSHmOaLYmnAc9LcjzwIOChwJ8CK5Isb1sTq4Btbf5twMHA1iTLgf2Ar4+Uzxit0yuXJC2CibckquoNVbWqqg5hOPD8qap6GfBp4IVtthOBj7bpC9pj2vOfqqpq5S9uZz8dCqwGvgBcAqxuZ0vt1ZZxwaT9lSSNb1f8TuK3gXOTvBW4DDi9lZ8OvDfJFmA7w4c+VbU5yXnANcA9wKur6l6AJK8BLgSWAWdU1eZd0F9J93Ee09h1MnyZ33P8yBOfXG8982O7uxuS7kMMCUiyqarWzC53WA5JUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKlr+e7ugCTtbu/bcONU9V961KMXqCdLj1sSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHX5YzpJmtKe/GM8tyQkSV2GhCSpy5CQJHUZEpKkrolDIsnBST6d5Jokm5O8tpUfkGR9kuvb/f6tPEnelWRLkiuTHD7S1olt/uuTnDhSfkSSq1qddyXJNC9WkjSeabYk7gF+s6oOA9YCr05yGHAKcFFVrQYuao8BjgNWt9vJwKkwhArwJuAo4EjgTTPB0ub51ZF666boryRpTBOHRFXdXFWXtulvANcCK4ETgLPabGcBz2/TJwBn1+BiYEWSg4DnAOurantV3Q6sB9a15x5aVRdXVQFnj7QlSVoEC3JMIskhwFOBDcCBVXVze+oW4MA2vRK4aaTa1lY2X/nWOcrnWv7JSTYm2fiNO7ZP92IkSd8zdUgkeQjwQeB1VXXX6HNtC6CmXcaOVNVpVbWmqtbsu+KAXb04SbrfmCokkjyAISDOqaoPteJb264i2v1trXwbcPBI9VWtbL7yVXOUS5IWyTRnNwU4Hbi2qv545KkLgJkzlE4EPjpS/vJ2ltNa4M62W+pC4Ngk+7cD1scCF7bn7kqyti3r5SNtSZIWwTRjNz0N+GXgqiSXt7LfAd4GnJfkJOAG4EXtuX8Ajge2AN8GXglQVduTvAW4pM33+1U1c2DhVcCZwN7Ax9tNkrRIJg6Jqvo/QO93C8fMMX8Br+60dQZwxhzlG4EnTdpHSdJ0/MW1JKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpfXuJak3WwpXyPbLQlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpa8mHRJJ1Sa5LsiXJKbu7P5J0f7KkQyLJMuAvgOOAw4CXJDls9/ZKku4/lnRIAEcCW6rqS1V1N3AucMJu7pMk3W8s390d2IGVwE0jj7cCR82eKcnJwMnt4XdetvYxV0+53IcDX9uN9fekNpZCHxaijaXQh6XSxlLow1JpYyn0gZctTD8eM1fhUg+JnVJVpwGnASTZWFVrpmlv2jaWQh+WShtLoQ8L0cZS6MNSaWMp9GGptLEU+rBQbfQs9d1N24CDRx6vamWSpEWw1EPiEmB1kkOT7AW8GLhgN/dJku43lvTupqq6J8lrgAuBZcAZVbV5B9VOW4BFT9vGUujDUmljKfRhIdpYCn1YKm0shT4slTaWQh8Wqo05pap2VduSpPu4pb67SZK0GxkSkqSuPSYkkpyR5LYkE/1GIsnBST6d5Jokm5O8doI2HpTkC0muaG383oR9WZbksiQfm7D+V5JcleTyJBsnbGNFkvOTfDHJtUl+csz6j2/Ln7ndleR1E/Tj9e29vDrJ+5M8aMz6r211N+/s8udal5IckGR9kuvb/f4TtPELrR//nmSHpyt22nhH+5tcmeTDSVZM0MZbWv3Lk3wiyaPGqT/y3G8mqSQPn6APb06ybWT9OH7cNlr5r7f3Y3OSPxizDx8YWf5Xklw+wet4SpKLZ/7Xkhw5QRs/nuTz7X/275I8dJ76c35Ojbt+jqWq9ogb8AzgcODqCesfBBzepvcF/gU4bMw2AjykTT8A2ACsnaAv/xV4H/CxCV/LV4CHT/l+ngX85za9F7BiiraWAbcAjxmz3krgy8De7fF5wCvGqP8k4GrgwQwnaXwSeNwk6xLwB8ApbfoU4O0TtPFE4PHAZ4A1E/bjWGB5m377hP146Mj0bwB/OU79Vn4wwwklN+xoXev04c3AfxvjbzlXG89sf9MHtsePHPd1jDz/R8DvTtCHTwDHtenjgc9M0MYlwM+06V8B3jJP/Tk/p8ZdP8e57TFbElX1OWD7FPVvrqpL2/Q3gGsZPqTGaaOq6pvt4QPabawzA5KsAn4WeM849RZSkv0YVubTAarq7qq6Y4omjwH+tapumKDucmDvJMsZPuz/bYy6TwQ2VNW3q+oe4LPAz+2oUmddOoEhOGn3zx+3jaq6tqqu27mud9v4RHstABcz/HZo3DbuGnm4D/Oso/P8X70T+K356u5EGzut08avAW+rqu+0eW6bpA9JArwIeP8EfShg5pv/fuxg/ey08aPA59r0euDn56nf+5waa/0cxx4TEgspySHAUxm2BMatu6xttt4GrK+qcdv4E4Z/vn8fd9kjCvhEkk0ZhiwZ16HAV4G/bru93pNknyn682J28A84l6raBvwhcCNwM3BnVX1ijCauBn46ycOSPJjhm97BO6jTc2BV3dymbwEOnLCdhfQrwMcnqZjkfya5CXgZ8Ltj1j0B2FZVV0yy7BGvabu9zphw98iPMvx9NyT5bJKfmLAfPw3cWlXXT1D3dcA72nv5h8AbJmhjM98fk+4X2Ml1dNbn1C5bPw2JWZI8BPgg8LpZ37h2SlXdW1VPYfiGd2SSJ42x7OcCt1XVpnGXO8vTq+pwhtFzX53kGWPWX86wSXxqVT0V+BbDJuzYMvwI8nnA305Qd3+Gf55DgUcB+yT5pZ2tX1XXMuyS+QTwj8DlwL3j9mOOdosxtxAXWpI3AvcA50xSv6reWFUHt/qvGWO5DwZ+hzGDZQ6nAo8FnsLwBeCPJmhjOXAAsBb478B5batgXC9hgi8xza8Br2/v5etpW99j+hXgVUk2MexCuntHFeb7nFro9dOQGJHkAQxv/DlV9aFp2mq7Zz4NrBuj2tOA5yX5CsOIt89K8jcTLHtbu78N+DDDaLrj2ApsHdkKOp8hNCZxHHBpVd06Qd1nA1+uqq9W1XeBDwE/NU4DVXV6VR1RVc8AbmfYhzuJW5McBNDuu7s2drUkrwCeC7ysfSBM4xzm2b0xh8cyhPYVbT1dBVya5IfHWWhV3dq+UP078FeMv47CsJ5+qO3m/QLD1ve8B9Fna7sxfw74wATLBziRYb2E4YvQ2K+jqr5YVcdW1REMYfWv883f+ZzaZeunIdG0byCnA9dW1R9P2MYjZs42SbI38J+AL+5s/ap6Q1WtqqpDGHbRfKqqdvqbc1vuPkn2nZlmONA51hlfVXULcFOSx7eiY4BrxmljxDTf0m4E1iZ5cPv7HMOwD3anJXlku380w4fB+ybsywUMHwi0+49O2M5Ukqxj2B35vKr69oRtrB55eALjraNXVdUjq+qQtp5uZTiQesuYfTho5OELGHMdbT7CcPCaJD/KcILFuCOhPhv4YlVtnWD5MByD+Jk2/Sxg7F1WI+voDwH/A/jLeebtfU7tuvVzoY6A7+4bwwfRzcB3GVbck8as/3SGTbQrGXZLXA4cP2YbTwYua21czQ7OlthBW0czwdlNwI8AV7TbZuCNEy7/KcDG9lo+Auw/QRv7AF8H9pviffg9hg+xq4H30s5kGaP+PzEE3BXAMZOuS8DDgIsYPgQ+CRwwQRsvaNPfAW4FLpygjS0Mw+fPrKPdM5PmaeOD7f28Evg7YOU49Wc9/xV2fHbTXH14L3BV68MFwEETtLEX8DfttVwKPGvc1wGcCfyXKdaLpwOb2vq1AThigjZey7CF+y/A22gjYXTqz/k5Ne76Oc7NYTkkSV3ubpIkdRkSkqQuQ0KS1GVISJK6DAlJUpchoUWV5I1t9MqZUUiP2g19ODoTjrA74fJ+ZwHbWpHkVQvV3kJKcmaSF+7ufmhhGRJaNBmGG38uw4+vnszwQ6abdm+vdqz9Kncac4ZEBuP+D64Axg6JJMvGrSOBIaHFdRDwtfr+qJ1fq6p/A0hyRBukbVOSC0eGGHhckk9muEbHpUke2z5c35HhOhFXJfnFNu/RST6T718H45yZsXySrGtllzIyEmySIzOM5X9Zkn+e+ZV5klckuSDJp4CLkpyd5Pkj9c5pA90xUnZQks+1LaSrk/x0krcxjGJ7eatzSJLrkpzN8COwg5N8c6SNFyY5s00fmOGaEVe0208x/Njqsa29d8zeKkry523Yjpnriry9veZfSHJse62XJvnbDOP//Adjvt9py7suySeBR460M+ffU/dBC/WrPG/ednQDHsLwC9F/Ad7N98fQfwDwz8Aj2uNfBM5o0xuAF7TpBzEMF/7zDEMqL2MY7fJGhgA6GriTYTyhHwI+z/AL1QcxbLGsZrjmx3m0X7MzDPM8c32GZwMfbNOvYPhF7AHt8c8AH2nT+zFc52L5rNf3m7RfuLe+7dumvzkyzyEMYwytHSkbff6FwJlt+gMMA7jNtLdfqz96LYKjGfllPvDntGtuMPwa+rfa9MMZhqPepz3+beYYEWDM9/vnRsofBdzR+t/9e3q7792m3YyWdlpVfTPJEQxDMz8T+ECSUxiG/3gSsL598V8G3JxhDKqVVfXhVv//ASR5OvD+qrqXYWCzzwI/AdwFfKHaODwZhmw/BPgmw0CB17fyvwFmhlDfDzgrw3hGxfABN2N9VW1vy/5skncneQTDh+YH6/vXdZhxCXBGhgHYPlJVl3feihuq6uKdeMueBby8Lf9e4M6MP6T2zMB1axkuTvN/23u8F0OIfs8E7/czRsr/rW11wXBhpR/4e47Zby0RhoQWVftA+QzwmSRXMQxGtgnYXFX/4RKp7UNrXN8Zmb6XHa/jbwE+XVUvyDA+/2dGnvvWrHnPBn6JYfDFV85uqKo+l2FY9p8Fzkzyx1V19hzLnN3u6Ng4Y12elWG48NHdxrPrzywrDKH3kjHbn0SY4++p+yaPSWjRZLju9egIpE9huPzldcAj0q6jneQBSX6shitvbZ05FpDkgRmuZ/BPwC9muMDTIxi+0X5hnkV/ETgkyWPb49EPyv2AbW36FTt4CWcyXGSGqvqBUXGTPIbh4jV/xXBlwZnh1b/bti56bk3yxAwHsV8wUn4Rw/UKZi5mtR/wDYZrDsy4ATisvTcrGEbKncvFwNOSPK61t0+GkVO/Z4L3+3Mj5QfRRmSl8/ec5/VrCTMktJgewrBr55okVzLs/nhzVd3NsC/77UmuYDhuMXPdiF8GfqPN/8/ADzNcI+NKhpE3P8Ww3707VHXbbXIy8PftIO7oWPt/APzvJJexg62OGq6JcS3w151Zjma4zsJlDPvh/7SVnwZcmaR3gaBTgI+11ze6W+a1wDPbFtcmhmuuf51hl9HVSd5RVTcxHGO5ut1f1un7VxlC8P3tvfw88IQ5Zh3n/f4ww6ij1zBsZX2+LWu+v6fuYxwFVtpJ7Vv1VQyn8N65u/sjLQa3JKSdkOTZDFsRf2ZA6P7ELQlJUpdbEpKkLkNCktRlSEiSugwJSVKXISFJ6vr/JRk1KUsvo2AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################\n",
      "DICTIONARY y_data\n",
      "{'num_words': None, 'filters': '!\"$%&()*+,-./:;<=>?[\\\\]^_`{|}\\t\\n', 'lower': True, 'split': ' ', 'char_level': True, 'oov_token': None, 'document_count': 14133, 'word_counts': '{\"g\": 86058, \"l\": 95355, \"a\": 80173, \"q\": 46588, \"f\": 41813, \"i\": 58817, \"k\": 85676, \"v\": 75303, \"n\": 49610, \"t\": 61951, \"e\": 84220, \"p\": 51444, \"y\": 40136, \"d\": 66422, \"c\": 37878, \"s\": 77110, \"m\": 23974, \"r\": 56955, \"h\": 27835, \"w\": 14833}', 'word_docs': '{\"y\": 12114, \"q\": 12292, \"f\": 12172, \"n\": 12571, \"c\": 9080, \"l\": 13547, \"g\": 13560, \"p\": 12423, \"v\": 12931, \"i\": 12818, \"m\": 9646, \"r\": 12779, \"e\": 13083, \"a\": 13311, \"t\": 12784, \"d\": 12661, \"s\": 13193, \"k\": 13209, \"h\": 10545, \"w\": 8193}', 'index_docs': '{\"16\": 12114, \"14\": 12292, \"15\": 12172, \"13\": 12571, \"17\": 9080, \"1\": 13547, \"2\": 13560, \"12\": 12423, \"7\": 12931, \"10\": 12818, \"19\": 9646, \"11\": 12779, \"4\": 13083, \"5\": 13311, \"9\": 12784, \"8\": 12661, \"6\": 13193, \"3\": 13209, \"18\": 10545, \"20\": 8193}', 'index_word': '{\"1\": \"l\", \"2\": \"g\", \"3\": \"k\", \"4\": \"e\", \"5\": \"a\", \"6\": \"s\", \"7\": \"v\", \"8\": \"d\", \"9\": \"t\", \"10\": \"i\", \"11\": \"r\", \"12\": \"p\", \"13\": \"n\", \"14\": \"q\", \"15\": \"f\", \"16\": \"y\", \"17\": \"c\", \"18\": \"h\", \"19\": \"m\", \"20\": \"w\"}', 'word_index': '{\"l\": 1, \"g\": 2, \"k\": 3, \"e\": 4, \"a\": 5, \"s\": 6, \"v\": 7, \"d\": 8, \"t\": 9, \"i\": 10, \"r\": 11, \"p\": 12, \"n\": 13, \"q\": 14, \"f\": 15, \"y\": 16, \"c\": 17, \"h\": 18, \"m\": 19, \"w\": 20}'}\n",
      "################## y max token:  21\n",
      "y data shape:  (14133, 128)\n",
      "X data shape:  (14133, 128)\n",
      "TEST REVERSE: \n",
      "Element 0 GLAQFIKVNVTLENGEPVFIYTDANGQVCQGDITVTQAGTITYLLNDQTLKGLKFVGVGFVTPFDGIIDAVTISSDGMLVQLVDLDKTPGTTKFQFVLSNTANTLLVLSADPQIINRP\n",
      "Number of y samples 14133\n",
      "Original:  [[ 2  1  5 14 15 10  3  7 13  7  9  1  4 13  2  4 12  7 15 10 16  9  8  5\n",
      "  13  2 14  7 17 14  2  8 10  9  7  9 14  5  2  9 10  9 16  1  1 13  8 14\n",
      "   9  1  3  2  1  3 15  7  2  7  2 15  7  9 12 15  8  2 10 10  8  5  7  9\n",
      "  10  6  6  8  2 19  1  7 14  1  7  8  1  8  3  9 12  2  9  9  3 15 14 15\n",
      "   7  1  6 13  9  5 13  9  1  1  7  1  6  5  8 12 14 10 10 13 11 12  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [ 2  5 19  2  3  7  9 18  6 10 18 10  4  3  6  8  9  5  5  8  9 16  2 15\n",
      "   6  1  6  6  7  4  4  8  2 10 11 11  1 16  7 13  6  7  3  4  9  2  1  5\n",
      "   6  3  3  2  1  3  5  2  8  4 10  1  4 10 13 13 11  5  5  8  5  1 13  6\n",
      "   6 19 19  4  8 15 15  6 14 12  6  7  2  1  1  7 11  9 16 12  4  1 13  3\n",
      "   8  3  4 16 16  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]\n",
      " [ 5 15  7  7  9  8 13 17 10  3 17  3 16  9  8 17  7  4  7 17 12  7  8 17\n",
      "  15 16  4  2 12 13 15  1  7 10 18 12  8  4 17 10  8 17  5  1 17  4 12  4\n",
      "  17 12  5 14  5 10 15  6  4  8  4  7 12  4  8 19 14  4 15 10 14  1 13  5\n",
      "   4  1  5  4  7 20 12 13 10  9  4  3  3  8 12  1 12  8  5  4  8 20  8  2\n",
      "   7  3  2  3  1 14 18  1  4 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0]]\n",
      "REVERSED TEXT 0..2:  ['GLAQFIKVNVTLENGEPVFIYTDANGQVCQGDITVTQAGTITYLLNDQTLKGLKFVGVGFVTPFDGIIDAVTISSDGMLVQLVDLDKTPGTTKFQFVLSNTANTLLVLSADPQIINRP', 'GAMGKVTHSIHIEKSDTAADTYGFSLSSVEEDGIRRLYVNSVKETGLASKKGLKAGDEILEINNRAADALNSSMMEDFFSQPSVGLLVRTYPELNKDKEYYV', 'AFVVTDNCIKCKYTDCVEVCPVDCFYEGPNFLVIHPDECIDCALCEPECPAQAIFSEDEVPEDMQEFIQLNAELAEVWPNITEKKDPLPDAEDWDGVKGKLQHLER']\n",
      "Len 0 as example:  118\n",
      "Len 2 as example:  106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12203/4292614851.py:129: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  fig_handle = sns.distplot(torch.from_numpy(y_train.flatten()),bins=25,kde=False,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12203/4292614851.py:134: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  fig_handle = sns.distplot(torch.from_numpy(X_train.flatten()),bins=25,kde=False,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset\n",
    "ynormfac=21.\n",
    "Xnormfac=9.\n",
    "batch_size_=256\n",
    "max_length = 128\n",
    "number = 99999999999999999\n",
    "min_length=0\n",
    "train_loader, train_loader_noshuffle, test_loader,tokenizer_y, tokenizer_X \\\n",
    "        = load_data_set_SS_seq2seq (file_path='PROTEIN_Mar18_2022_SECSTR_ALL.csv', \n",
    "                   min_length=0, max_length=max_length, batch_size_=batch_size_, output_dim=3,\n",
    "                  maxdata=number, remove_longer=True,   split=0.1,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27657c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print (len (train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d303683",
   "metadata": {},
   "source": [
    "### Build diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01f39ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Attention-Diffusion model\n",
    "########################################################\n",
    "\n",
    "#based on: https://github.com/lucidrains/imagen-pytorch\n",
    "\n",
    "import math\n",
    "import copy\n",
    "from random import random\n",
    "from typing import List, Union\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial, wraps\n",
    "from contextlib import contextmanager, nullcontext\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch import nn, einsum\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.special import expm1\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import kornia.augmentation as K\n",
    "\n",
    "from einops import rearrange, repeat, reduce\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from einops_exts import rearrange_many, repeat_many, check_shape\n",
    "from einops_exts.torch import EinopsToAndFrom\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def identity(t, *args, **kwargs):\n",
    "    return t\n",
    "\n",
    "def first(arr, d = None):\n",
    "    if len(arr) == 0:\n",
    "        return d\n",
    "    return arr[0]\n",
    "\n",
    "def maybe(fn):\n",
    "    @wraps(fn)\n",
    "    def inner(x):\n",
    "        if not exists(x):\n",
    "            return x\n",
    "        return fn(x)\n",
    "    return inner\n",
    "\n",
    "def once(fn):\n",
    "    called = False\n",
    "    @wraps(fn)\n",
    "    def inner(x):\n",
    "        nonlocal called\n",
    "        if called:\n",
    "            return\n",
    "        called = True\n",
    "        return fn(x)\n",
    "    return inner\n",
    "\n",
    "print_once = once(print)\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def cast_tuple(val, length = None):\n",
    "    if isinstance(val, list):\n",
    "        val = tuple(val)\n",
    "\n",
    "    output = val if isinstance(val, tuple) else ((val,) * default(length, 1))\n",
    "\n",
    "    if exists(length):\n",
    "        assert len(output) == length\n",
    "\n",
    "    return output\n",
    "\n",
    "def is_float_dtype(dtype):\n",
    "    return any([dtype == float_dtype for float_dtype in (torch.float64, torch.float32, torch.float16, torch.bfloat16)])\n",
    "\n",
    "def cast_uint8_images_to_float(images):\n",
    "    if not images.dtype == torch.uint8:\n",
    "        return images\n",
    "    return images / 255\n",
    "\n",
    "def module_device(module):\n",
    "    return next(module.parameters()).device\n",
    "\n",
    "def zero_init_(m):\n",
    "    nn.init.zeros_(m.weight)\n",
    "    if exists(m.bias):\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "def eval_decorator(fn):\n",
    "    def inner(model, *args, **kwargs):\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "        out = fn(model, *args, **kwargs)\n",
    "        model.train(was_training)\n",
    "        return out\n",
    "    return inner\n",
    "\n",
    "def pad_tuple_to_length(t, length, fillvalue = None):\n",
    "    remain_length = length - len(t)\n",
    "    if remain_length <= 0:\n",
    "        return t\n",
    "    return (*t, *((fillvalue,) * remain_length))\n",
    "\n",
    "# helper classes\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return x\n",
    "\n",
    "# tensor helpers\n",
    "\n",
    "def log(t, eps: float = 1e-12):\n",
    "    return torch.log(t.clamp(min = eps))\n",
    "\n",
    "def l2norm(t):\n",
    "    return F.normalize(t, dim = -1)\n",
    "\n",
    "def right_pad_dims_to(x, t):\n",
    "    padding_dims = x.ndim - t.ndim\n",
    "    if padding_dims <= 0:\n",
    "        return t\n",
    "    return t.view(*t.shape, *((1,) * padding_dims))\n",
    "\n",
    "def masked_mean(t, *, dim, mask = None):\n",
    "    if not exists(mask):\n",
    "        return t.mean(dim = dim)\n",
    "\n",
    "    denom = mask.sum(dim = dim, keepdim = True)\n",
    "    mask = rearrange(mask, 'b n -> b n 1')\n",
    "    masked_t = t.masked_fill(~mask, 0.)\n",
    "\n",
    "    return masked_t.sum(dim = dim) / denom.clamp(min = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8aa90b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resize_image_to(\n",
    "    image,\n",
    "    target_image_size,\n",
    "    clamp_range = None\n",
    "):\n",
    "    orig_image_size = image.shape[-1]\n",
    "\n",
    "    if orig_image_size == target_image_size:\n",
    "        return image\n",
    "\n",
    "    out = F.interpolate(image.float(), target_image_size, mode = 'linear', align_corners = True) \n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4651cd96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_neg_one_to_one(img):\n",
    "    return img * 2 - 1\n",
    "\n",
    "def unnormalize_zero_to_one(normed_img):\n",
    "    return (normed_img + 1) * 0.5\n",
    "\n",
    "# classifier free guidance functions\n",
    "def prob_mask_like(shape, prob, device):\n",
    "    if prob == 1:\n",
    "        return torch.ones(shape, device = device, dtype = torch.bool)\n",
    "    elif prob == 0:\n",
    "        return torch.zeros(shape, device = device, dtype = torch.bool)\n",
    "    else:\n",
    "        return torch.zeros(shape, device = device).float().uniform_(0, 1) < prob\n",
    "\n",
    "# gaussian diffusion with continuous time helper functions and classes\n",
    "# large part of this was thanks to @crowsonkb at https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/utils.py\n",
    "\n",
    "@torch.jit.script\n",
    "def beta_linear_log_snr(t):\n",
    "    return -torch.log(expm1(1e-4 + 10 * (t ** 2)))\n",
    "\n",
    "@torch.jit.script\n",
    "def alpha_cosine_log_snr(t, s: float = 0.008):\n",
    "    return -log((torch.cos((t + s) / (1 + s) * math.pi * 0.5) ** -2) - 1, eps = 1e-5) # not sure if this accounts for beta being clipped to 0.999 in discrete version\n",
    "\n",
    "def log_snr_to_alpha_sigma(log_snr):\n",
    "    return torch.sqrt(torch.sigmoid(log_snr)), torch.sqrt(torch.sigmoid(-log_snr))\n",
    "\n",
    "class GaussianDiffusionContinuousTimes(nn.Module):\n",
    "    def __init__(self, *, noise_schedule, timesteps = 1000):\n",
    "        super().__init__()\n",
    "\n",
    "        if noise_schedule == \"linear\":\n",
    "            self.log_snr = beta_linear_log_snr\n",
    "        elif noise_schedule == \"cosine\":\n",
    "            self.log_snr = alpha_cosine_log_snr\n",
    "        else:\n",
    "            raise ValueError(f'invalid noise schedule {noise_schedule}')\n",
    "\n",
    "        self.num_timesteps = timesteps\n",
    "\n",
    "    def get_times(self, batch_size, noise_level, *, device):\n",
    "        return torch.full((batch_size,), noise_level, device = device, dtype = torch.float32)\n",
    "\n",
    "    def sample_random_times(self, batch_size, max_thres = 0.999, *, device):\n",
    "        return torch.zeros((batch_size,), device = device).float().uniform_(0, max_thres)\n",
    "\n",
    "    def get_condition(self, times):\n",
    "        return maybe(self.log_snr)(times)\n",
    "\n",
    "    def get_sampling_timesteps(self, batch, *, device):\n",
    "        times = torch.linspace(1., 0., self.num_timesteps + 1, device = device)\n",
    "        times = repeat(times, 't -> b t', b = batch)\n",
    "        times = torch.stack((times[:, :-1], times[:, 1:]), dim = 0)\n",
    "        times = times.unbind(dim = -1)\n",
    "        return times\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t, *, t_next = None):\n",
    "        t_next = default(t_next, lambda: (t - 1. / self.num_timesteps).clamp(min = 0.))\n",
    "\n",
    "        \"\"\" https://openreview.net/attachment?id=2LdBqxc1Yv&name=supplementary_material \"\"\"\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_next = self.log_snr(t_next)\n",
    "        log_snr, log_snr_next = map(partial(right_pad_dims_to, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "        # c - as defined near eq 33\n",
    "        c = -expm1(log_snr - log_snr_next)\n",
    "        posterior_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "        # following (eq. 33)\n",
    "        posterior_variance = (sigma_next ** 2) * c\n",
    "        posterior_log_variance_clipped = log(posterior_variance, eps = 1e-20)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def q_sample(self, x_start, t, noise = None):\n",
    "        dtype = x_start.dtype\n",
    "\n",
    "        if isinstance(t, float):\n",
    "            batch = x_start.shape[0]\n",
    "            t = torch.full((batch,), t, device = x_start.device, dtype = dtype)\n",
    "\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        log_snr = self.log_snr(t).type(dtype)\n",
    "        log_snr_padded_dim = right_pad_dims_to(x_start, log_snr)\n",
    "        alpha, sigma =  log_snr_to_alpha_sigma(log_snr_padded_dim)\n",
    "\n",
    "        return alpha * x_start + sigma * noise, log_snr\n",
    "\n",
    "    def q_sample_from_to(self, x_from, from_t, to_t, noise = None):\n",
    "        shape, device, dtype = x_from.shape, x_from.device, x_from.dtype\n",
    "        batch = shape[0]\n",
    "\n",
    "        if isinstance(from_t, float):\n",
    "            from_t = torch.full((batch,), from_t, device = device, dtype = dtype)\n",
    "\n",
    "        if isinstance(to_t, float):\n",
    "            to_t = torch.full((batch,), to_t, device = device, dtype = dtype)\n",
    "\n",
    "        noise = default(noise, lambda: torch.randn_like(x_from))\n",
    "\n",
    "        log_snr = self.log_snr(from_t)\n",
    "        log_snr_padded_dim = right_pad_dims_to(x_from, log_snr)\n",
    "        alpha, sigma =  log_snr_to_alpha_sigma(log_snr_padded_dim)\n",
    "\n",
    "        log_snr_to = self.log_snr(to_t)\n",
    "        log_snr_padded_dim_to = right_pad_dims_to(x_from, log_snr_to)\n",
    "        alpha_to, sigma_to =  log_snr_to_alpha_sigma(log_snr_padded_dim_to)\n",
    "\n",
    "        return x_from * (alpha_to / alpha) + noise * (sigma_to * alpha - sigma * alpha_to) / alpha\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr = right_pad_dims_to(x_t, log_snr)\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        return (x_t - sigma * noise) / alpha.clamp(min = 1e-8)\n",
    "\n",
    "# norms and residuals\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, feats, stable = False, dim = -1):\n",
    "        super().__init__()\n",
    "        self.stable = stable\n",
    "        self.dim = dim\n",
    "\n",
    "        self.g = nn.Parameter(torch.ones(feats, *((1,) * (-dim - 1))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        dtype, dim = x.dtype, self.dim\n",
    "\n",
    "        if self.stable:\n",
    "            x = x / x.amax(dim = dim, keepdim = True).detach()\n",
    "\n",
    "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
    "        var = torch.var(x, dim = dim, unbiased = False, keepdim = True)\n",
    "        mean = torch.mean(x, dim = dim, keepdim = True)\n",
    "\n",
    "        return (x - mean) * (var + eps).rsqrt().type(dtype) * self.g.type(dtype)\n",
    "\n",
    "ChanLayerNorm = partial(LayerNorm, dim = -2)\n",
    "\n",
    "class Always():\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.val\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "class Parallel(nn.Module):\n",
    "    def __init__(self, *fns):\n",
    "        super().__init__()\n",
    "        self.fns = nn.ModuleList(fns)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [fn(x) for fn in self.fns]\n",
    "        return sum(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b99ef42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attention pooling\n",
    "\n",
    "class PerceiverAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        cosine_sim_attn = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5 if not cosine_sim_attn else 1\n",
    "        self.cosine_sim_attn = cosine_sim_attn\n",
    "        self.cosine_sim_scale = 16 if cosine_sim_attn else 1\n",
    "\n",
    "        self.heads = heads\n",
    "        inner_dim = dim_head * heads\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.norm_latents = nn.LayerNorm(dim)\n",
    "\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim, bias = False),\n",
    "            nn.LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, latents, mask = None):\n",
    "        x = self.norm(x)\n",
    "        latents = self.norm_latents(latents)\n",
    "\n",
    "        b, h = x.shape[0], self.heads\n",
    "\n",
    "        q = self.to_q(latents)\n",
    "\n",
    "        # the paper differs from Perceiver in which they also concat the key / values \n",
    "        # derived from the latents to be attended to\n",
    "        kv_input = torch.cat((x, latents), dim = -2)\n",
    "        k, v = self.to_kv(kv_input).chunk(2, dim = -1)\n",
    "\n",
    "        q, k, v = rearrange_many((q, k, v), 'b n (h d) -> b h n d', h = h)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        # cosine sim attention\n",
    "\n",
    "        if self.cosine_sim_attn:\n",
    "            q, k = map(l2norm, (q, k))\n",
    "\n",
    "        # similarities and masking\n",
    "\n",
    "        sim = einsum('... i d, ... j d  -> ... i j', q, k) * self.cosine_sim_scale\n",
    "\n",
    "        if exists(mask):\n",
    "            max_neg_value = -torch.finfo(sim.dtype).max\n",
    "            mask = F.pad(mask, (0, latents.shape[-2]), value = True)\n",
    "             \n",
    "            mask = rearrange(mask, 'b j -> b 1 1 j')\n",
    "            sim = sim.masked_fill(~mask, max_neg_value)\n",
    "\n",
    "        # attention\n",
    "\n",
    "        attn = sim.softmax(dim = -1, dtype = torch.float32)\n",
    "        attn = attn.to(sim.dtype)\n",
    "\n",
    "        out = einsum('... i j, ... j d -> ... i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class PerceiverResampler(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        depth,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        num_latents = 64,\n",
    "        num_latents_mean_pooled = 4, # number of latents derived from mean pooled representation of the sequence\n",
    "        max_seq_len = 512,\n",
    "        ff_mult = 4,\n",
    "        cosine_sim_attn = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, dim)\n",
    "\n",
    "        self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
    "\n",
    "        self.to_latents_from_mean_pooled_seq = None\n",
    "\n",
    "        if num_latents_mean_pooled > 0:\n",
    "            self.to_latents_from_mean_pooled_seq = nn.Sequential(\n",
    "                LayerNorm(dim),\n",
    "                nn.Linear(dim, dim * num_latents_mean_pooled),\n",
    "                Rearrange('b (n d) -> b n d', n = num_latents_mean_pooled)\n",
    "            )\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PerceiverAttention(dim = dim, dim_head = dim_head, heads = heads, cosine_sim_attn = cosine_sim_attn),\n",
    "                FeedForward(dim = dim, mult = ff_mult)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        n, device = x.shape[1], x.device\n",
    "        pos_emb = self.pos_emb(torch.arange(n, device = device))\n",
    "\n",
    "        x_with_pos = x + pos_emb\n",
    "\n",
    "        latents = repeat(self.latents, 'n d -> b n d', b = x.shape[0])\n",
    "\n",
    "        if exists(self.to_latents_from_mean_pooled_seq):\n",
    "            meanpooled_seq = masked_mean(x, dim = 1, mask = torch.ones(x.shape[:2], device = x.device, dtype = torch.bool))\n",
    "            meanpooled_latents = self.to_latents_from_mean_pooled_seq(meanpooled_seq)\n",
    "            latents = torch.cat((meanpooled_latents, latents), dim = -2)\n",
    "\n",
    "        for attn, ff in self.layers:\n",
    "            latents = attn(x_with_pos, latents, mask = mask) + latents\n",
    "            latents = ff(latents) + latents\n",
    "\n",
    "        return latents\n",
    "\n",
    "# attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        context_dim = None,\n",
    "        cosine_sim_attn = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5 if not cosine_sim_attn else 1.\n",
    "        self.cosine_sim_attn = cosine_sim_attn\n",
    "        self.cosine_sim_scale = 16 if cosine_sim_attn else 1\n",
    "\n",
    "        self.heads = heads\n",
    "        inner_dim = dim_head * heads\n",
    "\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "        self.null_kv = nn.Parameter(torch.randn(2, dim_head))\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(dim, dim_head * 2, bias = False)\n",
    "\n",
    "        self.to_context = nn.Sequential(nn.LayerNorm(context_dim), nn.Linear(context_dim, dim_head * 2)) if exists(context_dim) else None\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim, bias = False),\n",
    "            LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, context = None, mask = None, attn_bias = None):\n",
    "        b, n, device = *x.shape[:2], x.device\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(x).chunk(2, dim = -1))\n",
    "\n",
    "        q = rearrange(q, 'b n (h d) -> b h n d', h = self.heads)\n",
    "        q = q * self.scale\n",
    "\n",
    "        # add null key / value for classifier free guidance in prior net\n",
    "\n",
    "        nk, nv = repeat_many(self.null_kv.unbind(dim = -2), 'd -> b 1 d', b = b)\n",
    "        k = torch.cat((nk, k), dim = -2)\n",
    "        v = torch.cat((nv, v), dim = -2)\n",
    "\n",
    "        # add text conditioning, if present\n",
    "\n",
    "        if exists(context):\n",
    "            assert exists(self.to_context)\n",
    "            ck, cv = self.to_context(context).chunk(2, dim = -1)\n",
    "            k = torch.cat((ck, k), dim = -2)\n",
    "            v = torch.cat((cv, v), dim = -2)\n",
    "\n",
    "        # cosine sim attention\n",
    "\n",
    "        if self.cosine_sim_attn:\n",
    "            q, k = map(l2norm, (q, k))\n",
    "\n",
    "        # calculate query / key similarities\n",
    "\n",
    "        sim = einsum('b h i d, b j d -> b h i j', q, k) * self.cosine_sim_scale\n",
    "\n",
    "        # relative positional encoding (T5 style)\n",
    "\n",
    "        if exists(attn_bias):\n",
    "            sim = sim + attn_bias\n",
    "\n",
    "        # masking\n",
    "\n",
    "        max_neg_value = -torch.finfo(sim.dtype).max\n",
    "\n",
    "        if exists(mask):\n",
    "            mask = F.pad(mask, (1, 0), value = True)\n",
    "            \n",
    "            mask = rearrange(mask, 'b j -> b 1 j')\n",
    "            sim = sim.masked_fill(~mask, max_neg_value)\n",
    "\n",
    "        # attention\n",
    "\n",
    "        attn = sim.softmax(dim = -1, dtype = torch.float32)\n",
    "        attn = attn.to(sim.dtype)\n",
    "\n",
    "        # aggregate values\n",
    "\n",
    "        out = einsum('b h i j, b j d -> b h i d', attn, v)\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "# decoder\n",
    "\n",
    "def Upsample(dim, dim_out = None):\n",
    "    dim_out = default(dim_out, dim)\n",
    "\n",
    "    return nn.Sequential(\n",
    "        nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
    "        nn.Conv1d(dim, dim_out, 3, padding = 1)\n",
    "    )\n",
    "\n",
    "class PixelShuffleUpsample(nn.Module):\n",
    "    \"\"\"\n",
    "    code shared by @MalumaDev at DALLE2-pytorch for addressing checkboard artifacts\n",
    "    https://arxiv.org/ftp/arxiv/papers/1707/1707.02937.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, dim_out = None):\n",
    "        super().__init__()\n",
    "        dim_out = default(dim_out, dim)\n",
    "        conv = nn.Conv1d(dim, dim_out * 4, 1)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            conv,\n",
    "            nn.SiLU(),\n",
    "            nn.PixelShuffle(2)\n",
    "        )\n",
    "\n",
    "        self.init_conv_(conv)\n",
    "\n",
    "    def init_conv_(self, conv):\n",
    "         \n",
    "        o, i, h  = conv.weight.shape\n",
    "        conv_weight = torch.empty(o // 4, i, h )\n",
    "        nn.init.kaiming_uniform_(conv_weight)\n",
    "        conv_weight = repeat(conv_weight, 'o ... -> (o 4) ...')\n",
    "\n",
    "        conv.weight.data.copy_(conv_weight)\n",
    "        nn.init.zeros_(conv.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def Downsample(dim, dim_out = None):\n",
    "    # https://arxiv.org/abs/2208.03641 shows this is the most optimal way to downsample\n",
    "    # named SP-conv in the paper, but basically a pixel unshuffle\n",
    "    dim_out = default(dim_out, dim)\n",
    "   \n",
    "    return nn.Sequential(\n",
    "         \n",
    "        Rearrange('b c (h s1)  -> b (c s1) h', s1 = 2),\n",
    "        nn.Conv1d(dim * 2, dim_out, 1)\n",
    "    )\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device = x.device) * -emb)\n",
    "        emb = rearrange(x, 'i -> i 1') * rearrange(emb, 'j -> 1 j')\n",
    "        return torch.cat((emb.sin(), emb.cos()), dim = -1)\n",
    "\n",
    "class LearnedSinusoidalPosEmb(nn.Module):\n",
    "    \"\"\" following @crowsonkb 's lead with learned sinusoidal pos emb \"\"\"\n",
    "    \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        assert (dim % 2) == 0\n",
    "        half_dim = dim // 2\n",
    "        self.weights = nn.Parameter(torch.randn(half_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b -> b 1')\n",
    "        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n",
    "        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n",
    "        fouriered = torch.cat((x, fouriered), dim = -1)\n",
    "        return fouriered\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        dim_out,\n",
    "        groups = 8,\n",
    "        norm = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.groupnorm = nn.GroupNorm(groups, dim) if norm else Identity()\n",
    "        self.activation = nn.SiLU()\n",
    "        self.project = nn.Conv1d(dim, dim_out, 3, padding = 1)\n",
    "\n",
    "    def forward(self, x, scale_shift = None):\n",
    "        x = self.groupnorm(x)\n",
    "\n",
    "        if exists(scale_shift):\n",
    "            scale, shift = scale_shift\n",
    "            x = x * (scale + 1) + shift\n",
    "\n",
    "        x = self.activation(x)\n",
    "        return self.project(x)\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        dim_out,\n",
    "        *,\n",
    "        cond_dim = None,\n",
    "        time_cond_dim = None,\n",
    "        groups = 8,\n",
    "        linear_attn = False,\n",
    "        use_gca = False,\n",
    "        squeeze_excite = False,\n",
    "        **attn_kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time_mlp = None\n",
    "\n",
    "        if exists(time_cond_dim):\n",
    "            self.time_mlp = nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(time_cond_dim, dim_out * 2)\n",
    "            )\n",
    "\n",
    "        self.cross_attn = None\n",
    "\n",
    "        if exists(cond_dim):\n",
    "            attn_klass = CrossAttention if not linear_attn else LinearCrossAttention\n",
    "\n",
    "            self.cross_attn = EinopsToAndFrom(\n",
    "           \n",
    "                'b c h ',\n",
    "                'b h c',\n",
    "                attn_klass(\n",
    "                    dim = dim_out,\n",
    "                    context_dim = cond_dim,\n",
    "                    **attn_kwargs\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups = groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups = groups)\n",
    "\n",
    "        self.gca = GlobalContext(dim_in = dim_out, dim_out = dim_out) if use_gca else Always(1)\n",
    "\n",
    "        self.res_conv = nn.Conv1d(dim, dim_out, 1) if dim != dim_out else Identity()\n",
    "\n",
    "\n",
    "    def forward(self, x, time_emb = None, cond = None):\n",
    "\n",
    "        scale_shift = None\n",
    "        if exists(self.time_mlp) and exists(time_emb):\n",
    "            time_emb = self.time_mlp(time_emb)\n",
    "            \n",
    "            time_emb = rearrange(time_emb, 'b c -> b c 1')\n",
    "            scale_shift = time_emb.chunk(2, dim = 1)\n",
    "\n",
    "        h = self.block1(x)\n",
    "\n",
    "        if exists(self.cross_attn):\n",
    "            assert exists(cond)\n",
    "            h = self.cross_attn(h, context = cond) + h\n",
    "\n",
    "        h = self.block2(h, scale_shift = scale_shift)\n",
    "\n",
    "        h = h * self.gca(h)\n",
    "\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        context_dim = None,\n",
    "        dim_head = 64,\n",
    "        heads = 8,\n",
    "        norm_context = False,\n",
    "        cosine_sim_attn = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5 if not cosine_sim_attn else 1.\n",
    "        self.cosine_sim_attn = cosine_sim_attn\n",
    "        self.cosine_sim_scale = 16 if cosine_sim_attn else 1\n",
    "\n",
    "        self.heads = heads\n",
    "        inner_dim = dim_head * heads\n",
    "\n",
    "        context_dim = default(context_dim, dim)\n",
    "\n",
    "        self.norm = LayerNorm(dim)\n",
    "        self.norm_context = LayerNorm(context_dim) if norm_context else Identity()\n",
    "\n",
    "        self.null_kv = nn.Parameter(torch.randn(2, dim_head))\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(context_dim, inner_dim * 2, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim, bias = False),\n",
    "            LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, context, mask = None):\n",
    "        b, n, device = *x.shape[:2], x.device\n",
    "\n",
    "        x = self.norm(x)\n",
    "        context = self.norm_context(context)\n",
    "\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(context).chunk(2, dim = -1))\n",
    "\n",
    "        q, k, v = rearrange_many((q, k, v), 'b n (h d) -> b h n d', h = self.heads)\n",
    "\n",
    "        # add null key / value for classifier free guidance in prior net\n",
    "\n",
    "        nk, nv = repeat_many(self.null_kv.unbind(dim = -2), 'd -> b h 1 d', h = self.heads,  b = b)\n",
    "\n",
    "        k = torch.cat((nk, k), dim = -2)\n",
    "        v = torch.cat((nv, v), dim = -2)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        # cosine sim attention\n",
    "\n",
    "        if self.cosine_sim_attn:\n",
    "            q, k = map(l2norm, (q, k))\n",
    "\n",
    "        # similarities\n",
    "\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', q, k) * self.cosine_sim_scale\n",
    "\n",
    "        # masking\n",
    "\n",
    "        max_neg_value = -torch.finfo(sim.dtype).max\n",
    "\n",
    "        if exists(mask):\n",
    "            mask = F.pad(mask, (1, 0), value = True)\n",
    "          \n",
    "            mask = rearrange(mask, 'b j -> b 1 j')\n",
    "            sim = sim.masked_fill(~mask, max_neg_value)\n",
    "\n",
    "        attn = sim.softmax(dim = -1, dtype = torch.float32)\n",
    "        attn = attn.to(sim.dtype)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LinearCrossAttention(CrossAttention):\n",
    "    def forward(self, x, context, mask = None):\n",
    "        b, n, device = *x.shape[:2], x.device\n",
    "\n",
    "        x = self.norm(x)\n",
    "        context = self.norm_context(context)\n",
    "\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(context).chunk(2, dim = -1))\n",
    "\n",
    "        q, k, v = rearrange_many((q, k, v), 'b n (h d) -> (b h) n d', h = self.heads)\n",
    "\n",
    "        # add null key / value for classifier free guidance in prior net\n",
    "\n",
    "        nk, nv = repeat_many(self.null_kv.unbind(dim = -2), 'd -> (b h) 1 d', h = self.heads,  b = b)\n",
    "\n",
    "        k = torch.cat((nk, k), dim = -2)\n",
    "        v = torch.cat((nv, v), dim = -2)\n",
    "\n",
    "        # masking\n",
    "\n",
    "        max_neg_value = -torch.finfo(x.dtype).max\n",
    "\n",
    "        if exists(mask):\n",
    "            mask = F.pad(mask, (1, 0), value = True)\n",
    "            mask = rearrange(mask, 'b n -> b n 1')\n",
    "            k = k.masked_fill(~mask, max_neg_value)\n",
    "            v = v.masked_fill(~mask, 0.)\n",
    "\n",
    "        # linear attention\n",
    "\n",
    "        q = q.softmax(dim = -1)\n",
    "        k = k.softmax(dim = -2)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        context = einsum('b n d, b n e -> b d e', k, v)\n",
    "        out = einsum('b n d, b d e -> b n e', q, context)\n",
    "        out = rearrange(out, '(b h) n d -> b n (h d)', h = self.heads)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        dim_head = 32,\n",
    "        heads = 8,\n",
    "        dropout = 0.05,\n",
    "        context_dim = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        inner_dim = dim_head * heads\n",
    "        self.norm = ChanLayerNorm(dim)\n",
    "\n",
    "        self.nonlin = nn.SiLU()\n",
    "\n",
    "        self.to_q = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(dim, inner_dim, 1, bias = False),\n",
    "            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, padding = 1, groups = inner_dim)\n",
    "        )\n",
    "\n",
    "        self.to_k = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(dim, inner_dim, 1, bias = False),\n",
    "            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, padding = 1, groups = inner_dim)\n",
    "        )\n",
    "\n",
    "        self.to_v = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(dim, inner_dim, 1, bias = False),\n",
    "            nn.Conv1d(inner_dim, inner_dim, 3, bias = False, padding = 1, groups = inner_dim)\n",
    "        )\n",
    "\n",
    "        self.to_context = nn.Sequential(nn.LayerNorm(context_dim), nn.Linear(context_dim, inner_dim * 2, bias = False)) if exists(context_dim) else None\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Conv1d(inner_dim, dim, 1, bias = False),\n",
    "            ChanLayerNorm(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, fmap, context = None):\n",
    "        h, x, y = self.heads, *fmap.shape[-2:]\n",
    "\n",
    "        fmap = self.norm(fmap)\n",
    "        q, k, v = map(lambda fn: fn(fmap), (self.to_q, self.to_k, self.to_v))\n",
    "        q, k, v = rearrange_many((q, k, v), 'b (h c) x y -> (b h) (x y) c', h = h)\n",
    "\n",
    "        if exists(context):\n",
    "            assert exists(self.to_context)\n",
    "            ck, cv = self.to_context(context).chunk(2, dim = -1)\n",
    "            ck, cv = rearrange_many((ck, cv), 'b n (h d) -> (b h) n d', h = h)\n",
    "            k = torch.cat((k, ck), dim = -2)\n",
    "            v = torch.cat((v, cv), dim = -2)\n",
    "\n",
    "        q = q.softmax(dim = -1)\n",
    "        k = k.softmax(dim = -2)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        context = einsum('b n d, b n e -> b d e', k, v)\n",
    "        out = einsum('b n d, b d e -> b n e', q, context)\n",
    "        out = rearrange(out, '(b h) (x y) d -> b (h d) x y', h = h, x = x, y = y)\n",
    "\n",
    "        out = self.nonlin(out)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class GlobalContext(nn.Module):\n",
    "    \"\"\" basically a superior form of squeeze-excitation that is attention-esque \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim_in,\n",
    "        dim_out\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.to_k = nn.Conv1d(dim_in, 1, 1)\n",
    "        hidden_dim = max(3, dim_out // 2)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(dim_in, hidden_dim, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(hidden_dim, dim_out, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = self.to_k(x)\n",
    "        x, context = rearrange_many((x, context), 'b n ... -> b n (...)')\n",
    "        out = einsum('b i n, b c n -> b c i', context.softmax(dim = -1), x)\n",
    "        \n",
    "        return self.net(out)\n",
    "\n",
    "def FeedForward(dim, mult = 2):\n",
    "    hidden_dim = int(dim * mult)\n",
    "    return nn.Sequential(\n",
    "        LayerNorm(dim),\n",
    "        nn.Linear(dim, hidden_dim, bias = False),\n",
    "        nn.GELU(),\n",
    "        LayerNorm(hidden_dim),\n",
    "        nn.Linear(hidden_dim, dim, bias = False)\n",
    "    )\n",
    "\n",
    "def ChanFeedForward(dim, mult = 2):  # in paper, it seems for self attention layers they did feedforwards with twice channel width\n",
    "    hidden_dim = int(dim * mult)\n",
    "    return nn.Sequential(\n",
    "        ChanLayerNorm(dim),\n",
    "        nn.Conv1d(dim, hidden_dim, 1, bias = False),\n",
    "        nn.GELU(),\n",
    "        ChanLayerNorm(hidden_dim),\n",
    "        nn.Conv1d(hidden_dim, dim, 1, bias = False)\n",
    "    )\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        depth = 1,\n",
    "        heads = 8,\n",
    "        dim_head = 32,\n",
    "        ff_mult = 2,\n",
    "        context_dim = None,\n",
    "        cosine_sim_attn = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                EinopsToAndFrom('b c h', 'b h c', Attention(dim = dim, heads = heads, dim_head = dim_head, context_dim = context_dim, cosine_sim_attn = cosine_sim_attn)),\n",
    "                ChanFeedForward(dim = dim, mult = ff_mult)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, context = None):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x, context = context) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class LinearAttentionTransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        depth = 1,\n",
    "        heads = 8,\n",
    "        dim_head = 32,\n",
    "        ff_mult = 2,\n",
    "        context_dim = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                LinearAttention(dim = dim, heads = heads, dim_head = dim_head, context_dim = context_dim),\n",
    "                ChanFeedForward(dim = dim, mult = ff_mult)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, context = None):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x, context = context) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class CrossEmbedLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim_in,\n",
    "        kernel_sizes,\n",
    "        dim_out = None,\n",
    "        stride = 2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert all([*map(lambda t: (t % 2) == (stride % 2), kernel_sizes)])\n",
    "        dim_out = default(dim_out, dim_in)\n",
    "\n",
    "        kernel_sizes = sorted(kernel_sizes)\n",
    "        num_scales = len(kernel_sizes)\n",
    "\n",
    "        # calculate the dimension at each scale\n",
    "        dim_scales = [int(dim_out / (2 ** i)) for i in range(1, num_scales)]\n",
    "        dim_scales = [*dim_scales, dim_out - sum(dim_scales)]\n",
    "\n",
    "        self.convs = nn.ModuleList([])\n",
    "        for kernel, dim_scale in zip(kernel_sizes, dim_scales):\n",
    "            self.convs.append(nn.Conv1d(dim_in, dim_scale, kernel, stride = stride, padding = (kernel - stride) // 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        fmaps = tuple(map(lambda conv: conv(x), self.convs))\n",
    "        return torch.cat(fmaps, dim = 1)\n",
    "\n",
    "class UpsampleCombiner(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        enabled = False,\n",
    "        dim_ins = tuple(),\n",
    "        dim_outs = tuple()\n",
    "    ):\n",
    "        super().__init__()\n",
    "        dim_outs = cast_tuple(dim_outs, len(dim_ins))\n",
    "        assert len(dim_ins) == len(dim_outs)\n",
    "\n",
    "        self.enabled = enabled\n",
    "\n",
    "        if not self.enabled:\n",
    "            self.dim_out = dim\n",
    "            return\n",
    "\n",
    "        self.fmap_convs = nn.ModuleList([Block(dim_in, dim_out) for dim_in, dim_out in zip(dim_ins, dim_outs)])\n",
    "        self.dim_out = dim + (sum(dim_outs) if len(dim_outs) > 0 else 0)\n",
    "\n",
    "    def forward(self, x, fmaps = None):\n",
    "        target_size = x.shape[-1]\n",
    "\n",
    "        fmaps = default(fmaps, tuple())\n",
    "\n",
    "        if not self.enabled or len(fmaps) == 0 or len(self.fmap_convs) == 0:\n",
    "            return x\n",
    "\n",
    "        fmaps = [resize_image_to(fmap, target_size) for fmap in fmaps]\n",
    "        outs = [conv(fmap) for fmap, conv in zip(fmaps, self.fmap_convs)]\n",
    "        return torch.cat((x, *outs), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7db83ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "## 1D Unet \n",
    "########################################################\n",
    "class OneD_Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        image_embed_dim = 1024,\n",
    "        text_embed_dim = 768,  \n",
    "        num_resnet_blocks = 1,\n",
    "        cond_dim = None,\n",
    "        num_image_tokens = 4,\n",
    "        num_time_tokens = 2,\n",
    "        learned_sinu_pos_emb_dim = 16,\n",
    "        out_dim = None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        cond_images_channels = 0,\n",
    "        channels = 3,\n",
    "        channels_out = None,\n",
    "        attn_dim_head = 64,\n",
    "        attn_heads = 8,\n",
    "        ff_mult = 2.,\n",
    "        lowres_cond = False,                # for cascading diffusion - https://cascaded-diffusion.github.io/\n",
    "        layer_attns = True,\n",
    "        layer_attns_depth = 1,\n",
    "        layer_attns_add_text_cond = True,   # whether to condition the self-attention blocks with the text embeddings, as described in Appendix D.3.1\n",
    "        attend_at_middle = True,            # whether to have a layer of attention at the bottleneck (can turn off for higher resolution in cascading DDPM, before bringing in efficient attention)\n",
    "        layer_cross_attns = True,\n",
    "        use_linear_attn = False,\n",
    "        use_linear_cross_attn = False,\n",
    "        cond_on_text = True,\n",
    "        max_text_len = 256,\n",
    "        init_dim = None,\n",
    "        resnet_groups = 8,\n",
    "        init_conv_kernel_size = 7,          # kernel size of initial conv, if not using cross embed\n",
    "        init_cross_embed = False,\n",
    "        init_cross_embed_kernel_sizes = (3, 7, 15),\n",
    "        cross_embed_downsample = False,\n",
    "        cross_embed_downsample_kernel_sizes = (2, 4),\n",
    "        attn_pool_text = True,\n",
    "        attn_pool_num_latents = 32,\n",
    "        dropout = 0.,\n",
    "        memory_efficient = False,\n",
    "        init_conv_to_final_conv_residual = False,\n",
    "        use_global_context_attn = True,\n",
    "        scale_skip_connection = True,\n",
    "        final_resnet_block = True,\n",
    "        final_conv_kernel_size = 3,\n",
    "        cosine_sim_attn = False,\n",
    "        self_cond = False,\n",
    "        combine_upsample_fmaps = False,      # combine feature maps from all upsample blocks, used in unet squared successfully\n",
    "        pixel_shuffle_upsample = False  ,      # may address checkboard artifacts\n",
    "        beginning_and_final_conv_present = True , #TODO add cross-attn, doesnt work yet...whether or not to have final conv layer\n",
    "           \n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert attn_heads > 1, 'you need to have more than 1 attention head, ideally at least 4 or 8'\n",
    "\n",
    "        # save locals to take care of some hyperparameters for cascading DDPM\n",
    "\n",
    "        self._locals = locals()\n",
    "        self._locals.pop('self', None)\n",
    "        self._locals.pop('__class__', None)\n",
    "\n",
    "        # determine dimensions\n",
    "\n",
    "        self.channels = channels\n",
    "        self.channels_out = default(channels_out, channels)\n",
    "\n",
    "        init_channels = channels * (1 + int(lowres_cond) + int(self_cond))\n",
    "        init_dim = default(init_dim, dim)\n",
    "\n",
    "        self.self_cond = self_cond\n",
    "\n",
    "        # optional image conditioning\n",
    "\n",
    "        self.has_cond_image = cond_images_channels > 0\n",
    "        self.cond_images_channels = cond_images_channels\n",
    "\n",
    "        init_channels += cond_images_channels\n",
    " \n",
    "\n",
    "        self.beginning_and_final_conv_present=beginning_and_final_conv_present\n",
    "        \n",
    "      \n",
    "        if self.beginning_and_final_conv_present:\n",
    "             self.init_conv = CrossEmbedLayer(init_channels, dim_out = init_dim, \n",
    "                                         kernel_sizes = init_cross_embed_kernel_sizes, stride = 1) if init_cross_embed else nn.Conv1d(init_channels, init_dim, init_conv_kernel_size, padding = init_conv_kernel_size // 2)\n",
    "              \n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        # time conditioning\n",
    "\n",
    "        cond_dim = default(cond_dim, dim)\n",
    "        time_cond_dim = dim * 4 * (2 if lowres_cond else 1)\n",
    "\n",
    "        # embedding time for log(snr) noise from continuous version\n",
    "\n",
    "        sinu_pos_emb = LearnedSinusoidalPosEmb(learned_sinu_pos_emb_dim)\n",
    "        sinu_pos_emb_input_dim = learned_sinu_pos_emb_dim + 1\n",
    "\n",
    "        self.to_time_hiddens = nn.Sequential(\n",
    "            sinu_pos_emb,\n",
    "            nn.Linear(sinu_pos_emb_input_dim, time_cond_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.to_time_cond = nn.Sequential(\n",
    "            nn.Linear(time_cond_dim, time_cond_dim)\n",
    "        )\n",
    "\n",
    "        # project to time tokens as well as time hiddens\n",
    "\n",
    "        self.to_time_tokens = nn.Sequential(\n",
    "            nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n",
    "            Rearrange('b (r d) -> b r d', r = num_time_tokens)\n",
    "        )\n",
    "\n",
    "        # low res aug noise conditioning\n",
    "\n",
    "        self.lowres_cond = lowres_cond\n",
    "\n",
    "        if lowres_cond:\n",
    "            self.to_lowres_time_hiddens = nn.Sequential(\n",
    "                LearnedSinusoidalPosEmb(learned_sinu_pos_emb_dim),\n",
    "                nn.Linear(learned_sinu_pos_emb_dim + 1, time_cond_dim),\n",
    "                nn.SiLU()\n",
    "            )\n",
    "\n",
    "            self.to_lowres_time_cond = nn.Sequential(\n",
    "                nn.Linear(time_cond_dim, time_cond_dim)\n",
    "            )\n",
    "\n",
    "            self.to_lowres_time_tokens = nn.Sequential(\n",
    "                nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n",
    "                Rearrange('b (r d) -> b r d', r = num_time_tokens)\n",
    "            )\n",
    "\n",
    "        # normalizations\n",
    "\n",
    "        self.norm_cond = nn.LayerNorm(cond_dim)\n",
    "\n",
    "        # text encoding conditioning (optional)\n",
    "\n",
    "        self.text_to_cond = None\n",
    "\n",
    "        if cond_on_text: #only add linear lear if cond dim is not text emnd dim\n",
    "            assert exists(text_embed_dim), 'text_embed_dim must be given to the unet if cond_on_text is True'\n",
    "            if text_embed_dim != cond_dim:\n",
    "                self.text_to_cond = nn.Linear(text_embed_dim, cond_dim)\n",
    "                self.text_cond_linear=True\n",
    "                \n",
    "            else:\n",
    "                print (\"Text conditioning is equatl to cond_dim - no linear layer used\")\n",
    "                self.text_cond_linear=False\n",
    "                \n",
    "        # finer control over whether to condition on text encodings\n",
    "\n",
    "        self.cond_on_text = cond_on_text\n",
    "\n",
    "        # attention pooling\n",
    "\n",
    "        self.attn_pool = PerceiverResampler(dim = cond_dim, depth = 2, \n",
    "                                            dim_head = attn_dim_head, heads = attn_heads, \n",
    "                                            num_latents = attn_pool_num_latents, \n",
    "                                            cosine_sim_attn = cosine_sim_attn) if attn_pool_text else None\n",
    "\n",
    "        # for classifier free guidance\n",
    "\n",
    "        self.max_text_len = max_text_len\n",
    "\n",
    "        self.null_text_embed = nn.Parameter(torch.randn(1, max_text_len, cond_dim))\n",
    "        self.null_text_hidden = nn.Parameter(torch.randn(1, time_cond_dim))\n",
    "\n",
    "        # for non-attention based text conditioning at all points in the network where time is also conditioned\n",
    "\n",
    "        self.to_text_non_attn_cond = None\n",
    "\n",
    "        if cond_on_text:\n",
    "            self.to_text_non_attn_cond = nn.Sequential(\n",
    "                nn.LayerNorm(cond_dim),\n",
    "                nn.Linear(cond_dim, time_cond_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(time_cond_dim, time_cond_dim)\n",
    "            )\n",
    "\n",
    "        # attention related params\n",
    "\n",
    "        attn_kwargs = dict(heads = attn_heads, dim_head = attn_dim_head, cosine_sim_attn = cosine_sim_attn)\n",
    "\n",
    "        num_layers = len(in_out)\n",
    "\n",
    "        # resnet block klass\n",
    "\n",
    "        num_resnet_blocks = cast_tuple(num_resnet_blocks, num_layers)\n",
    "        resnet_groups = cast_tuple(resnet_groups, num_layers)\n",
    "\n",
    "        resnet_klass = partial(ResnetBlock, **attn_kwargs)\n",
    "\n",
    "        layer_attns = cast_tuple(layer_attns, num_layers)\n",
    "        layer_attns_depth = cast_tuple(layer_attns_depth, num_layers)\n",
    "        layer_cross_attns = cast_tuple(layer_cross_attns, num_layers)\n",
    "\n",
    "        use_linear_attn = cast_tuple(use_linear_attn, num_layers)\n",
    "        use_linear_cross_attn = cast_tuple(use_linear_cross_attn, num_layers)\n",
    "\n",
    "        assert all([layers == num_layers for layers in list(map(len, (resnet_groups, layer_attns, layer_cross_attns)))])\n",
    "\n",
    "        # downsample klass\n",
    "\n",
    "        downsample_klass = Downsample\n",
    "\n",
    "        if cross_embed_downsample:\n",
    "            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)\n",
    "\n",
    "        # initial resnet block (for memory efficient unet)\n",
    "\n",
    "        self.init_resnet_block = resnet_klass(init_dim, init_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[0], use_gca = use_global_context_attn) if memory_efficient else None\n",
    "\n",
    "        # scale for resnet skip connections\n",
    "\n",
    "        self.skip_connect_scale = 1. if not scale_skip_connection else (2 ** -0.5)\n",
    "\n",
    "        # layers\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        layer_params = [num_resnet_blocks, resnet_groups, layer_attns, layer_attns_depth, layer_cross_attns, use_linear_attn, use_linear_cross_attn]\n",
    "        reversed_layer_params = list(map(reversed, layer_params))\n",
    "\n",
    "        # downsampling layers\n",
    "\n",
    "        skip_connect_dims = [] # keep track of skip connection dimensions\n",
    "\n",
    "        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_attn_depth, layer_cross_attn, layer_use_linear_attn, layer_use_linear_cross_attn) in enumerate(zip(in_out, *layer_params)):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            layer_cond_dim = cond_dim if layer_cross_attn or layer_use_linear_cross_attn else None\n",
    "\n",
    "            if layer_attn:\n",
    "                transformer_block_klass = TransformerBlock\n",
    "            elif layer_use_linear_attn:\n",
    "                transformer_block_klass = LinearAttentionTransformerBlock\n",
    "            else:\n",
    "                transformer_block_klass = Identity\n",
    "\n",
    "            current_dim = dim_in\n",
    "\n",
    "            # whether to pre-downsample, from memory efficient unet\n",
    "\n",
    "            pre_downsample = None\n",
    "\n",
    "            if memory_efficient:\n",
    "                pre_downsample = downsample_klass(dim_in, dim_out)\n",
    "                current_dim = dim_out\n",
    "\n",
    "            skip_connect_dims.append(current_dim)\n",
    "\n",
    "            # whether to do post-downsample, for non-memory efficient unet\n",
    "\n",
    "            post_downsample = None\n",
    "            if not memory_efficient:\n",
    "                post_downsample = downsample_klass(current_dim, dim_out) if not is_last else Parallel(nn.Conv1d(dim_in, dim_out, 3, padding = 1), nn.Conv1d(dim_in, dim_out, 1))\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                pre_downsample,\n",
    "                resnet_klass(current_dim, current_dim, cond_dim = layer_cond_dim, linear_attn = layer_use_linear_cross_attn, time_cond_dim = time_cond_dim, groups = groups),\n",
    "                nn.ModuleList([ResnetBlock(current_dim, current_dim, time_cond_dim = time_cond_dim, groups = groups, use_gca = use_global_context_attn) for _ in range(layer_num_resnet_blocks)]),\n",
    "                transformer_block_klass(dim = current_dim, depth = layer_attn_depth, ff_mult = ff_mult, context_dim = cond_dim, **attn_kwargs),\n",
    "                post_downsample\n",
    "            ]))\n",
    "\n",
    "        # middle layers\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "\n",
    "        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n",
    "        self.mid_attn = EinopsToAndFrom('b c h', 'b h c', Residual(Attention(mid_dim, **attn_kwargs))) if attend_at_middle else None\n",
    "        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n",
    "\n",
    "        # upsample klass\n",
    "\n",
    "        upsample_klass = Upsample if not pixel_shuffle_upsample else PixelShuffleUpsample\n",
    "\n",
    "        # upsampling layers\n",
    "\n",
    "        upsample_fmap_dims = []\n",
    "\n",
    "        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_attn_depth, layer_cross_attn, layer_use_linear_attn, layer_use_linear_cross_attn) in enumerate(zip(reversed(in_out), *reversed_layer_params)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "\n",
    "            layer_cond_dim = cond_dim if layer_cross_attn or layer_use_linear_cross_attn else None\n",
    "\n",
    "            if layer_attn:\n",
    "                transformer_block_klass = TransformerBlock\n",
    "            elif layer_use_linear_attn:\n",
    "                transformer_block_klass = LinearAttentionTransformerBlock\n",
    "            else:\n",
    "                transformer_block_klass = Identity\n",
    "\n",
    "            skip_connect_dim = skip_connect_dims.pop()\n",
    "\n",
    "            upsample_fmap_dims.append(dim_out)\n",
    "\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                resnet_klass(dim_out + skip_connect_dim, dim_out, cond_dim = layer_cond_dim, linear_attn = layer_use_linear_cross_attn, time_cond_dim = time_cond_dim, groups = groups),\n",
    "                nn.ModuleList([ResnetBlock(dim_out + skip_connect_dim, dim_out, time_cond_dim = time_cond_dim, groups = groups, use_gca = use_global_context_attn) for _ in range(layer_num_resnet_blocks)]),\n",
    "                transformer_block_klass(dim = dim_out, depth = layer_attn_depth, ff_mult = ff_mult, context_dim = cond_dim, **attn_kwargs),\n",
    "                upsample_klass(dim_out, dim_in) if not is_last or memory_efficient else Identity()\n",
    "            ]))\n",
    "\n",
    "        # whether to combine feature maps from all upsample blocks before final resnet block out\n",
    "\n",
    "        self.upsample_combiner = UpsampleCombiner(\n",
    "            dim = dim,\n",
    "            enabled = combine_upsample_fmaps,\n",
    "            dim_ins = upsample_fmap_dims,\n",
    "            dim_outs = dim\n",
    "        )\n",
    "\n",
    "        # whether to do a final residual from initial conv to the final resnet block out\n",
    "\n",
    "        self.init_conv_to_final_conv_residual = init_conv_to_final_conv_residual\n",
    "        final_conv_dim = self.upsample_combiner.dim_out + (dim if init_conv_to_final_conv_residual else 0)\n",
    "\n",
    "        # final optional resnet block and convolution out\n",
    "\n",
    "        self.final_res_block = ResnetBlock(final_conv_dim, dim, time_cond_dim = time_cond_dim, groups = resnet_groups[0], use_gca = True) if final_resnet_block else None\n",
    "\n",
    "        final_conv_dim_in = dim if final_resnet_block else final_conv_dim\n",
    "        final_conv_dim_in += (channels if lowres_cond else 0)\n",
    "\n",
    "        if self.beginning_and_final_conv_present:\n",
    "            print (final_conv_dim_in, self.channels_out)\n",
    "            self.final_conv = nn.Conv1d(final_conv_dim_in, self.channels_out, final_conv_kernel_size, padding = final_conv_kernel_size // 2)\n",
    "\n",
    "        if self.beginning_and_final_conv_present:\n",
    "            zero_init_(self.final_conv)\n",
    "\n",
    "    # if the current settings for the unet are not correct\n",
    "    # for cascading DDPM, then reinit the unet with the right settings\n",
    "    def cast_model_parameters(\n",
    "        self,\n",
    "        *,\n",
    "        lowres_cond,\n",
    "        text_embed_dim,\n",
    "        channels,\n",
    "        channels_out,\n",
    "        cond_on_text\n",
    "    ):\n",
    "        if lowres_cond == self.lowres_cond and \\\n",
    "            channels == self.channels and \\\n",
    "            cond_on_text == self.cond_on_text and \\\n",
    "            text_embed_dim == self._locals['text_embed_dim'] and \\\n",
    "            channels_out == self.channels_out:\n",
    "            return self\n",
    "\n",
    "        updated_kwargs = dict(\n",
    "            lowres_cond = lowres_cond,\n",
    "            text_embed_dim = text_embed_dim,\n",
    "            channels = channels,\n",
    "            channels_out = channels_out,\n",
    "            cond_on_text = cond_on_text\n",
    "        )\n",
    "\n",
    "        return self.__class__(**{**self._locals, **updated_kwargs})\n",
    "\n",
    "    # methods for returning the full unet config as well as its parameter state\n",
    "\n",
    "    def to_config_and_state_dict(self):\n",
    "        return self._locals, self.state_dict()\n",
    "\n",
    "    # class method for rehydrating the unet from its config and state dict\n",
    "\n",
    "    @classmethod\n",
    "    def from_config_and_state_dict(klass, config, state_dict):\n",
    "        unet = klass(**config)\n",
    "        unet.load_state_dict(state_dict)\n",
    "        return unet\n",
    "\n",
    "    # methods for persisting unet to disk\n",
    "\n",
    "    def persist_to_file(self, path):\n",
    "        path = Path(path)\n",
    "        path.parents[0].mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "        config, state_dict = self.to_config_and_state_dict()\n",
    "        pkg = dict(config = config, state_dict = state_dict)\n",
    "        torch.save(pkg, str(path))\n",
    "\n",
    "    # class method for rehydrating the unet from file saved with `persist_to_file`\n",
    "\n",
    "    @classmethod\n",
    "    def hydrate_from_file(klass, path):\n",
    "        path = Path(path)\n",
    "        assert path.exists()\n",
    "        pkg = torch.load(str(path))\n",
    "\n",
    "        assert 'config' in pkg and 'state_dict' in pkg\n",
    "        config, state_dict = pkg['config'], pkg['state_dict']\n",
    "\n",
    "        return Unet.from_config_and_state_dict(config, state_dict)\n",
    "\n",
    "    # forward with classifier free guidance\n",
    "\n",
    "    def forward_with_cond_scale(\n",
    "        self,\n",
    "        *args,\n",
    "        cond_scale = 1.,\n",
    "        **kwargs\n",
    "    ):\n",
    "        logits = self.forward(*args, **kwargs)\n",
    "\n",
    "        if cond_scale == 1:\n",
    "            return logits\n",
    "\n",
    "        null_logits = self.forward(*args, cond_drop_prob = 1., **kwargs)\n",
    "        return null_logits + (logits - null_logits) * cond_scale\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        time,\n",
    "        *,\n",
    "        lowres_cond_img = None,\n",
    "        lowres_noise_times = None,\n",
    "        text_embeds = None,\n",
    "        text_mask = None,\n",
    "        cond_images = None,\n",
    "        self_cond = None,\n",
    "        cond_drop_prob = 0.\n",
    "    ):\n",
    "        batch_size, device = x.shape[0], x.device\n",
    "         # condition on self\n",
    "\n",
    "        if self.self_cond:\n",
    "            self_cond = default(self_cond, lambda: torch.zeros_like(x))\n",
    "            x = torch.cat((x, self_cond), dim = 1)\n",
    "\n",
    "        # add low resolution conditioning, if present\n",
    "\n",
    "        assert not (self.lowres_cond and not exists(lowres_cond_img)), 'low resolution conditioning image must be present'\n",
    "        assert not (self.lowres_cond and not exists(lowres_noise_times)), 'low resolution conditioning noise time must be present'\n",
    "\n",
    "        if exists(lowres_cond_img):\n",
    "            x = torch.cat((x, lowres_cond_img), dim = 1)\n",
    "\n",
    "        # condition on input image\n",
    "\n",
    "        assert not (self.has_cond_image ^ exists(cond_images)), 'you either requested to condition on an image on the unet, but the conditioning image is not supplied, or vice versa'\n",
    "\n",
    "        if exists(cond_images):\n",
    "            assert cond_images.shape[1] == self.cond_images_channels, 'the number of channels on the conditioning image you are passing in does not match what you specified on initialiation of the unet'\n",
    "            cond_images = resize_image_to(cond_images, x.shape[-1])\n",
    "            \n",
    "            x = torch.cat((cond_images.to(device), x.to(device)), dim = 1)\n",
    "\n",
    "        # initial convolution\n",
    "      \n",
    "        if self.beginning_and_final_conv_present:\n",
    "            x = self.init_conv(x)  \n",
    "\n",
    "        # init conv residual\n",
    "\n",
    "        if self.init_conv_to_final_conv_residual:\n",
    "            init_conv_residual = x.clone()\n",
    "\n",
    "        # time conditioning\n",
    "\n",
    "        time_hiddens = self.to_time_hiddens(time)\n",
    "\n",
    "        # derive time tokens\n",
    "\n",
    "        time_tokens = self.to_time_tokens(time_hiddens)\n",
    "        t = self.to_time_cond(time_hiddens)\n",
    "\n",
    "        # add lowres time conditioning to time hiddens\n",
    "        # and add lowres time tokens along sequence dimension for attention\n",
    "\n",
    "        if self.lowres_cond:\n",
    "            lowres_time_hiddens = self.to_lowres_time_hiddens(lowres_noise_times)\n",
    "            lowres_time_tokens = self.to_lowres_time_tokens(lowres_time_hiddens)\n",
    "            lowres_t = self.to_lowres_time_cond(lowres_time_hiddens)\n",
    "\n",
    "            t = t + lowres_t\n",
    "            \n",
    "            time_tokens = torch.cat((time_tokens, lowres_time_tokens), dim = -2)\n",
    "\n",
    "        # text conditioning\n",
    "\n",
    "        text_tokens = None\n",
    "\n",
    "        if exists(text_embeds) and self.cond_on_text:\n",
    "\n",
    "            # conditional dropout\n",
    "\n",
    "            text_keep_mask = prob_mask_like((batch_size,), 1 - cond_drop_prob, device = device)\n",
    "            \n",
    "            text_keep_mask_embed = rearrange(text_keep_mask, 'b -> b 1 1')\n",
    "            text_keep_mask_hidden = rearrange(text_keep_mask, 'b -> b 1')\n",
    "\n",
    "            # calculate text embeds\n",
    "             \n",
    "            if self.text_cond_linear:\n",
    "                text_tokens = self.text_to_cond(text_embeds)\n",
    "            else:\n",
    "                text_tokens=text_embeds\n",
    "\n",
    "            text_tokens = text_tokens[:, :self.max_text_len]\n",
    "            \n",
    "            if exists(text_mask):\n",
    "                text_mask = text_mask[:, :self.max_text_len]\n",
    "\n",
    "            text_tokens_len = text_tokens.shape[1]\n",
    "            remainder = self.max_text_len - text_tokens_len\n",
    "             \n",
    "            if remainder > 0:\n",
    "                 \n",
    "                text_tokens = F.pad(text_tokens, (0, 0, 0, remainder))\n",
    "\n",
    "            if exists(text_mask):\n",
    "                if remainder > 0:\n",
    "                    text_mask = F.pad(text_mask, (0, remainder), value = False)\n",
    "\n",
    "                \n",
    "                text_mask = rearrange(text_mask, 'b n -> b n 1')\n",
    "                text_keep_mask_embed = text_mask & text_keep_mask_embed\n",
    "            \n",
    "            null_text_embed = self.null_text_embed.to(text_tokens.dtype) # for some reason pytorch AMP not working\n",
    "            text_tokens = torch.where(\n",
    "                text_keep_mask_embed,\n",
    "                text_tokens,\n",
    "                null_text_embed\n",
    "            )\n",
    "            \n",
    "            if exists(self.attn_pool):\n",
    "                text_tokens = self.attn_pool(text_tokens)\n",
    "\n",
    "            # extra non-attention conditioning by projecting and then summing text embeddings to time\n",
    "            # termed as text hiddens\n",
    "            \n",
    "            mean_pooled_text_tokens = text_tokens.mean(dim = -2)\n",
    "\n",
    "            text_hiddens = self.to_text_non_attn_cond(mean_pooled_text_tokens)\n",
    "\n",
    "            null_text_hidden = self.null_text_hidden.to(t.dtype)\n",
    "\n",
    "            text_hiddens = torch.where(\n",
    "                text_keep_mask_hidden,\n",
    "                text_hiddens,\n",
    "                null_text_hidden\n",
    "            )\n",
    "\n",
    "            t = t + text_hiddens\n",
    "\n",
    "        # main conditioning tokens (c)\n",
    "        \n",
    "        c = time_tokens if not exists(text_tokens) else torch.cat((time_tokens, text_tokens), dim = -2)\n",
    "        \n",
    "        # normalize conditioning tokens\n",
    "\n",
    "        c = self.norm_cond(c)\n",
    "        \n",
    "        # initial resnet block (for memory efficient unet)\n",
    "\n",
    "        if exists(self.init_resnet_block):\n",
    "            x = self.init_resnet_block(x, t)\n",
    "        \n",
    "        # go through the layers of the unet, down and up\n",
    "\n",
    "        hiddens = []\n",
    "\n",
    "        for pre_downsample, init_block, resnet_blocks, attn_block, post_downsample in self.downs:\n",
    "            if exists(pre_downsample):\n",
    "                x = pre_downsample(x)\n",
    "            \n",
    "            x = init_block(x, t, c)\n",
    "             \n",
    "            for resnet_block in resnet_blocks:\n",
    "                x = resnet_block(x, t)\n",
    "                hiddens.append(x)\n",
    "            \n",
    "            \n",
    "            x = attn_block(x, c)\n",
    "            \n",
    "            hiddens.append(x)\n",
    "\n",
    "            if exists(post_downsample):\n",
    "                \n",
    "                x = post_downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t, c)\n",
    "        \n",
    "        if exists(self.mid_attn):\n",
    "            x = self.mid_attn(x)\n",
    "\n",
    "        x = self.mid_block2(x, t, c)\n",
    "        \n",
    "        add_skip_connection = lambda x: torch.cat((x, hiddens.pop() * self.skip_connect_scale), dim = 1)\n",
    "\n",
    "        up_hiddens = []\n",
    "        \n",
    "        for init_block, resnet_blocks, attn_block, upsample in self.ups:\n",
    "            x = add_skip_connection(x)\n",
    "            x = init_block(x, t, c)\n",
    "            \n",
    "            for resnet_block in resnet_blocks:\n",
    "                x = add_skip_connection(x)\n",
    "                x = resnet_block(x, t)\n",
    "\n",
    "            x = attn_block(x, c)\n",
    "            up_hiddens.append(x.contiguous())\n",
    "            x = upsample(x)\n",
    "\n",
    "        # whether to combine all feature maps from upsample blocks\n",
    "\n",
    "        x = self.upsample_combiner(x, up_hiddens)\n",
    "\n",
    "        # final top-most residual if needed\n",
    "\n",
    "        if self.init_conv_to_final_conv_residual:\n",
    "            x = torch.cat((x, init_conv_residual), dim = 1)\n",
    "\n",
    "        if exists(self.final_res_block):\n",
    "            x = self.final_res_block(x, t)\n",
    "\n",
    "        if exists(lowres_cond_img):\n",
    "            x = torch.cat((x, lowres_cond_img), dim = 1)\n",
    "            \n",
    "        if self.beginning_and_final_conv_present:\n",
    "            x=self.final_conv(x) \n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "694caa53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "## null unets \n",
    "########################################################\n",
    "\n",
    "class NullUnet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.lowres_cond = False\n",
    "        self.dummy_parameter = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def cast_model_parameters(self, *args, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return x\n",
    "    \n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.lowres_cond = False\n",
    "        self.dummy_parameter = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def cast_model_parameters(self, *args, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5fdcad64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########################################################\n",
    "## Elucidated denoising model \n",
    "## After: Tero Karras and Miika Aittala and Timo Aila and Samuli Laine, \n",
    "##        Elucidating the Design Space of Diffusion-Based Generative Models\n",
    "##        https://arxiv.org/abs/2206.00364, 2022\n",
    "########################################################\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "Hparams_fields = [\n",
    "    'num_sample_steps',\n",
    "    'sigma_min',\n",
    "    'sigma_max',\n",
    "    'sigma_data',\n",
    "    'rho',\n",
    "    'P_mean',\n",
    "    'P_std',\n",
    "    'S_churn',\n",
    "    'S_tmin',\n",
    "    'S_tmax',\n",
    "    'S_noise'\n",
    "]\n",
    "\n",
    "Hparams = namedtuple('Hparams', Hparams_fields)\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def log(t, eps = 1e-20):\n",
    "    return torch.log(t.clamp(min = eps))\n",
    "\n",
    "# main class\n",
    "\n",
    "class ElucidatedImagen(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unets,\n",
    "        *,\n",
    "        image_sizes,                                # for cascading ddpm, image size at each stage\n",
    "        text_encoder_name = '',\n",
    "        text_embed_dim = None,\n",
    "        channels = 3,\n",
    "        channels_out=3,\n",
    "        cond_drop_prob = 0.1,\n",
    "        random_crop_sizes = None,\n",
    "        lowres_sample_noise_level = 0.2,            # in the paper, they present a new trick where they noise the lowres conditioning image, and at sample time, fix it to a certain level (0.1 or 0.3) - the unets are also made to be conditioned on this noise level\n",
    "        per_sample_random_aug_noise_level = False,  # unclear when conditioning on augmentation noise level, whether each batch element receives a random aug noise value - turning off due to @marunine's find\n",
    "        condition_on_text = True,\n",
    "        auto_normalize_img = True,                  # whether to take care of normalizing the image from [0, 1] to [-1, 1] and back automatically - you can turn this off if you want to pass in the [-1, 1] ranged image yourself from the dataloader\n",
    "        dynamic_thresholding = True,\n",
    "        dynamic_thresholding_percentile = 0.95,     # unsure what this was based on perusal of paper\n",
    "        only_train_unet_number = None,\n",
    "        lowres_noise_schedule = 'linear',\n",
    "        num_sample_steps = 32,                      # number of sampling steps\n",
    "        sigma_min = 0.002,                          # min noise level\n",
    "        sigma_max = 80,                             # max noise level\n",
    "        sigma_data = 0.5,                           # standard deviation of data distribution\n",
    "        rho = 7,                                    # controls the sampling schedule\n",
    "        P_mean = -1.2,                              # mean of log-normal distribution from which noise is drawn for training\n",
    "        P_std = 1.2,                                # standard deviation of log-normal distribution from which noise is drawn for training\n",
    "        S_churn = 80,                               # parameters for stochastic sampling - depends on dataset, Table 5 in apper\n",
    "        S_tmin = 0.05,\n",
    "        S_tmax = 50,\n",
    "        S_noise = 1.003,\n",
    "        \n",
    "        loss_type=0, #0=MSE,  \n",
    "        categorical_loss_ignore=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.only_train_unet_number = only_train_unet_number\n",
    "\n",
    "        self.condition_on_text = condition_on_text\n",
    "        self.unconditional = not condition_on_text\n",
    "        self.loss_type=loss_type\n",
    "        if self.loss_type>0:\n",
    "            self.categorical_loss=True\n",
    "            self.m = nn.LogSoftmax(dim=1) #used for some loss functins\n",
    "        else:\n",
    "            self.categorical_loss=False\n",
    "            \n",
    "        \n",
    "        self.categorical_loss_ignore=categorical_loss_ignore\n",
    "        \n",
    "        # channels\n",
    "\n",
    "        self.channels = channels\n",
    "        self.channels_out = channels_out\n",
    "\n",
    "        unets = cast_tuple(unets)\n",
    "        num_unets = len(unets)\n",
    "\n",
    "        # randomly cropping for upsampler training\n",
    "\n",
    "        self.random_crop_sizes = cast_tuple(random_crop_sizes, num_unets)\n",
    "        assert not exists(first(self.random_crop_sizes)), 'you should not need to randomly crop image during training for base unet, only for upsamplers - so pass in `random_crop_sizes = (None, 128, 256)` as example'\n",
    "\n",
    "        # lowres augmentation noise schedule\n",
    "\n",
    "        self.lowres_noise_schedule = GaussianDiffusionContinuousTimes(noise_schedule = lowres_noise_schedule)\n",
    "\n",
    "        # get text encoder\n",
    "\n",
    "        self.text_embed_dim =text_embed_dim\n",
    "    \n",
    "        # construct unets\n",
    "\n",
    "        self.unets = nn.ModuleList([])\n",
    "        self.unet_being_trained_index = -1 # keeps track of which unet is being trained at the moment\n",
    "\n",
    "        print (f\"Channels in={self.channels}, channels out={self.channels_out}\")\n",
    "        for ind, one_unet in enumerate(unets):\n",
    "             \n",
    "            assert isinstance(one_unet, ( OneD_Unet, NullUnet))\n",
    "            is_first = ind == 0\n",
    "\n",
    "            one_unet = one_unet.cast_model_parameters(\n",
    "                lowres_cond = not is_first,\n",
    "                cond_on_text = self.condition_on_text,\n",
    "                text_embed_dim = self.text_embed_dim if self.condition_on_text else None,\n",
    "                channels = self.channels,\n",
    "                #channels_out = self.channels\n",
    "                channels_out = self.channels_out\n",
    "            )\n",
    "\n",
    "            self.unets.append(one_unet)\n",
    "\n",
    "        # determine whether we are training on images or video\n",
    "\n",
    "        is_video = False # \n",
    "        self.is_video = is_video\n",
    "\n",
    "        self.right_pad_dims_to_datatype = partial(rearrange, pattern = ('b -> b 1 1' if not is_video else 'b -> b 1 1 1'))\n",
    "        self.resize_to = resize_video_to if is_video else resize_image_to\n",
    "\n",
    "        \n",
    "        self.image_sizes = image_sizes\n",
    "        assert num_unets == len(self.image_sizes), f'you did not supply the correct number of u-nets ({len(self.unets)}) for resolutions {self.image_sizes}'\n",
    "\n",
    "        self.sample_channels = cast_tuple(self.channels, num_unets)\n",
    "\n",
    "        lowres_conditions = tuple(map(lambda t: t.lowres_cond, self.unets))\n",
    "        assert lowres_conditions == (False, *((True,) * (num_unets - 1))), 'the first unet must be unconditioned (by low resolution image), and the rest of the unets must have `lowres_cond` set to True'\n",
    "\n",
    "        self.lowres_sample_noise_level = lowres_sample_noise_level\n",
    "        self.per_sample_random_aug_noise_level = per_sample_random_aug_noise_level\n",
    "\n",
    "        # classifier free guidance\n",
    "\n",
    "        self.cond_drop_prob = cond_drop_prob\n",
    "        self.can_classifier_guidance = cond_drop_prob > 0.\n",
    "\n",
    "        # normalize and unnormalize image functions\n",
    "\n",
    "        self.normalize_img = normalize_neg_one_to_one if auto_normalize_img else identity\n",
    "        self.unnormalize_img = unnormalize_zero_to_one if auto_normalize_img else identity\n",
    "        self.input_image_range = (0. if auto_normalize_img else -1., 1.)\n",
    "\n",
    "        # dynamic thresholding\n",
    "\n",
    "        self.dynamic_thresholding = cast_tuple(dynamic_thresholding, num_unets)\n",
    "        self.dynamic_thresholding_percentile = dynamic_thresholding_percentile\n",
    "\n",
    "        # elucidating parameters\n",
    "\n",
    "        hparams = [\n",
    "            num_sample_steps,\n",
    "            sigma_min,\n",
    "            sigma_max,\n",
    "            sigma_data,\n",
    "            rho,\n",
    "            P_mean,\n",
    "            P_std,\n",
    "            S_churn,\n",
    "            S_tmin,\n",
    "            S_tmax,\n",
    "            S_noise,\n",
    "        ]\n",
    "\n",
    "        hparams = [cast_tuple(hp, num_unets) for hp in hparams]\n",
    "        self.hparams = [Hparams(*unet_hp) for unet_hp in zip(*hparams)]\n",
    "\n",
    "        # one temp parameter for keeping track of device\n",
    "\n",
    "        self.register_buffer('_temp', torch.tensor([0.]).to(device), persistent = False)\n",
    "\n",
    "        # default to device of unets passed in\n",
    "\n",
    "        self.to(next(self.unets.parameters()).device)\n",
    "        \n",
    "        print (\"Device used in ImagenEluc: \", self.device)\n",
    "\n",
    "    def force_unconditional_(self):\n",
    "        self.condition_on_text = False\n",
    "        self.unconditional = True\n",
    "\n",
    "        for unet in self.unets:\n",
    "            unet.cond_on_text = False\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        #return self._temp.device\n",
    "        return (device)\n",
    "\n",
    "    def get_unet(self, unet_number):\n",
    "        assert 0 < unet_number <= len(self.unets)\n",
    "        index = unet_number - 1\n",
    "\n",
    "        if isinstance(self.unets, nn.ModuleList):\n",
    "            unets_list = [unet for unet in self.unets]\n",
    "            delattr(self, 'unets')\n",
    "            self.unets = unets_list\n",
    "\n",
    "        if index != self.unet_being_trained_index:\n",
    "            for unet_index, unet in enumerate(self.unets):\n",
    "                unet.to(self.device if unet_index == index else 'cpu')\n",
    "\n",
    "        self.unet_being_trained_index = index\n",
    "        return self.unets[index]\n",
    "\n",
    "    def reset_unets_all_one_device(self, device = None):\n",
    "        device = default(device, self.device)\n",
    "        \n",
    "        self.unets = nn.ModuleList([*self.unets])\n",
    "        self.unets.to(device)\n",
    "\n",
    "        self.unet_being_trained_index = -1\n",
    "\n",
    "    @contextmanager\n",
    "    def one_unet_in_gpu(self, unet_number = None, unet = None):\n",
    "        assert exists(unet_number) ^ exists(unet)\n",
    "\n",
    "        if exists(unet_number):\n",
    "            unet = self.unets[unet_number - 1]\n",
    "\n",
    "        devices = [module_device(unet) for unet in self.unets]\n",
    "        self.unets.cpu()\n",
    "        unet.to(self.device)\n",
    "        \n",
    "        yield\n",
    "\n",
    "        for unet, device in zip(self.unets, devices):\n",
    "            unet.to(device)\n",
    "\n",
    "    # overriding state dict functions\n",
    "\n",
    "    def state_dict(self, *args, **kwargs):\n",
    "        self.reset_unets_all_one_device()\n",
    "        return super().state_dict(*args, **kwargs)\n",
    "\n",
    "    def load_state_dict(self, *args, **kwargs):\n",
    "        self.reset_unets_all_one_device()\n",
    "        return super().load_state_dict(*args, **kwargs)\n",
    "\n",
    "    # dynamic thresholding\n",
    "\n",
    "    def threshold_x_start(self, x_start, dynamic_threshold = True):\n",
    "        if not dynamic_threshold:\n",
    "            return x_start.clamp(-1., 1.)\n",
    "\n",
    "        s = torch.quantile(\n",
    "            rearrange(x_start, 'b ... -> b (...)').abs(),\n",
    "            self.dynamic_thresholding_percentile,\n",
    "            dim = -1\n",
    "        )\n",
    "\n",
    "        s.clamp_(min = 1.)\n",
    "        s = right_pad_dims_to(x_start, s)\n",
    "        return x_start.clamp(-s, s) / s\n",
    "\n",
    "    # derived preconditioning params - Table 1\n",
    "\n",
    "    def c_skip(self, sigma_data, sigma):\n",
    "        return (sigma_data ** 2) / (sigma ** 2 + sigma_data ** 2)\n",
    "\n",
    "    def c_out(self, sigma_data, sigma):\n",
    "        return sigma * sigma_data * (sigma_data ** 2 + sigma ** 2) ** -0.5\n",
    "\n",
    "    def c_in(self, sigma_data, sigma):\n",
    "        return 1 * (sigma ** 2 + sigma_data ** 2) ** -0.5\n",
    "\n",
    "    def c_noise(self, sigma):\n",
    "        return log(sigma) * 0.25\n",
    "\n",
    "   # preconditioned network output\n",
    "    # equation (7) in the paper\n",
    "\n",
    "    def preconditioned_network_forward(\n",
    "        self,\n",
    "        unet_forward,\n",
    "        noised_images,\n",
    "        sigma,\n",
    "        *,\n",
    "        sigma_data,\n",
    "        clamp = False,\n",
    "        dynamic_threshold = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        batch, device = noised_images.shape[0], noised_images.device\n",
    "        \n",
    "        if isinstance(sigma, float):\n",
    "            sigma = torch.full((batch,), sigma, device = device)\n",
    "\n",
    "        padded_sigma = self.right_pad_dims_to_datatype(sigma)\n",
    "\n",
    "        net_out = unet_forward(\n",
    "            self.c_in(sigma_data, padded_sigma) * noised_images,\n",
    "            self.c_noise(sigma),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        out = self.c_skip(sigma_data, padded_sigma) * noised_images +  self.c_out(sigma_data, padded_sigma) * net_out\n",
    "\n",
    "        if not clamp:\n",
    "            return out\n",
    "\n",
    "        return self.threshold_x_start(out, dynamic_threshold)\n",
    "\n",
    "    # sampling\n",
    "\n",
    "    # sample schedule\n",
    "    # equation (5) in the paper\n",
    "\n",
    "    def sample_schedule(\n",
    "        self,\n",
    "        num_sample_steps,\n",
    "        rho,\n",
    "        sigma_min,\n",
    "        sigma_max\n",
    "    ):\n",
    "        N = num_sample_steps\n",
    "        inv_rho = 1 / rho\n",
    "\n",
    "        steps = torch.arange(num_sample_steps, device = self.device, dtype = torch.float32)\n",
    "        sigmas = (sigma_max ** inv_rho + steps / (N - 1) * (sigma_min ** inv_rho - sigma_max ** inv_rho)) ** rho\n",
    "\n",
    "        sigmas = F.pad(sigmas, (0, 1), value = 0.) # last step is sigma value of 0.\n",
    "        return sigmas\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def one_unet_sample(\n",
    "        self,\n",
    "        unet,\n",
    "        shape,\n",
    "        *,\n",
    "        unet_number,\n",
    "        clamp = True,\n",
    "        dynamic_threshold = True,\n",
    "        cond_scale = 1.,\n",
    "        use_tqdm = True,\n",
    "        inpaint_images = None,\n",
    "        inpaint_masks = None,\n",
    "        inpaint_resample_times = 5,\n",
    "        init_images = None,\n",
    "        skip_steps = None,\n",
    "        sigma_min = None,\n",
    "        sigma_max = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # get specific sampling hyperparameters for unet\n",
    "\n",
    "        hp = self.hparams[unet_number - 1]\n",
    "\n",
    "        sigma_min = default(sigma_min, hp.sigma_min)\n",
    "        sigma_max = default(sigma_max, hp.sigma_max)\n",
    "\n",
    "        # get the schedule, which is returned as (sigma, gamma) tuple, and pair up with the next sigma and gamma\n",
    "\n",
    "        sigmas = self.sample_schedule(hp.num_sample_steps, hp.rho, sigma_min, sigma_max)\n",
    "\n",
    "        gammas = torch.where(\n",
    "            (sigmas >= hp.S_tmin) & (sigmas <= hp.S_tmax),\n",
    "            min(hp.S_churn / hp.num_sample_steps, sqrt(2) - 1),\n",
    "            0.\n",
    "        )\n",
    "\n",
    "        sigmas_and_gammas = list(zip(sigmas[:-1], sigmas[1:], gammas[:-1]))\n",
    "\n",
    "        # images is noise at the beginning\n",
    "\n",
    "        init_sigma = sigmas[0]\n",
    "\n",
    "        images = init_sigma * torch.randn(shape, device = self.device)\n",
    "\n",
    "        # initializing with an image\n",
    "\n",
    "        if exists(init_images):\n",
    "            images += init_images\n",
    "\n",
    "        # keeping track of x0, for self conditioning if needed\n",
    "\n",
    "        x_start = None\n",
    "\n",
    "        # prepare inpainting images and mask\n",
    "\n",
    "        has_inpainting = exists(inpaint_images) and exists(inpaint_masks)\n",
    "        resample_times = inpaint_resample_times if has_inpainting else 1\n",
    "\n",
    "        if has_inpainting:\n",
    "            inpaint_images = self.normalize_img(inpaint_images)\n",
    "            inpaint_images = self.resize_to(inpaint_images, shape[-1])\n",
    "            inpaint_masks = self.resize_to(rearrange(inpaint_masks, 'b ... -> b 1 ...').float(), shape[-1]).bool()\n",
    "\n",
    "        # unet kwargs\n",
    "\n",
    "        unet_kwargs = dict(\n",
    "            sigma_data = hp.sigma_data,\n",
    "            clamp = clamp,\n",
    "            dynamic_threshold = dynamic_threshold,\n",
    "            cond_scale = cond_scale,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # gradually denoise\n",
    "\n",
    "        initial_step = default(skip_steps, 0)\n",
    "        sigmas_and_gammas = sigmas_and_gammas[initial_step:]\n",
    "\n",
    "        total_steps = len(sigmas_and_gammas)\n",
    "\n",
    "        for ind, (sigma, sigma_next, gamma) in tqdm(enumerate(sigmas_and_gammas), total = total_steps, desc = 'sampling time step', disable = not use_tqdm):\n",
    "            is_last_timestep = ind == (total_steps - 1)\n",
    "\n",
    "            sigma, sigma_next, gamma = map(lambda t: t.item(), (sigma, sigma_next, gamma))\n",
    "\n",
    "            for r in reversed(range(resample_times)):\n",
    "                is_last_resample_step = r == 0\n",
    "\n",
    "                eps = hp.S_noise * torch.randn(shape, device = self.device) # stochastic sampling\n",
    "\n",
    "                sigma_hat = sigma + gamma * sigma\n",
    "                added_noise = sqrt(sigma_hat ** 2 - sigma ** 2) * eps\n",
    "\n",
    "                images_hat = images + added_noise\n",
    "\n",
    "                self_cond = x_start if unet.self_cond else None\n",
    "\n",
    "                if has_inpainting:\n",
    "                    images_hat = images_hat * ~inpaint_masks + (inpaint_images + added_noise) * inpaint_masks\n",
    "\n",
    "                model_output = self.preconditioned_network_forward(\n",
    "                    unet.forward_with_cond_scale,\n",
    "                    images_hat,\n",
    "                    sigma_hat,\n",
    "                    self_cond = self_cond,\n",
    "                    **unet_kwargs\n",
    "                )\n",
    "                \n",
    "                denoised_over_sigma = (images_hat - model_output) / sigma_hat\n",
    "\n",
    "                images_next = images_hat + (sigma_next - sigma_hat) * denoised_over_sigma\n",
    "\n",
    "                # second order correction, if not the last timestep\n",
    "\n",
    "                if sigma_next != 0:\n",
    "                    self_cond = model_output if unet.self_cond else None\n",
    "\n",
    "                    model_output_next = self.preconditioned_network_forward(\n",
    "                        unet.forward_with_cond_scale,\n",
    "                        images_next,\n",
    "                        sigma_next,\n",
    "                        self_cond = self_cond,\n",
    "                        **unet_kwargs\n",
    "                    )\n",
    "                  \n",
    "                    denoised_prime_over_sigma = (images_next - model_output_next) / sigma_next\n",
    "                    images_next = images_hat + 0.5 * (sigma_next - sigma_hat) * (denoised_over_sigma + denoised_prime_over_sigma)\n",
    "\n",
    "                images = images_next\n",
    "\n",
    "                if has_inpainting and not (is_last_resample_step or is_last_timestep):\n",
    "                    # renoise in repaint and then resample\n",
    "                    repaint_noise = torch.randn(shape, device = self.device)\n",
    "                    images = images + (sigma - sigma_next) * repaint_noise\n",
    "\n",
    "                x_start = model_output  # save model output for self conditioning\n",
    "            \n",
    "\n",
    "        if has_inpainting:\n",
    "            images = images * ~inpaint_masks + inpaint_images * inpaint_masks\n",
    "\n",
    "        return  images\n",
    "\n",
    "    @torch.no_grad()\n",
    "    @eval_decorator\n",
    "    def sample(\n",
    "        self,\n",
    "        texts: List[str] = None,\n",
    "        text_masks = None,\n",
    "        text_embeds = None,\n",
    "        cond_images = None,\n",
    "        inpaint_images = None,\n",
    "        inpaint_masks = None,\n",
    "        inpaint_resample_times = 5,\n",
    "        init_images = None,\n",
    "        skip_steps = None,\n",
    "        sigma_min = None,\n",
    "        sigma_max = None,\n",
    "        video_frames = None,\n",
    "        batch_size = 1,\n",
    "        cond_scale = 1.,\n",
    "        lowres_sample_noise_level = None,\n",
    "        start_at_unet_number = 1,\n",
    "        start_image_or_video = None,\n",
    "        stop_at_unet_number = None,\n",
    "        return_all_unet_outputs = False,\n",
    "        return_pil_images = False,\n",
    "        use_tqdm = True,\n",
    "        device = None,\n",
    "        \n",
    "    ):\n",
    "\n",
    "        self.reset_unets_all_one_device(device = device)\n",
    "\n",
    "        cond_images = maybe(cast_uint8_images_to_float)(cond_images)\n",
    "\n",
    "        if exists(texts) and not exists(text_embeds) and not self.unconditional:\n",
    "            assert all([*map(len, texts)]), 'text cannot be empty'\n",
    "\n",
    "            with autocast(enabled = False):\n",
    "                text_embeds, text_masks = self.encode_text(texts, return_attn_mask = True)\n",
    "\n",
    "            text_embeds, text_masks = map(lambda t: t.to(device), (text_embeds, text_masks))\n",
    "\n",
    "        if not self.unconditional:\n",
    "            assert exists(text_embeds), 'text must be passed in if the network was not trained without text `condition_on_text` must be set to `False` when training'\n",
    "\n",
    "            text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))\n",
    "            batch_size = text_embeds.shape[0]\n",
    "\n",
    "        if exists(inpaint_images):\n",
    "            if self.unconditional:\n",
    "                if batch_size == 1: # assume researcher wants to broadcast along inpainted images\n",
    "                    batch_size = inpaint_images.shape[0]\n",
    "\n",
    "            assert inpaint_images.shape[0] == batch_size, 'number of inpainting images must be equal to the specified batch size on sample `sample(batch_size=<int>)``'\n",
    "            assert not (self.condition_on_text and inpaint_images.shape[0] != text_embeds.shape[0]), 'number of inpainting images must be equal to the number of text to be conditioned on'\n",
    "\n",
    "        assert not (self.condition_on_text and not exists(text_embeds)), 'text or text encodings must be passed into imagen if specified'\n",
    "        assert not (not self.condition_on_text and exists(text_embeds)), 'imagen specified not to be conditioned on text, yet it is presented'\n",
    "        assert not (exists(text_embeds) and text_embeds.shape[-1] != self.text_embed_dim), f'invalid text embedding dimension being passed in (should be {self.text_embed_dim})'\n",
    "\n",
    "        assert not (exists(inpaint_images) ^ exists(inpaint_masks)),  'inpaint images and masks must be both passed in to do inpainting'\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        is_cuda = next(self.parameters()).is_cuda\n",
    "        device = next(self.parameters()).device\n",
    "\n",
    "        lowres_sample_noise_level = default(lowres_sample_noise_level, self.lowres_sample_noise_level)\n",
    "\n",
    "        num_unets = len(self.unets)\n",
    "        cond_scale = cast_tuple(cond_scale, num_unets)\n",
    "\n",
    "        # handle video and frame dimension\n",
    "\n",
    "        assert not (self.is_video and not exists(video_frames)), 'video_frames must be passed in on sample time if training on video'\n",
    "\n",
    "        frame_dims = (video_frames,) if self.is_video else tuple()\n",
    "\n",
    "        # initializing with an image or video\n",
    "\n",
    "        init_images = cast_tuple(init_images, num_unets)\n",
    "        init_images = [maybe(self.normalize_img)(init_image) for init_image in init_images]\n",
    "\n",
    "        skip_steps = cast_tuple(skip_steps, num_unets)\n",
    "\n",
    "        sigma_min = cast_tuple(sigma_min, num_unets)\n",
    "        sigma_max = cast_tuple(sigma_max, num_unets)\n",
    "\n",
    "        # handle starting at a unet greater than 1, for training only-upscaler training\n",
    "\n",
    "        if start_at_unet_number > 1:\n",
    "            assert start_at_unet_number <= num_unets, 'must start a unet that is less than the total number of unets'\n",
    "            assert not exists(stop_at_unet_number) or start_at_unet_number <= stop_at_unet_number\n",
    "            assert exists(start_image_or_video), 'starting image or video must be supplied if only doing upscaling'\n",
    "\n",
    "            prev_image_size = self.image_sizes[start_at_unet_number - 2]\n",
    "            img = self.resize_to(start_image_or_video, prev_image_size)\n",
    "\n",
    "  \n",
    "        for unet_number, unet, channel, image_size, unet_hparam, dynamic_threshold, unet_cond_scale, unet_init_images, unet_skip_steps, unet_sigma_min, unet_sigma_max in tqdm(zip(range(1, num_unets + 1), self.unets, self.sample_channels, self.image_sizes, self.hparams, self.dynamic_thresholding, cond_scale, init_images, skip_steps, sigma_min, sigma_max), disable = not use_tqdm):\n",
    "            if unet_number < start_at_unet_number:\n",
    "                continue\n",
    "\n",
    "            assert not isinstance(unet, NullUnet), 'cannot sample from null unet'\n",
    "\n",
    "            context = self.one_unet_in_gpu(unet = unet) if is_cuda else nullcontext()\n",
    "\n",
    "            with context:\n",
    "                lowres_cond_img = lowres_noise_times = None\n",
    "\n",
    "                shape = (batch_size, channel, *frame_dims, image_size )\n",
    "\n",
    "                if unet.lowres_cond:\n",
    "                    lowres_noise_times = self.lowres_noise_schedule.get_times(batch_size, lowres_sample_noise_level, device = device)\n",
    "\n",
    "                    lowres_cond_img = self.resize_to(img, image_size)\n",
    "                    \n",
    "                   \n",
    "                    lowres_cond_img = self.normalize_img(lowres_cond_img.float())\n",
    "\n",
    "                    lowres_cond_img, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img.float(), \n",
    "                                                                             t = lowres_noise_times, \n",
    "                                                                             noise = torch.randn_like(lowres_cond_img.float()))\n",
    "\n",
    "                if exists(unet_init_images):\n",
    "                    unet_init_images = self.resize_to(unet_init_images, image_size)\n",
    "\n",
    "                 \n",
    "                shape = (batch_size, self.channels, *frame_dims, image_size)\n",
    "\n",
    "                img = self.one_unet_sample(\n",
    "                    unet,\n",
    "                    shape,\n",
    "                    unet_number = unet_number,\n",
    "                    text_embeds = text_embeds,\n",
    "                    text_mask =text_masks,\n",
    "                    cond_images = cond_images,\n",
    "                    inpaint_images = inpaint_images,\n",
    "                    inpaint_masks = inpaint_masks,\n",
    "                    inpaint_resample_times = inpaint_resample_times,\n",
    "                    init_images = unet_init_images,\n",
    "                    skip_steps = unet_skip_steps,\n",
    "                    sigma_min = unet_sigma_min,\n",
    "                    sigma_max = unet_sigma_max,\n",
    "                    cond_scale = unet_cond_scale,\n",
    "                    lowres_cond_img = lowres_cond_img,\n",
    "                    lowres_noise_times = lowres_noise_times,\n",
    "                    dynamic_threshold = dynamic_threshold,\n",
    "                    use_tqdm = use_tqdm\n",
    "                )\n",
    "               \n",
    "                if self.categorical_loss:\n",
    "                    img=self.m(img)\n",
    "                outputs.append(img)\n",
    "\n",
    "            if exists(stop_at_unet_number) and stop_at_unet_number == unet_number:\n",
    "                break\n",
    "\n",
    "        output_index = -1 if not return_all_unet_outputs else slice(None) # either return last unet output or all unet outputs\n",
    "\n",
    "\n",
    "        if not return_all_unet_outputs:\n",
    "            outputs = outputs[-1:]\n",
    "\n",
    "        assert not self.is_video, 'automatically converting video tensor to video file for saving is not built yet'\n",
    "        \n",
    "        if self.categorical_loss:\n",
    "            return  torch.argmax(outputs[output_index], dim=1).unsqueeze (1)\n",
    "        else:\n",
    "            return  outputs[output_index]\n",
    "\n",
    "    # training\n",
    "\n",
    "    def loss_weight(self, sigma_data, sigma):\n",
    "        return (sigma ** 2 + sigma_data ** 2) * (sigma * sigma_data) ** -2\n",
    "\n",
    "    def noise_distribution(self, P_mean, P_std, batch_size):\n",
    "        return (P_mean + P_std * torch.randn((batch_size,), device = self.device)).exp()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        images,\n",
    "        unet: Union[  NullUnet, DistributedDataParallel] = None,\n",
    "        texts: List[str] = None,\n",
    "        text_embeds = None,\n",
    "        text_masks = None,\n",
    "        unet_number = None,\n",
    "        cond_images = None,\n",
    "         \n",
    "    ):\n",
    "        assert not (len(self.unets) > 1 and not exists(unet_number)), f'you must specify which unet you want trained, from a range of 1 to {len(self.unets)}, if you are training cascading DDPM (multiple unets)'\n",
    "        unet_number = default(unet_number, 1)\n",
    "        assert not exists(self.only_train_unet_number) or self.only_train_unet_number == unet_number, 'you can only train on unet #{self.only_train_unet_number}'\n",
    "\n",
    "       \n",
    "        cond_images = maybe(cast_uint8_images_to_float)(cond_images)\n",
    "       \n",
    "        if self.categorical_loss==False:\n",
    "            assert is_float_dtype(images.dtype), f'images tensor needs to be floats but {images.dtype} dtype found instead'\n",
    "\n",
    "        unet_index = unet_number - 1\n",
    "        \n",
    "        unet = default(unet, lambda: self.get_unet(unet_number))\n",
    "\n",
    "        assert not isinstance(unet, NullUnet), 'null unet cannot and should not be trained'\n",
    "\n",
    "        target_image_size    = self.image_sizes[unet_index]\n",
    "        random_crop_size     = self.random_crop_sizes[unet_index]\n",
    "        prev_image_size      = self.image_sizes[unet_index - 1] if unet_index > 0 else None\n",
    "        hp                   = self.hparams[unet_index]\n",
    "\n",
    "        \n",
    "        batch_size, c, *_, h, device, is_video = *images.shape, images.device, (images.ndim == 4)\n",
    "\n",
    "        frames = images.shape[2] if is_video else None\n",
    "\n",
    "        check_shape(images, 'b c ...', c = self.channels)\n",
    "\n",
    "        \n",
    "        assert h >= target_image_size\n",
    "\n",
    "        if exists(texts) and not exists(text_embeds) and not self.unconditional:\n",
    "            assert all([*map(len, texts)]), 'text cannot be empty'\n",
    "            assert len(texts) == len(images), 'number of text captions does not match up with the number of images given'\n",
    "\n",
    "            with autocast(enabled = False):\n",
    "                text_embeds, text_masks = self.encode_text(texts, return_attn_mask = True)\n",
    "\n",
    "            text_embeds, text_masks = map(lambda t: t.to(images.device), (text_embeds, text_masks))\n",
    "\n",
    "        if not self.unconditional:\n",
    "            text_masks = default(text_masks, lambda: torch.any(text_embeds != 0., dim = -1))\n",
    "\n",
    "        assert not (self.condition_on_text and not exists(text_embeds)), 'text or text encodings must be passed into decoder if specified'\n",
    "        assert not (not self.condition_on_text and exists(text_embeds)), 'decoder specified not to be conditioned on text, yet it is presented'\n",
    "\n",
    "        assert not (exists(text_embeds) and text_embeds.shape[-1] != self.text_embed_dim), f'invalid text embedding dimension being passed in (should be {self.text_embed_dim})'\n",
    "\n",
    "        lowres_cond_img = lowres_aug_times = None\n",
    "        if exists(prev_image_size):\n",
    "            lowres_cond_img = self.resize_to(images, prev_image_size, clamp_range = self.input_image_range)\n",
    "            lowres_cond_img = self.resize_to(lowres_cond_img, target_image_size, clamp_range = self.input_image_range)\n",
    "\n",
    "            if self.per_sample_random_aug_noise_level:\n",
    "                lowres_aug_times = self.lowres_noise_schedule.sample_random_times(batch_size, device = device)\n",
    "            else:\n",
    "                lowres_aug_time = self.lowres_noise_schedule.sample_random_times(1, device = device)\n",
    "                lowres_aug_times = repeat(lowres_aug_time, '1 -> b', b = batch_size)\n",
    "\n",
    "        if exists(random_crop_size):\n",
    "            aug = K.RandomCrop((random_crop_size, random_crop_size), p = 1.)\n",
    "\n",
    "            if is_video:\n",
    "                images, lowres_cond_img = rearrange_many((images, lowres_cond_img), 'b c f h -> (b f) c h')\n",
    "\n",
    "            images = aug(images)\n",
    "            lowres_cond_img = aug(lowres_cond_img, params = aug._params)\n",
    "\n",
    "            if is_video:\n",
    "                images, lowres_cond_img = rearrange_many((images, lowres_cond_img), '(b f) c h -> b c f h', f = frames)\n",
    "\n",
    "      \n",
    "        lowres_cond_img_noisy = None\n",
    "        if exists(lowres_cond_img):\n",
    "            lowres_cond_img_noisy, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, \n",
    "                                                                           t = lowres_aug_times,\n",
    "                                                                           noise = torch.randn_like(lowres_cond_img.float()))\n",
    "\n",
    "        # get the sigmas\n",
    "\n",
    "        sigmas = self.noise_distribution(hp.P_mean, hp.P_std, batch_size).to(device)\n",
    "        padded_sigmas = self.right_pad_dims_to_datatype(sigmas).to(device)\n",
    "\n",
    "        # noise\n",
    "\n",
    "        noise = torch.randn_like(images.float()).to(device)\n",
    "        \n",
    "       \n",
    "        noised_images = images + padded_sigmas * noise  # alphas are 1. in the paper\n",
    "     \n",
    "        # unet kwargs\n",
    "\n",
    "        unet_kwargs = dict(\n",
    "            sigma_data = hp.sigma_data,\n",
    "            text_embeds = text_embeds,\n",
    "            text_mask =text_masks,\n",
    "            cond_images = cond_images,\n",
    "            lowres_noise_times = self.lowres_noise_schedule.get_condition(lowres_aug_times),\n",
    "            lowres_cond_img = lowres_cond_img_noisy,\n",
    "            cond_drop_prob = self.cond_drop_prob,\n",
    "        )\n",
    "\n",
    "        # self conditioning - https://arxiv.org/abs/2208.04202 - training will be 25% slower\n",
    "\n",
    "        # Because 'unet' can be an instance of DistributedDataParallel coming from the\n",
    "        # ImagenTrainer.unet_being_trained when invoking ImagenTrainer.forward(), we need to\n",
    "        # access the member 'module' of the wrapped unet instance.\n",
    "        \n",
    "        self_cond = unet.module.self_cond if isinstance(unet, DistributedDataParallel) else unet\n",
    "\n",
    "        if self_cond and random() < 0.5:\n",
    "            with torch.no_grad():\n",
    "                pred_x0 = self.preconditioned_network_forward(\n",
    "                    unet.forward,\n",
    "                    noised_images,\n",
    "                    sigmas,\n",
    "                    **unet_kwargs\n",
    "                ).detach()\n",
    "\n",
    "            unet_kwargs = {**unet_kwargs, 'self_cond': pred_x0}\n",
    "\n",
    "        # get prediction\n",
    "\n",
    "        denoised_images = self.preconditioned_network_forward(\n",
    "            unet.forward,\n",
    "            noised_images,\n",
    "            sigmas,\n",
    "            **unet_kwargs\n",
    "        )\n",
    "\n",
    "        # losses\n",
    "        \n",
    "        if self.loss_type==0: \n",
    "\n",
    "            losses = F.mse_loss(denoised_images, images, reduction = 'none')\n",
    "            losses = reduce(losses, 'b ... -> b', 'mean')\n",
    "\n",
    "            # loss weighting\n",
    "\n",
    "            losses = losses * self.loss_weight(hp.sigma_data, sigmas)\n",
    "            losses=losses.mean()\n",
    "\n",
    "        return losses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9058aa",
   "metadata": {},
   "source": [
    "## Define protein generative diffusion model - Model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "da2a0563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProteinDesigner_B(nn.Module):\n",
    "    def __init__(self, unet, timesteps=10 , dim=32,pred_dim=25,loss_type=0, \n",
    "                 elucidated=True ,  \n",
    "                  padding_idx=0,\n",
    "                cond_dim = 512,\n",
    "                text_embed_dim = 512,\n",
    "                 input_tokens=25,#for non-BERT\n",
    "                 sequence_embed=False,\n",
    "                 embed_dim_position=32,\n",
    "                 max_text_len=16,\n",
    "                 cond_images_channels=0,\n",
    "                \n",
    "                ):\n",
    "        super(ProteinDesigner_B, self).__init__()\n",
    "\n",
    "        print (\"Model B: Generative protein diffusion model, residue-based\")\n",
    "        self.pred_dim=pred_dim\n",
    "        self.loss_type=loss_type\n",
    "        \n",
    "        assert loss_type == 0, \"Losses other than MSE not implemented\"\n",
    "        \n",
    "        self.fc_embed1 = nn.Linear( 8,  max_length)      # not used\n",
    "        self.fc_embed2 = nn.Linear( 1,  text_embed_dim)  #\n",
    "        self.max_text_len=max_text_len\n",
    "       \n",
    "        self.pos_emb_x = nn.Embedding(max_text_len+1, embed_dim_position)\n",
    "        text_embed_dim=text_embed_dim+embed_dim_position\n",
    "        \n",
    "        self.pos_matrix_i = torch.zeros (max_text_len, dtype=torch.long)\n",
    "        for i in range (max_text_len):\n",
    "            self.pos_matrix_i [i]=i +1         \n",
    "\n",
    "        condition_on_text=True        \n",
    "        self.cond_images_channels=cond_images_channels \n",
    "        \n",
    "        if self.cond_images_channels>0:\n",
    "            condition_on_text = False \n",
    "            \n",
    "        if self.cond_images_channels>0:\n",
    "            print (\"Use conditioning image during training....\")\n",
    "        \n",
    "        assert elucidated , \"Only elucidated model implemented....\"\n",
    "        self.is_elucidated=elucidated\n",
    "        if elucidated:\n",
    "            self.imagen = ElucidatedImagen(\n",
    "                unets = (unet),\n",
    "                channels=self.pred_dim,\n",
    "                channels_out=self.pred_dim ,\n",
    "                loss_type=loss_type, \n",
    "                condition_on_text = condition_on_text,\n",
    "                text_embed_dim = text_embed_dim,\n",
    "                image_sizes = ( [max_length ]),\n",
    "                cond_drop_prob = 0.1,\n",
    "                auto_normalize_img = False, \n",
    "                num_sample_steps = timesteps, # number of sample steps - 64 for base unet, 32 for upsampler (just an example, have no clue what the optimal values are)\n",
    "                sigma_min = 0.002,           # min noise level\n",
    "                sigma_max = 160,#(80, 160),       # max noise level, @crowsonkb recommends double the max noise level for upsampler\n",
    "                sigma_data = 0.5,            # standard deviation of data distribution\n",
    "                rho = 7,                     # controls the sampling schedule\n",
    "                P_mean = -1.2,               # mean of log-normal distribution from which noise is drawn for training\n",
    "                P_std = 1.2,                 # standard deviation of log-normal distribution from which noise is drawn for training\n",
    "                S_churn = 40,#80,                # parameters for stochastic sampling - depends on dataset, Table 5 in apper\n",
    "                S_tmin = 0.05,\n",
    "                S_tmax = 50,\n",
    "                S_noise = 1.003,\n",
    "                 \n",
    "                    ).to(device)\n",
    "        else:\n",
    "             print (\"Not implemented.\")\n",
    "            \n",
    "    def forward(self,output,  x=None, cond_images = None, \n",
    "                unet_number=1,\n",
    "               ): \n",
    "       \n",
    "        if x !=None:\n",
    "            x_in=torch.zeros( (x.shape[0],max_length) ).to(device)\n",
    "            x_in[:,:x.shape[1]]=x\n",
    "            x=x_in       \n",
    "            \n",
    "            x=x.unsqueeze (2)\n",
    "           \n",
    "            x= self.fc_embed2(x)\n",
    "            \n",
    "            pos_matrix_i_=self.pos_matrix_i.repeat(x.shape[0], 1).to(device) \n",
    "            pos_emb_x = self.pos_emb_x( pos_matrix_i_)\n",
    "            pos_emb_x = torch.squeeze(pos_emb_x, 1)\n",
    "\n",
    "            x= torch.cat( (x,   pos_emb_x ), 2)        \n",
    "        \n",
    "        loss =  self.imagen(output, text_embeds = x,  cond_images=cond_images.to(device), \n",
    "                            unet_number = unet_number, )\n",
    " \n",
    "        return loss\n",
    "    \n",
    "    def sample (self, x=None, stop_at_unet_number=1 ,cond_scale=7.5, \n",
    "                x_data=None, skip_steps=None,\n",
    "                     inpaint_images = None,\n",
    "                    inpaint_masks = None,\n",
    "                    inpaint_resample_times = 5,\n",
    "                    init_images = None,\n",
    "                x_data_tokenized=None,device=None,\n",
    "                   ):\n",
    "           \n",
    "        batch_size=1\n",
    "        \n",
    "        if x_data != None:\n",
    "            print (\"Conditioning target sequence provided via x_data ...\", x_data)\n",
    "            x_data = tokenizer_X.texts_to_sequences(x_data)\n",
    "            x_data= sequence.pad_sequences(x_data,  maxlen=max_length, padding='post', truncating='post')\n",
    "            \n",
    "            x_data= torch.from_numpy(x_data).float().to(device)\n",
    "            x_data = x_data/Xnormfac\n",
    "            x_data=x_data.unsqueeze (2)\n",
    "            x_data=torch.permute(x_data, (0,2,1)  )\n",
    "            \n",
    "            print (\"x_data from target sequence=\", x_data, x_data.shape)\n",
    "            batch_size=x_data.shape[0]\n",
    "            \n",
    "        if x_data_tokenized != None:\n",
    "            print (\"Conditioning target sequence provided via x_data_tokenized ...\", x_data_tokenized, x_data_tokenized.shape)\n",
    "             \n",
    "            x_data=x_data_tokenized.unsqueeze (2)\n",
    "            x_data=torch.permute(x_data, (0,2,1)  ).to(device)\n",
    "            print (\"Data provided from x_data_tokenized: \", x_data.shape)\n",
    "            batch_size=x_data.shape[0]\n",
    "            \n",
    "        if init_images != None:\n",
    "            print (\"Init sequence provided...\", init_images)\n",
    "            init_images = tokenizer_y.texts_to_sequences(init_images)\n",
    "            init_images= sequence.pad_sequences(init_images,  maxlen=max_length, padding='post', truncating='post')\n",
    "            init_images= torch.from_numpy(init_images).float().to(device)/ynormfac\n",
    "            print (\"init_images=\", init_images)   \n",
    "            \n",
    "        if inpaint_images != None:\n",
    "            print (\"Inpaint sequence provided...\", inpaint_images)\n",
    "            print (\"Mask:                            \", inpaint_masks)\n",
    "            inpaint_images = tokenizer_y.texts_to_sequences(inpaint_images)\n",
    "            inpaint_images= sequence.pad_sequences(inpaint_images,  maxlen=max_length, padding='post', truncating='post')\n",
    "            inpaint_images= torch.from_numpy(inpaint_images).float().to(device)/ynormfac\n",
    "            print (\"in_paint images=\", inpaint_images)   \n",
    "                      \n",
    "        if x !=None:\n",
    "            x_in=torch.zeros( (x.shape[0],max_length) ).to(device)\n",
    "            x_in[:,:x.shape[1]]=x\n",
    "            x=x_in\n",
    "            x=x.unsqueeze (2)\n",
    "          \n",
    "            x= self.fc_embed2(x)\n",
    "            \n",
    "            pos_matrix_i_=self.pos_matrix_i.repeat(x.shape[0], 1).to(device) \n",
    "            pos_emb_x = self.pos_emb_x( pos_matrix_i_)\n",
    "            pos_emb_x = torch.squeeze(pos_emb_x, 1)\n",
    "            \n",
    "            x= torch.cat( (x,   pos_emb_x ), 2)    \n",
    "            \n",
    "            batch_size=x.shape[0]\n",
    "    \n",
    "        output =  self.imagen.sample(text_embeds= x, cond_scale = cond_scale, \n",
    "                                     stop_at_unet_number=stop_at_unet_number,\n",
    "                                    cond_images=x_data,\n",
    "                                     skip_steps=skip_steps,\n",
    "                                     inpaint_images = inpaint_images,\n",
    "                                        inpaint_masks = inpaint_masks,\n",
    "                                        inpaint_resample_times = inpaint_resample_times,\n",
    "                                        init_images = init_images,batch_size=batch_size,\n",
    "                                     device=device,\n",
    "                                    )\n",
    "       \n",
    "        return output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00e032",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73fb5d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "from contextlib import contextmanager, nullcontext\n",
    "from functools import partial, wraps\n",
    "from collections.abc import Iterable\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import pytorch_warmup as warmup\n",
    " \n",
    "from packaging import version\n",
    "__version__ = '1.9.3'\n",
    "\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "            \n",
    "from packaging import version\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from ema_pytorch import EMA\n",
    "\n",
    "from accelerate import Accelerator, DistributedType, DistributedDataParallelKwargs\n",
    "\n",
    "from fsspec.core import url_to_fs\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def cast_tuple(val, length = 1):\n",
    "    if isinstance(val, list):\n",
    "        val = tuple(val)\n",
    "    \n",
    "    return val if isinstance(val, tuple) else ((val,) * length)\n",
    "\n",
    "def find_first(fn, arr):\n",
    "    for ind, el in enumerate(arr):\n",
    "        if fn(el):\n",
    "            return ind\n",
    "    return -1\n",
    "\n",
    "def pick_and_pop(keys, d):\n",
    "    values = list(map(lambda key: d.pop(key), keys))\n",
    "    return dict(zip(keys, values))\n",
    "\n",
    "def group_dict_by_key(cond, d):\n",
    "    return_val = [dict(),dict()]\n",
    "    for key in d.keys():\n",
    "        match = bool(cond(key))\n",
    "        ind = int(not match)\n",
    "        return_val[ind][key] = d[key]\n",
    "    return (*return_val,)\n",
    "\n",
    "def string_begins_with(prefix, str):\n",
    "    return str.startswith(prefix)\n",
    "\n",
    "def group_by_key_prefix(prefix, d):\n",
    "    return group_dict_by_key(partial(string_begins_with, prefix), d)\n",
    "\n",
    "def groupby_prefix_and_trim(prefix, d):\n",
    "    kwargs_with_prefix, kwargs = group_dict_by_key(partial(string_begins_with, prefix), d)\n",
    "    kwargs_without_prefix = dict(map(lambda x: (x[0][len(prefix):], x[1]), tuple(kwargs_with_prefix.items())))\n",
    "    return kwargs_without_prefix, kwargs\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "# url to fs, bucket, path - for checkpointing to cloud\n",
    "\n",
    "def url_to_bucket(url):\n",
    "    if '://' not in url:\n",
    "        return url\n",
    "\n",
    "    _, suffix = url.split('://')\n",
    "\n",
    "    if prefix in {'gs', 's3'}:\n",
    "        return suffix.split('/')[0]\n",
    "    else:\n",
    "        raise ValueError(f'storage type prefix \"{prefix}\" is not supported yet')\n",
    "\n",
    "# decorators\n",
    "\n",
    "def eval_decorator(fn):\n",
    "    def inner(model, *args, **kwargs):\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "        out = fn(model, *args, **kwargs)\n",
    "        model.train(was_training)\n",
    "        return out\n",
    "    return inner\n",
    "\n",
    "def cast_torch_tensor(fn, cast_fp16 = False):\n",
    "    @wraps(fn)\n",
    "    def inner(model, *args, **kwargs):\n",
    "        device = kwargs.pop('_device', model.device)\n",
    "        cast_device = kwargs.pop('_cast_device', True)\n",
    "\n",
    "        should_cast_fp16 = cast_fp16 and model.cast_half_at_training\n",
    "\n",
    "        kwargs_keys = kwargs.keys()\n",
    "        all_args = (*args, *kwargs.values())\n",
    "        split_kwargs_index = len(all_args) - len(kwargs_keys)\n",
    "        all_args = tuple(map(lambda t: torch.from_numpy(t) if exists(t) and isinstance(t, np.ndarray) else t, all_args))\n",
    "\n",
    "        if cast_device:\n",
    "            all_args = tuple(map(lambda t: t.to(device) if exists(t) and isinstance(t, torch.Tensor) else t, all_args))\n",
    "\n",
    "        if should_cast_fp16:\n",
    "            all_args = tuple(map(lambda t: t.half() if exists(t) and isinstance(t, torch.Tensor) and t.dtype != torch.bool else t, all_args))\n",
    "\n",
    "        args, kwargs_values = all_args[:split_kwargs_index], all_args[split_kwargs_index:]\n",
    "        kwargs = dict(tuple(zip(kwargs_keys, kwargs_values)))\n",
    "\n",
    "        out = fn(model, *args, **kwargs)\n",
    "        return out\n",
    "    return inner\n",
    "\n",
    "# gradient accumulation functions\n",
    "\n",
    "def split_iterable(it, split_size):\n",
    "    accum = []\n",
    "    for ind in range(ceil(len(it) / split_size)):\n",
    "        start_index = ind * split_size\n",
    "        accum.append(it[start_index: (start_index + split_size)])\n",
    "    return accum\n",
    "\n",
    "def split(t, split_size = None):\n",
    "    if not exists(split_size):\n",
    "        return t\n",
    "\n",
    "    if isinstance(t, torch.Tensor):\n",
    "        return t.split(split_size, dim = 0)\n",
    "\n",
    "    if isinstance(t, Iterable):\n",
    "        return split_iterable(t, split_size)\n",
    "\n",
    "    return TypeError\n",
    "\n",
    "def find_first(cond, arr):\n",
    "    for el in arr:\n",
    "        if cond(el):\n",
    "            return el\n",
    "    return None\n",
    "\n",
    "def split_args_and_kwargs(*args, split_size = None, **kwargs):\n",
    "    all_args = (*args, *kwargs.values())\n",
    "    len_all_args = len(all_args)\n",
    "    first_tensor = find_first(lambda t: isinstance(t, torch.Tensor), all_args)\n",
    "    assert exists(first_tensor)\n",
    "\n",
    "    batch_size = len(first_tensor)\n",
    "    split_size = default(split_size, batch_size)\n",
    "    num_chunks = ceil(batch_size / split_size)\n",
    "\n",
    "    dict_len = len(kwargs)\n",
    "    dict_keys = kwargs.keys()\n",
    "    split_kwargs_index = len_all_args - dict_len\n",
    "\n",
    "    split_all_args = [split(arg, split_size = split_size) if exists(arg) and isinstance(arg, (torch.Tensor, Iterable)) else ((arg,) * num_chunks) for arg in all_args]\n",
    "    chunk_sizes = tuple(map(len, split_all_args[0]))\n",
    "\n",
    "    for (chunk_size, *chunked_all_args) in tuple(zip(chunk_sizes, *split_all_args)):\n",
    "        chunked_args, chunked_kwargs_values = chunked_all_args[:split_kwargs_index], chunked_all_args[split_kwargs_index:]\n",
    "        chunked_kwargs = dict(tuple(zip(dict_keys, chunked_kwargs_values)))\n",
    "        chunk_size_frac = chunk_size / batch_size\n",
    "        yield chunk_size_frac, (chunked_args, chunked_kwargs)\n",
    "\n",
    "# imagen trainer\n",
    "\n",
    "def imagen_sample_in_chunks(fn):\n",
    "    @wraps(fn)\n",
    "    def inner(self, *args, max_batch_size = None, **kwargs):\n",
    "        if not exists(max_batch_size):\n",
    "            return fn(self, *args, **kwargs)\n",
    "\n",
    "        if self.imagen.unconditional:\n",
    "            batch_size = kwargs.get('batch_size')\n",
    "            batch_sizes = num_to_groups(batch_size, max_batch_size)\n",
    "            outputs = [fn(self, *args, **{**kwargs, 'batch_size': sub_batch_size}) for sub_batch_size in batch_sizes]\n",
    "        else:\n",
    "            outputs = [fn(self, *chunked_args, **chunked_kwargs) for _, (chunked_args, chunked_kwargs) in split_args_and_kwargs(*args, split_size = max_batch_size, **kwargs)]\n",
    "\n",
    "        if isinstance(outputs[0], torch.Tensor):\n",
    "            return torch.cat(outputs, dim = 0)\n",
    "\n",
    "        return list(map(lambda t: torch.cat(t, dim = 0), list(zip(*outputs))))\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "def restore_parts(state_dict_target, state_dict_from):\n",
    "    for name, param in state_dict_from.items():\n",
    "\n",
    "        if name not in state_dict_target:\n",
    "            continue\n",
    "\n",
    "        if param.size() == state_dict_target[name].size():\n",
    "            state_dict_target[name].copy_(param)\n",
    "        else:\n",
    "            print(f\"layer {name}({param.size()} different than target: {state_dict_target[name].size()}\")\n",
    "\n",
    "    return state_dict_target\n",
    "\n",
    "\n",
    "class ImagenTrainer(nn.Module):\n",
    "    locked = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        #imagen = None,\n",
    "        model = None,\n",
    "        \n",
    "        imagen_checkpoint_path = None,\n",
    "        use_ema = True,\n",
    "        lr = 1e-4,\n",
    "        eps = 1e-8,\n",
    "        beta1 = 0.9,\n",
    "        beta2 = 0.99,\n",
    "        max_grad_norm = None,\n",
    "        group_wd_params = True,\n",
    "        warmup_steps = None,\n",
    "        cosine_decay_max_steps = None,\n",
    "        only_train_unet_number = None,\n",
    "        fp16 = False,\n",
    "        precision = None,\n",
    "        split_batches = True,\n",
    "        dl_tuple_output_keywords_names = ('images', 'text_embeds', 'text_masks', 'cond_images'),\n",
    "        verbose = True,\n",
    "        split_valid_fraction = 0.025,\n",
    "        split_valid_from_train = False,\n",
    "        split_random_seed = 42,\n",
    "        checkpoint_path = None,\n",
    "        checkpoint_every = None,\n",
    "        checkpoint_fs = None,\n",
    "        fs_kwargs: dict = None,\n",
    "        max_checkpoints_keep = 20,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert not ImagenTrainer.locked, 'ImagenTrainer can only be initialized once per process - for the sake of distributed training, you will now have to create a separate script to train each unet (or a script that accepts unet number as an argument)'\n",
    "        assert exists(model.imagen) ^ exists(imagen_checkpoint_path), 'either imagen instance is passed into the trainer, or a checkpoint path that contains the imagen config'\n",
    "\n",
    "        # determine filesystem, using fsspec, for saving to local filesystem or cloud\n",
    "\n",
    "        self.fs = checkpoint_fs\n",
    "\n",
    "        if not exists(self.fs):\n",
    "            fs_kwargs = default(fs_kwargs, {})\n",
    "            self.fs, _ = url_to_fs(default(checkpoint_path, './'), **fs_kwargs)\n",
    "        \n",
    "        assert isinstance(model.imagen, (ProteinDesigner_B))\n",
    "        ema_kwargs, kwargs = groupby_prefix_and_trim('ema_', kwargs)\n",
    "\n",
    "         \n",
    "        self.imagen = model.imagen\n",
    "       \n",
    "        \n",
    "\n",
    "        self.model=model\n",
    "        self.is_elucidated = self.model.is_elucidated \n",
    "        # create accelerator instance\n",
    "\n",
    "        accelerate_kwargs, kwargs = groupby_prefix_and_trim('accelerate_', kwargs)\n",
    "\n",
    "        assert not (fp16 and exists(precision)), 'either set fp16 = True or forward the precision (\"fp16\", \"bf16\") to Accelerator'\n",
    "        accelerator_mixed_precision = default(precision, 'fp16' if fp16 else 'no')\n",
    "\n",
    "        self.accelerator = Accelerator(**{\n",
    "            'split_batches': split_batches,\n",
    "            'mixed_precision': accelerator_mixed_precision,\n",
    "            'kwargs_handlers': [DistributedDataParallelKwargs(find_unused_parameters = True)]\n",
    "        , **accelerate_kwargs})\n",
    "\n",
    "        ImagenTrainer.locked = self.is_distributed\n",
    "\n",
    "        # cast data to fp16 at training time if needed\n",
    "\n",
    "        self.cast_half_at_training = accelerator_mixed_precision == 'fp16'\n",
    "\n",
    "        # grad scaler must be managed outside of accelerator\n",
    "\n",
    "        grad_scaler_enabled = fp16\n",
    "   \n",
    "        self.num_unets = len(self.imagen.unets)\n",
    "\n",
    "        self.use_ema = use_ema and self.is_main\n",
    "        self.ema_unets = nn.ModuleList([])\n",
    "\n",
    "        # keep track of what unet is being trained on\n",
    "        # only going to allow 1 unet training at a time\n",
    "\n",
    "        self.ema_unet_being_trained_index = -1 # keeps track of which ema unet is being trained on\n",
    "\n",
    "        # data related functions\n",
    "\n",
    "        self.train_dl_iter = None\n",
    "        self.train_dl = None\n",
    "\n",
    "        self.valid_dl_iter = None\n",
    "        self.valid_dl = None\n",
    "\n",
    "        self.dl_tuple_output_keywords_names = dl_tuple_output_keywords_names\n",
    "\n",
    "        # auto splitting validation from training, if dataset is passed in\n",
    "\n",
    "        self.split_valid_from_train = split_valid_from_train\n",
    "\n",
    "        assert 0 <= split_valid_fraction <= 1, 'split valid fraction must be between 0 and 1'\n",
    "        self.split_valid_fraction = split_valid_fraction\n",
    "        self.split_random_seed = split_random_seed\n",
    "\n",
    "        # be able to finely customize learning rate, weight decay\n",
    "        # per unet\n",
    "\n",
    "        lr, eps, warmup_steps, cosine_decay_max_steps = map(partial(cast_tuple, length = self.num_unets), (lr, eps, warmup_steps, cosine_decay_max_steps))\n",
    "\n",
    "        for ind, (unet, unet_lr, unet_eps, unet_warmup_steps, unet_cosine_decay_max_steps) in enumerate(zip(self.imagen.unets, lr, eps, warmup_steps, cosine_decay_max_steps)):\n",
    "            optimizer = Adam(\n",
    "                unet.parameters(),\n",
    "                lr = unet_lr,\n",
    "                eps = unet_eps,\n",
    "                betas = (beta1, beta2),\n",
    "                **kwargs\n",
    "            )\n",
    "\n",
    "            if self.use_ema:\n",
    "                self.ema_unets.append(EMA(unet, **ema_kwargs))\n",
    "\n",
    "            scaler = GradScaler(enabled = grad_scaler_enabled)\n",
    "\n",
    "            scheduler = warmup_scheduler = None\n",
    "\n",
    "            if exists(unet_cosine_decay_max_steps):\n",
    "                scheduler = CosineAnnealingLR(optimizer, T_max = unet_cosine_decay_max_steps)\n",
    "\n",
    "            if exists(unet_warmup_steps):\n",
    "                warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period = unet_warmup_steps)\n",
    "\n",
    "                if not exists(scheduler):\n",
    "                    scheduler = LambdaLR(optimizer, lr_lambda = lambda step: 1.0)\n",
    "\n",
    "            # set on object\n",
    "\n",
    "            setattr(self, f'optim{ind}', optimizer) # cannot use pytorch ModuleList for some reason with optimizers\n",
    "            setattr(self, f'scaler{ind}', scaler)\n",
    "            setattr(self, f'scheduler{ind}', scheduler)\n",
    "            setattr(self, f'warmup{ind}', warmup_scheduler)\n",
    "\n",
    "        # gradient clipping if needed\n",
    "\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "\n",
    "        # step tracker and misc\n",
    "\n",
    "        self.register_buffer('steps', torch.tensor([0] * self.num_unets))\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # automatic set devices based on what accelerator decided\n",
    "\n",
    "        self.imagen.to(self.device)\n",
    "        self.to(self.device)\n",
    "\n",
    "        # checkpointing\n",
    "\n",
    "        assert not (exists(checkpoint_path) ^ exists(checkpoint_every))\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.checkpoint_every = checkpoint_every\n",
    "        self.max_checkpoints_keep = max_checkpoints_keep\n",
    "\n",
    "        self.can_checkpoint = self.is_local_main if isinstance(checkpoint_fs, LocalFileSystem) else self.is_main\n",
    "\n",
    "        if exists(checkpoint_path) and self.can_checkpoint:\n",
    "            bucket = url_to_bucket(checkpoint_path)\n",
    "\n",
    "            if not self.fs.exists(bucket):\n",
    "                self.fs.mkdir(bucket)\n",
    "\n",
    "            self.load_from_checkpoint_folder()\n",
    "\n",
    "        # only allowing training for unet\n",
    "\n",
    "        self.only_train_unet_number = only_train_unet_number\n",
    "        self.validate_and_set_unet_being_trained(only_train_unet_number)\n",
    "\n",
    "    # computed values\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.accelerator.device\n",
    "\n",
    "    @property\n",
    "    def is_distributed(self):\n",
    "        return not (self.accelerator.distributed_type == DistributedType.NO and self.accelerator.num_processes == 1)\n",
    "\n",
    "    @property\n",
    "    def is_main(self):\n",
    "        return self.accelerator.is_main_process\n",
    "\n",
    "    @property\n",
    "    def is_local_main(self):\n",
    "        return self.accelerator.is_local_main_process\n",
    "\n",
    "    @property\n",
    "    def unwrapped_unet(self):\n",
    "        return self.accelerator.unwrap_model(self.unet_being_trained)\n",
    "\n",
    "    # optimizer helper functions\n",
    "\n",
    "    def get_lr(self, unet_number):\n",
    "        self.validate_unet_number(unet_number)\n",
    "        unet_index = unet_number - 1\n",
    "\n",
    "        optim = getattr(self, f'optim{unet_index}')\n",
    "\n",
    "        return optim.param_groups[0]['lr']\n",
    "\n",
    "    # function for allowing only one unet from being trained at a time\n",
    "\n",
    "    def validate_and_set_unet_being_trained(self, unet_number = None):\n",
    "        if exists(unet_number):\n",
    "            self.validate_unet_number(unet_number)\n",
    "\n",
    "        assert not exists(self.only_train_unet_number) or self.only_train_unet_number == unet_number, 'you cannot only train on one unet at a time. you will need to save the trainer into a checkpoint, and resume training on a new unet'\n",
    "\n",
    "        self.only_train_unet_number = unet_number\n",
    "        self.imagen.only_train_unet_number = unet_number\n",
    "\n",
    "        if not exists(unet_number):\n",
    "            return\n",
    "\n",
    "        self.wrap_unet(unet_number)\n",
    "\n",
    "    def wrap_unet(self, unet_number):\n",
    "        if hasattr(self, 'one_unet_wrapped'):\n",
    "            return\n",
    "\n",
    "        unet = self.imagen.get_unet(unet_number)\n",
    "        self.unet_being_trained = self.accelerator.prepare(unet)\n",
    "        unet_index = unet_number - 1\n",
    "\n",
    "        optimizer = getattr(self, f'optim{unet_index}')\n",
    "        scheduler = getattr(self, f'scheduler{unet_index}')\n",
    "\n",
    "        optimizer = self.accelerator.prepare(optimizer)\n",
    "\n",
    "        if exists(scheduler):\n",
    "            scheduler = self.accelerator.prepare(scheduler)\n",
    "\n",
    "        setattr(self, f'optim{unet_index}', optimizer)\n",
    "        setattr(self, f'scheduler{unet_index}', scheduler)\n",
    "\n",
    "        self.one_unet_wrapped = True\n",
    "\n",
    "    # hacking accelerator due to not having separate gradscaler per optimizer\n",
    "\n",
    "    def set_accelerator_scaler(self, unet_number):\n",
    "        unet_number = self.validate_unet_number(unet_number)\n",
    "        scaler = getattr(self, f'scaler{unet_number - 1}')\n",
    "\n",
    "        self.accelerator.scaler = scaler\n",
    "        for optimizer in self.accelerator._optimizers:\n",
    "            optimizer.scaler = scaler\n",
    "\n",
    "    # helper print\n",
    "\n",
    "    def print(self, msg):\n",
    "        if not self.is_main:\n",
    "            return\n",
    "\n",
    "        if not self.verbose:\n",
    "            return\n",
    "\n",
    "        return self.accelerator.print(msg)\n",
    "\n",
    "    # validating the unet number\n",
    "\n",
    "    def validate_unet_number(self, unet_number = None):\n",
    "        if self.num_unets == 1:\n",
    "            unet_number = default(unet_number, 1)\n",
    "\n",
    "        assert 0 < unet_number <= self.num_unets, f'unet number should be in between 1 and {self.num_unets}'\n",
    "        return unet_number\n",
    "\n",
    "    # number of training steps taken\n",
    "\n",
    "    def num_steps_taken(self, unet_number = None):\n",
    "        if self.num_unets == 1:\n",
    "            unet_number = default(unet_number, 1)\n",
    "\n",
    "        return self.steps[unet_number - 1].item()\n",
    "\n",
    "    def print_untrained_unets(self):\n",
    "        print_final_error = False\n",
    "\n",
    "        for ind, (steps, unet) in enumerate(zip(self.steps.tolist(), self.imagen.unets)):\n",
    "            if steps > 0 or isinstance(unet, NullUnet):\n",
    "                continue\n",
    "\n",
    "            self.print(f'unet {ind + 1} has not been trained')\n",
    "            print_final_error = True\n",
    "\n",
    "        if print_final_error:\n",
    "            self.print('when sampling, you can pass stop_at_unet_number to stop early in the cascade, so it does not try to generate with untrained unets')\n",
    "\n",
    "    # data related functions\n",
    "\n",
    "    def add_train_dataloader(self, dl = None):\n",
    "        if not exists(dl):\n",
    "            return\n",
    "\n",
    "        assert not exists(self.train_dl), 'training dataloader was already added'\n",
    "        self.train_dl = self.accelerator.prepare(dl)\n",
    "\n",
    "    def add_valid_dataloader(self, dl):\n",
    "        if not exists(dl):\n",
    "            return\n",
    "\n",
    "        assert not exists(self.valid_dl), 'validation dataloader was already added'\n",
    "        self.valid_dl = self.accelerator.prepare(dl)\n",
    "\n",
    "    def add_train_dataset(self, ds = None, *, batch_size, **dl_kwargs):\n",
    "        if not exists(ds):\n",
    "            return\n",
    "\n",
    "        assert not exists(self.train_dl), 'training dataloader was already added'\n",
    "\n",
    "        valid_ds = None\n",
    "        if self.split_valid_from_train:\n",
    "            train_size = int((1 - self.split_valid_fraction) * len(ds))\n",
    "            valid_size = len(ds) - train_size\n",
    "\n",
    "            ds, valid_ds = random_split(ds, [train_size, valid_size], generator = torch.Generator().manual_seed(self.split_random_seed))\n",
    "            self.print(f'training with dataset of {len(ds)} samples and validating with randomly splitted {len(valid_ds)} samples')\n",
    "\n",
    "        dl = DataLoader(ds, batch_size = batch_size, **dl_kwargs)\n",
    "        self.train_dl = self.accelerator.prepare(dl)\n",
    "\n",
    "        if not self.split_valid_from_train:\n",
    "            return\n",
    "\n",
    "        self.add_valid_dataset(valid_ds, batch_size = batch_size, **dl_kwargs)\n",
    "\n",
    "    def add_valid_dataset(self, ds, *, batch_size, **dl_kwargs):\n",
    "        if not exists(ds):\n",
    "            return\n",
    "\n",
    "        assert not exists(self.valid_dl), 'validation dataloader was already added'\n",
    "\n",
    "        dl = DataLoader(ds, batch_size = batch_size, **dl_kwargs)\n",
    "        self.valid_dl = self.accelerator.prepare(dl)\n",
    "\n",
    "    def create_train_iter(self):\n",
    "        assert exists(self.train_dl), 'training dataloader has not been registered with the trainer yet'\n",
    "\n",
    "        if exists(self.train_dl_iter):\n",
    "            return\n",
    "\n",
    "        self.train_dl_iter = cycle(self.train_dl)\n",
    "\n",
    "    def create_valid_iter(self):\n",
    "        assert exists(self.valid_dl), 'validation dataloader has not been registered with the trainer yet'\n",
    "\n",
    "        if exists(self.valid_dl_iter):\n",
    "            return\n",
    "\n",
    "        self.valid_dl_iter = cycle(self.valid_dl)\n",
    "\n",
    "    def train_step(self, unet_number = None, **kwargs):\n",
    "        self.create_train_iter()\n",
    "        loss = self.step_with_dl_iter(self.train_dl_iter, unet_number = unet_number, **kwargs)\n",
    "        self.update(unet_number = unet_number)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    @eval_decorator\n",
    "    def valid_step(self, **kwargs):\n",
    "        self.create_valid_iter()\n",
    "\n",
    "        context = self.use_ema_unets if kwargs.pop('use_ema_unets', False) else nullcontext\n",
    "\n",
    "        with context():\n",
    "            loss = self.step_with_dl_iter(self.valid_dl_iter, **kwargs)\n",
    "        return loss\n",
    "\n",
    "    def step_with_dl_iter(self, dl_iter, **kwargs):\n",
    "        dl_tuple_output = cast_tuple(next(dl_iter))\n",
    "        model_input = dict(list(zip(self.dl_tuple_output_keywords_names, dl_tuple_output)))\n",
    "        loss = self.forward(**{**kwargs, **model_input})\n",
    "        return loss\n",
    "\n",
    "    # checkpointing functions\n",
    "\n",
    "    @property\n",
    "    def all_checkpoints_sorted(self):\n",
    "        glob_pattern = os.path.join(self.checkpoint_path, '*.pt')\n",
    "        checkpoints = self.fs.glob(glob_pattern)\n",
    "        sorted_checkpoints = sorted(checkpoints, key = lambda x: int(str(x).split('.')[-2]), reverse = True)\n",
    "        return sorted_checkpoints\n",
    "\n",
    "    def load_from_checkpoint_folder(self, last_total_steps = -1):\n",
    "        if last_total_steps != -1:\n",
    "            filepath = os.path.join(self.checkpoint_path, f'checkpoint.{last_total_steps}.pt')\n",
    "            self.load(filepath)\n",
    "            return\n",
    "\n",
    "        sorted_checkpoints = self.all_checkpoints_sorted\n",
    "\n",
    "        if len(sorted_checkpoints) == 0:\n",
    "            self.print(f'no checkpoints found to load from at {self.checkpoint_path}')\n",
    "            return\n",
    "\n",
    "        last_checkpoint = sorted_checkpoints[0]\n",
    "        self.load(last_checkpoint)\n",
    "\n",
    "    def save_to_checkpoint_folder(self):\n",
    "        self.accelerator.wait_for_everyone()\n",
    "\n",
    "        if not self.can_checkpoint:\n",
    "            return\n",
    "\n",
    "        total_steps = int(self.steps.sum().item())\n",
    "        filepath = os.path.join(self.checkpoint_path, f'checkpoint.{total_steps}.pt')\n",
    "\n",
    "        self.save(filepath)\n",
    "\n",
    "        if self.max_checkpoints_keep <= 0:\n",
    "            return\n",
    "\n",
    "        sorted_checkpoints = self.all_checkpoints_sorted\n",
    "        checkpoints_to_discard = sorted_checkpoints[self.max_checkpoints_keep:]\n",
    "\n",
    "        for checkpoint in checkpoints_to_discard:\n",
    "            self.fs.rm(checkpoint)\n",
    "\n",
    "    # saving and loading functions\n",
    "\n",
    "    def save(\n",
    "        self,\n",
    "        path,\n",
    "        overwrite = True,\n",
    "        without_optim_and_sched = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.accelerator.wait_for_everyone()\n",
    "\n",
    "        if not self.can_checkpoint:\n",
    "            return\n",
    "\n",
    "        fs = self.fs\n",
    "\n",
    "        assert not (fs.exists(path) and not overwrite)\n",
    "\n",
    "        self.reset_ema_unets_all_one_device()\n",
    "\n",
    "        save_obj = dict(\n",
    "            model = self.imagen.state_dict(),\n",
    "            version = __version__,\n",
    "            steps = self.steps.cpu(),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        save_optim_and_sched_iter = range(0, self.num_unets) if not without_optim_and_sched else tuple()\n",
    "\n",
    "        for ind in save_optim_and_sched_iter:\n",
    "            scaler_key = f'scaler{ind}'\n",
    "            optimizer_key = f'optim{ind}'\n",
    "            scheduler_key = f'scheduler{ind}'\n",
    "            warmup_scheduler_key = f'warmup{ind}'\n",
    "\n",
    "            scaler = getattr(self, scaler_key)\n",
    "            optimizer = getattr(self, optimizer_key)\n",
    "            scheduler = getattr(self, scheduler_key)\n",
    "            warmup_scheduler = getattr(self, warmup_scheduler_key)\n",
    "\n",
    "            if exists(scheduler):\n",
    "                save_obj = {**save_obj, scheduler_key: scheduler.state_dict()}\n",
    "\n",
    "            if exists(warmup_scheduler):\n",
    "                save_obj = {**save_obj, warmup_scheduler_key: warmup_scheduler.state_dict()}\n",
    "\n",
    "            save_obj = {**save_obj, scaler_key: scaler.state_dict(), optimizer_key: optimizer.state_dict()}\n",
    "\n",
    "        if self.use_ema:\n",
    "            save_obj = {**save_obj, 'ema': self.ema_unets.state_dict()}\n",
    "\n",
    "        # determine if imagen config is available\n",
    "\n",
    "        if hasattr(self.imagen, '_config'):\n",
    "            self.print(f'this checkpoint is commandable from the CLI - \"imagen --model {str(path)} \\\"<prompt>\\\"\"')\n",
    "\n",
    "            save_obj = {\n",
    "                **save_obj,\n",
    "                'imagen_type': 'elucidated' if self.is_elucidated else 'original',\n",
    "                'imagen_params': self.imagen._config\n",
    "            }\n",
    "\n",
    "        #save to path\n",
    "\n",
    "        with fs.open(path, 'wb') as f:\n",
    "            torch.save(save_obj, f)\n",
    "\n",
    "        self.print(f'checkpoint saved to {path}')\n",
    "\n",
    "    def load(self, path, only_model = False, strict = True, noop_if_not_exist = False):\n",
    "        fs = self.fs\n",
    "\n",
    "        if noop_if_not_exist and not fs.exists(path):\n",
    "            self.print(f'trainer checkpoint not found at {str(path)}')\n",
    "            return\n",
    "\n",
    "        assert fs.exists(path), f'{path} does not exist'\n",
    "\n",
    "        self.reset_ema_unets_all_one_device()\n",
    "\n",
    "        # to avoid extra GPU memory usage in main process when using Accelerate\n",
    "\n",
    "        with fs.open(path) as f:\n",
    "            loaded_obj = torch.load(f, map_location='cpu')\n",
    "\n",
    "        if version.parse(__version__) != version.parse(loaded_obj['version']):\n",
    "            self.print(f'loading saved imagen at version {loaded_obj[\"version\"]}, but current package version is {__version__}')\n",
    "\n",
    "        try:\n",
    "            self.imagen.load_state_dict(loaded_obj['model'], strict = strict)\n",
    "        except RuntimeError:\n",
    "            print(\"Failed loading state dict. Trying partial load\")\n",
    "            self.imagen.load_state_dict(restore_parts(self.imagen.state_dict(),\n",
    "                                                      loaded_obj['model']))\n",
    "\n",
    "        if only_model:\n",
    "            return loaded_obj\n",
    "\n",
    "        self.steps.copy_(loaded_obj['steps'])\n",
    "\n",
    "        for ind in range(0, self.num_unets):\n",
    "            scaler_key = f'scaler{ind}'\n",
    "            optimizer_key = f'optim{ind}'\n",
    "            scheduler_key = f'scheduler{ind}'\n",
    "            warmup_scheduler_key = f'warmup{ind}'\n",
    "\n",
    "            scaler = getattr(self, scaler_key)\n",
    "            optimizer = getattr(self, optimizer_key)\n",
    "            scheduler = getattr(self, scheduler_key)\n",
    "            warmup_scheduler = getattr(self, warmup_scheduler_key)\n",
    "\n",
    "            if exists(scheduler) and scheduler_key in loaded_obj:\n",
    "                scheduler.load_state_dict(loaded_obj[scheduler_key])\n",
    "\n",
    "            if exists(warmup_scheduler) and warmup_scheduler_key in loaded_obj:\n",
    "                warmup_scheduler.load_state_dict(loaded_obj[warmup_scheduler_key])\n",
    "\n",
    "            if exists(optimizer):\n",
    "                try:\n",
    "                    optimizer.load_state_dict(loaded_obj[optimizer_key])\n",
    "                    scaler.load_state_dict(loaded_obj[scaler_key])\n",
    "                except:\n",
    "                    self.print('could not load optimizer and scaler, possibly because you have turned on mixed precision training since the last run. resuming with new optimizer and scalers')\n",
    "\n",
    "        if self.use_ema:\n",
    "            assert 'ema' in loaded_obj\n",
    "            try:\n",
    "                self.ema_unets.load_state_dict(loaded_obj['ema'], strict = strict)\n",
    "            except RuntimeError:\n",
    "                print(\"Failed loading state dict. Trying partial load\")\n",
    "                self.ema_unets.load_state_dict(restore_parts(self.ema_unets.state_dict(),\n",
    "                                                             loaded_obj['ema']))\n",
    "\n",
    "        self.print(f'checkpoint loaded from {path}')\n",
    "        return loaded_obj\n",
    "\n",
    "    # managing ema unets and their devices\n",
    "\n",
    "    @property\n",
    "    def unets(self):\n",
    "        return nn.ModuleList([ema.ema_model for ema in self.ema_unets])\n",
    "\n",
    "    def get_ema_unet(self, unet_number = None):\n",
    "        if not self.use_ema:\n",
    "            return\n",
    "\n",
    "        unet_number = self.validate_unet_number(unet_number)\n",
    "        index = unet_number - 1\n",
    "\n",
    "        if isinstance(self.unets, nn.ModuleList):\n",
    "            unets_list = [unet for unet in self.ema_unets]\n",
    "            delattr(self, 'ema_unets')\n",
    "            self.ema_unets = unets_list\n",
    "\n",
    "        if index != self.ema_unet_being_trained_index:\n",
    "            for unet_index, unet in enumerate(self.ema_unets):\n",
    "                unet.to(self.device if unet_index == index else 'cpu')\n",
    "\n",
    "        self.ema_unet_being_trained_index = index\n",
    "        return self.ema_unets[index]\n",
    "\n",
    "    def reset_ema_unets_all_one_device(self, device = None):\n",
    "        if not self.use_ema:\n",
    "            return\n",
    "\n",
    "        device = default(device, self.device)\n",
    "        self.ema_unets = nn.ModuleList([*self.ema_unets])\n",
    "        self.ema_unets.to(device)\n",
    "\n",
    "        self.ema_unet_being_trained_index = -1\n",
    "\n",
    "    @torch.no_grad()\n",
    "    @contextmanager\n",
    "    def use_ema_unets(self):\n",
    "        if not self.use_ema:\n",
    "            output = yield\n",
    "            return output\n",
    "\n",
    "        self.reset_ema_unets_all_one_device()\n",
    "        self.imagen.reset_unets_all_one_device()\n",
    "\n",
    "        self.unets.eval()\n",
    "\n",
    "        trainable_unets = self.imagen.unets\n",
    "        self.imagen.unets = self.unets                  # swap in exponential moving averaged unets for sampling\n",
    "\n",
    "        output = yield\n",
    "\n",
    "        self.imagen.unets = trainable_unets             # restore original training unets\n",
    "\n",
    "        # cast the ema_model unets back to original device\n",
    "        for ema in self.ema_unets:\n",
    "            ema.restore_ema_model_device()\n",
    "\n",
    "        return output\n",
    "\n",
    "    def print_unet_devices(self):\n",
    "        self.print('unet devices:')\n",
    "        for i, unet in enumerate(self.imagen.unets):\n",
    "            device = next(unet.parameters()).device\n",
    "            self.print(f'\\tunet {i}: {device}')\n",
    "\n",
    "        if not self.use_ema:\n",
    "            return\n",
    "\n",
    "        self.print('\\nema unet devices:')\n",
    "        for i, ema_unet in enumerate(self.ema_unets):\n",
    "            device = next(ema_unet.parameters()).device\n",
    "            self.print(f'\\tema unet {i}: {device}')\n",
    "\n",
    "    # overriding state dict functions\n",
    "\n",
    "    def state_dict(self, *args, **kwargs):\n",
    "        self.reset_ema_unets_all_one_device()\n",
    "        return super().state_dict(*args, **kwargs)\n",
    "\n",
    "    def load_state_dict(self, *args, **kwargs):\n",
    "        self.reset_ema_unets_all_one_device()\n",
    "        return super().load_state_dict(*args, **kwargs)\n",
    "\n",
    "    # encoding text functions\n",
    "\n",
    "    def encode_text(self, text, **kwargs):\n",
    "        return self.imagen.encode_text(text, **kwargs)\n",
    "\n",
    "    # forwarding functions and gradient step updates\n",
    "\n",
    "    def update(self, unet_number = None):\n",
    "        unet_number = self.validate_unet_number(unet_number)\n",
    "        self.validate_and_set_unet_being_trained(unet_number)\n",
    "        self.set_accelerator_scaler(unet_number)\n",
    "\n",
    "        index = unet_number - 1\n",
    "        unet = self.unet_being_trained\n",
    "\n",
    "        optimizer = getattr(self, f'optim{index}')\n",
    "        scaler = getattr(self, f'scaler{index}')\n",
    "        scheduler = getattr(self, f'scheduler{index}')\n",
    "        warmup_scheduler = getattr(self, f'warmup{index}')\n",
    "\n",
    "        # set the grad scaler on the accelerator, since we are managing one per u-net\n",
    "\n",
    "        if exists(self.max_grad_norm):\n",
    "            self.accelerator.clip_grad_norm_(unet.parameters(), self.max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if self.use_ema:\n",
    "            ema_unet = self.get_ema_unet(unet_number)\n",
    "            ema_unet.update()\n",
    "\n",
    "        # scheduler, if needed\n",
    "\n",
    "        maybe_warmup_context = nullcontext() if not exists(warmup_scheduler) else warmup_scheduler.dampening()\n",
    "\n",
    "        with maybe_warmup_context:\n",
    "            if exists(scheduler) and not self.accelerator.optimizer_step_was_skipped: # recommended in the docs\n",
    "                scheduler.step()\n",
    "\n",
    "        self.steps += F.one_hot(torch.tensor(unet_number - 1, device = self.steps.device), num_classes = len(self.steps))\n",
    "\n",
    "        if not exists(self.checkpoint_path):\n",
    "            return\n",
    "\n",
    "        total_steps = int(self.steps.sum().item())\n",
    "\n",
    "        if total_steps % self.checkpoint_every:\n",
    "            return\n",
    "\n",
    "        self.save_to_checkpoint_folder()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    @cast_torch_tensor\n",
    "    @imagen_sample_in_chunks\n",
    "    def sample(self, *args, **kwargs):\n",
    "        context = nullcontext if  kwargs.pop('use_non_ema', False) else self.use_ema_unets\n",
    "\n",
    "        self.print_untrained_unets()        \n",
    "        \n",
    "        if not self.is_main:\n",
    "            kwargs['use_tqdm'] = False\n",
    "\n",
    "        with context():\n",
    "            output = self.imagen.sample(*args, device = self.device, **kwargs)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @partial(cast_torch_tensor, cast_fp16 = True)\n",
    "    def forward(\n",
    "        self,\n",
    "        *args,\n",
    "        unet_number = None,\n",
    "        max_batch_size = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        unet_number = self.validate_unet_number(unet_number)\n",
    "        self.validate_and_set_unet_being_trained(unet_number)\n",
    "        self.set_accelerator_scaler(unet_number)\n",
    "\n",
    "        assert not exists(self.only_train_unet_number) or self.only_train_unet_number == unet_number, f'you can only train unet #{self.only_train_unet_number}'\n",
    "\n",
    "        total_loss = 0.\n",
    "\n",
    "        for chunk_size_frac, (chunked_args, chunked_kwargs) in split_args_and_kwargs(*args, split_size = max_batch_size, **kwargs):\n",
    "            with self.accelerator.autocast():\n",
    "                loss = self.model(*chunked_args, unet_number = unet_number, **chunked_kwargs)\n",
    "                loss = loss * chunk_size_frac\n",
    "\n",
    "            total_loss += loss#.item()\n",
    "\n",
    "            if self.training:\n",
    "                self.accelerator.backward(loss)\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70c5147c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_fasta (sequence, filename_out):\n",
    "    \n",
    "    with open (filename_out, mode ='w') as f:\n",
    "        f.write (f'>{filename_out}\\n')\n",
    "        f.write (f'{sequence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2816c032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_sequence (model,\n",
    "                X=None, #this is the target conventionally when using text embd\n",
    "                 flag=0,\n",
    "                     cond_scales=1.,foldproteins=False,X_string=None,\n",
    "                     x_data=None,  \n",
    "                                     skip_steps=0,\n",
    "                                     inpaint_images = None,\n",
    "                                     inpaint_masks = None,\n",
    "                                        inpaint_resample_times = None,\n",
    "                                        init_images = None,\n",
    "                     num_cycle=16,\n",
    "               ):\n",
    "    steps=0\n",
    "    e=flag\n",
    "\n",
    "    if X!=None:\n",
    "        print (f\"Producing {len(X)} samples...from text conditioning X...\")\n",
    "        lenn_val=len(X)\n",
    "    if X_string!=None:\n",
    "        lenn_val=len(X_string)\n",
    "        print (f\"Producing {len(X_string)} samples...from text conditioning X_String (from string)...\")\n",
    "    \n",
    "    if x_data!=None:\n",
    "        print (f\"Producing {len(x_data)} samples...from image conditingig x_data  ...\")\n",
    "        lenn_val=len(x_data)\n",
    "        print (x_data)\n",
    "        \n",
    "    print ('Device: ', device)\n",
    "\n",
    "    for iisample in range (lenn_val):\n",
    "        X_cond=None  \n",
    "        if X_string==None and X != None: #only do if X provided\n",
    "            X_cond=torch.Tensor (X[iisample]).to(device).unsqueeze (0)\n",
    "        if X_string !=None:\n",
    "            X = tokenizer_X.texts_to_sequences(X_string[iisample])\n",
    "            X= sequence.pad_sequences(X,  maxlen=max_length, padding='post', truncating='post')  \n",
    "            X=np.array(X)\n",
    "            X_cond=torch.from_numpy(X).float()/Xnormfac\n",
    "        \n",
    "        result=model.sample ( x=X_cond,stop_at_unet_number=train_unet_number ,\n",
    "                                 cond_scale=cond_scales ,\n",
    "                            x_data=x_data, skip_steps=skip_steps,\n",
    "                     inpaint_images = inpaint_images,\n",
    "                    inpaint_masks = inpaint_masks,\n",
    "                    inpaint_resample_times = inpaint_resample_times,\n",
    "                    init_images = init_images,device=device,\n",
    "                            \n",
    "                            )\n",
    "        result=torch.round(result*ynormfac)\n",
    "        \n",
    "        plt.plot (result[0,0,:].cpu().detach().numpy(),label= f'Predicted')\n",
    "       \n",
    "        plt.legend()\n",
    "\n",
    "        outname = prefix+ f\"sampled_from_X_{flag}_condscale-{str (cond_scales)}_{e}_{steps}.jpg\"\n",
    "        \n",
    "        plt.savefig(outname, dpi=200)\n",
    "        plt.show ()\n",
    "\n",
    "        to_rev=result[:,0,:] \n",
    "        to_rev=to_rev.long().cpu().detach().numpy()\n",
    "       \n",
    "        y_data_reversed=tokenizer_y.sequences_to_texts (to_rev)\n",
    "\n",
    "        for iii in range (len(y_data_reversed)):\n",
    "            y_data_reversed[iii]=y_data_reversed[iii].upper().strip().replace(\" \", \"\")\n",
    "        \n",
    "        ### reverse second structure input....\n",
    "        if X_cond != None:\n",
    "            X_cond=torch.round(X_cond*Xnormfac)\n",
    "\n",
    "            to_rev=X_cond[:,:] \n",
    "            to_rev=to_rev.long().cpu().detach().numpy()\n",
    "            print (to_rev.shape)\n",
    "            X_data_reversed=tokenizer_X.sequences_to_texts (to_rev)\n",
    "\n",
    "            for iii in range (len(y_data_reversed)):\n",
    "                X_data_reversed[iii]=X_data_reversed[iii].upper().strip().replace(\" \", \"\")\n",
    "        if x_data !=None:\n",
    "            X_data_reversed=x_data #is already in sequence fromat..\n",
    "               \n",
    "\n",
    "        print (f\"For {X} or {X_data_reversed[iisample]}, predicted sequence\", y_data_reversed[iisample])\n",
    "        if foldproteins:\n",
    "            \n",
    "            if X_cond != None:\n",
    "                xbc=X_cond[iisample,:].cpu().detach().numpy()\n",
    "                out_nam=np.array2string(xbc, formatter={'float_kind':lambda xbc: \"%.1f\" % xbc})+f'_{flag}_{steps}'\n",
    "            if x_data !=None:\n",
    "                \n",
    "                out_nam=x_data[iisample] \n",
    "             \n",
    "            \n",
    "            tempname='temp'\n",
    "            pdb_file=foldandsavePDB (sequence=y_data_reversed[0], \n",
    "                                                 filename_out=tempname, \n",
    "                                                 num_cycle=num_cycle, flag=flag)\n",
    "\n",
    "            out_nam_fasta=f'{prefix}{out_nam}_{flag}_{steps}.fasta'\n",
    "\n",
    "            write_fasta (y_data_reversed[0], out_nam_fasta)            \n",
    "            \n",
    "        \n",
    "            out_nam=f'{prefix}{X_data_reversed[iisample]}_{flag}_{steps}.pdb'\n",
    "            shutil.copy (pdb_file, out_nam) #source, dest\n",
    "            pdb_file=out_nam\n",
    "            \n",
    "            print (f\"Properly named PDB file produced: {pdb_file}\")\n",
    "            \n",
    "            view=show_pdb(pdb_file=pdb_file, flag=flag,\n",
    "                          show_sidechains=show_sidechains, show_mainchains=show_mainchains, color=color)\n",
    "            view.show()\n",
    "\n",
    "        steps=steps+1\n",
    "        \n",
    "        return pdb_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "decd98a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_loop (model,\n",
    "                train_loader,\n",
    "                cond_scales=[7.5], #list of cond scales - each sampled...\n",
    "                num_samples=2, #how many samples produced every time tested.....\n",
    "                timesteps=100,\n",
    "                 flag=0,foldproteins=False,\n",
    "                 use_text_embedd=True,skip_steps=0,\n",
    "                 \n",
    "               ):\n",
    "    steps=0\n",
    "    e=flag\n",
    "    for item  in train_loader:\n",
    "\n",
    "            X_train_batch= item[0].to(device)\n",
    "            y_train_batch=item[1].to(device)\n",
    "\n",
    "            GT=y_train_batch.cpu().detach() \n",
    "                    \n",
    "            GT= GT.unsqueeze(1)\n",
    "            num_samples = min (num_samples,y_train_batch.shape[0] )\n",
    "            print (f\"Producing {num_samples} samples...\")\n",
    "            \n",
    "            print ('X_train_batch shape: ', X_train_batch.shape)\n",
    "\n",
    "            for iisample in range (len (cond_scales)):\n",
    "                \n",
    "                if use_text_embedd:\n",
    "                    result=model.sample (x= X_train_batch,stop_at_unet_number=train_unet_number ,\n",
    "                                         cond_scale=cond_scales[iisample], device=device, skip_steps=skip_steps)\n",
    "                else:\n",
    "                    result=model.sample (x= None, x_data_tokenized= X_train_batch,\n",
    "                                         stop_at_unet_number=train_unet_number ,\n",
    "                                         cond_scale=cond_scales[iisample],device=device,skip_steps=skip_steps)\n",
    "                    \n",
    "                result=torch.round(result*ynormfac)\n",
    "                GT=torch.round (GT*ynormfac)\n",
    "\n",
    "                for samples in range  (num_samples):\n",
    "                    print (\"sample \", samples, \"out of \", num_samples)\n",
    "                    \n",
    "                    plt.plot (result[samples,0,:].cpu().detach().numpy(),label= f'Predicted')\n",
    "                    plt.plot (GT[samples,0,:],label= f'GT {0}')\n",
    "                    plt.legend()\n",
    "\n",
    "                    outname = prefix+ f\"sample-{samples}_condscale-{str (cond_scales[iisample])}_{e}_{steps}.jpg\"\n",
    "                   \n",
    "                    plt.savefig(outname, dpi=200)\n",
    "                    plt.show ()\n",
    "                    \n",
    "                    #reverse y sequence\n",
    "                    to_rev=result[:,0,:]\n",
    "                    to_rev=to_rev.long().cpu().detach().numpy()\n",
    "                    \n",
    "                    y_data_reversed=tokenizer_y.sequences_to_texts (to_rev)\n",
    "\n",
    "                    for iii in range (len(y_data_reversed)):\n",
    "                        y_data_reversed[iii]=y_data_reversed[iii].upper().strip().replace(\" \", \"\")\n",
    "                        \n",
    "                    #reverse GT_y sequence\n",
    "                    to_rev=GT[:,0,:]\n",
    "                    to_rev=to_rev.long().cpu().detach().numpy()\n",
    "                    \n",
    "                    GT_y_data_reversed=tokenizer_y.sequences_to_texts (to_rev)\n",
    "\n",
    "                    for iii in range (len(y_data_reversed)):\n",
    "                        GT_y_data_reversed[iii]=GT_y_data_reversed[iii].upper().strip().replace(\" \", \"\")\n",
    "                    \n",
    "                    ### reverse second structure input....\n",
    "                    to_rev=torch.round (X_train_batch[:,:]*Xnormfac)\n",
    "                    to_rev=to_rev.long().cpu().detach().numpy()\n",
    "                   \n",
    "                    X_data_reversed=tokenizer_X.sequences_to_texts (to_rev)\n",
    "\n",
    "                    for iii in range (len(y_data_reversed)):\n",
    "                        X_data_reversed[iii]=X_data_reversed[iii].upper().strip().replace(\" \", \"\")\n",
    "\n",
    "                    print (f\"For {X_train_batch[samples,:].cpu().detach().numpy()} or {X_data_reversed[samples]}, predicted sequence\", y_data_reversed[samples])\n",
    "                    print (f\"Ground truth: {GT_y_data_reversed[samples]}\")\n",
    "                   \n",
    "                    if foldproteins:\n",
    "                        xbc=X_train_batch[samples,:].cpu().detach().numpy()\n",
    "                        out_nam=np.array2string(xbc, formatter={'float_kind':lambda xbc: \"%.1f\" % xbc})\n",
    "                        tempname='temp'\n",
    "                        pdb_file=foldandsavePDB (sequence=y_data_reversed[samples], \n",
    "                                                             filename_out=tempname, \n",
    "                                                             num_cycle=16, flag=flag)\n",
    "                        #out_nam=f'{prefix}{out_nam}.pdb'\n",
    "                        out_nam=f'{prefix}{X_data_reversed[samples]}.pdb'\n",
    "                        print (f'Original PDB: {pdb_file} OUT: {out_nam}')\n",
    "                        shutil.copy (pdb_file, out_nam) #source, dest\n",
    "                        pdb_file=out_nam\n",
    "                        print (f\"Properly named PDB file produced: {pdb_file}\")\n",
    "                        \n",
    "                        view=show_pdb(pdb_file=pdb_file, flag=flag, show_sidechains=show_sidechains,  show_mainchains=show_mainchains, color=color)\n",
    "                        view.show()\n",
    "\n",
    "                    steps=steps+1\n",
    "            if steps>num_samples:\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39b2cc38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop (model,\n",
    "                train_loader,\n",
    "                test_loader,\n",
    "                optimizer=None,\n",
    "                print_every=10,\n",
    "                epochs= 300,\n",
    "                start_ep=0,\n",
    "                start_step=0,\n",
    "                train_unet_number=1,\n",
    "                print_loss=1000,\n",
    "                trainer=None,\n",
    "                plot_unscaled=False,\n",
    "                max_batch_size=4,\n",
    "                save_model=False,\n",
    "                cond_scales=[7.5], #list of cond scales - each sampled...\n",
    "                num_samples=2, #how many samples produced every time tested.....\n",
    "                foldproteins=False,\n",
    "                cond_image=False, #use cond_images...\n",
    "                \n",
    "               ):\n",
    "    \n",
    "    if not exists (trainer):\n",
    "        if not exists (optimizer):\n",
    "            print (\"ERROR: If trainer not used, need to provide optimizer.\")\n",
    "    if exists (trainer):\n",
    "        print (\"Trainer provided... will be used\")\n",
    "    steps=start_step\n",
    "    \n",
    "    loss_total=0\n",
    "    for e in range(1, epochs+1):\n",
    "            start = time.time()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            print (\"######################################################################################\")\n",
    "            start = time.time()\n",
    "            print (\"NOW: Training epoch: \", e+start_ep)\n",
    "\n",
    "            train_epoch_loss = 0\n",
    "            model.train()\n",
    "            \n",
    "            print (\"Loop over \", len(train_loader), \" batches (print . every \", print_every, \" steps)\")\n",
    "            \n",
    "            for item  in train_loader:\n",
    "\n",
    "                X_train_batch= item[0].to(device)\n",
    "\n",
    "                y_train_batch=item[1].to(device)\n",
    "\n",
    "                if exists (trainer):\n",
    "                    if cond_image==False:\n",
    "                        loss = trainer(y_train_batch.unsqueeze(1) ,\n",
    "                                x=X_train_batch,  \n",
    "                                unet_number=train_unet_number,\n",
    "                                max_batch_size = max_batch_size,    # auto divide the batch of 64 up into batch size of 4 and accumulate gradients, so it all fits in memory\n",
    "                            )\n",
    "                    if cond_image==True:\n",
    "                       \n",
    "                        loss = trainer(y_train_batch.unsqueeze(1) ,x=None,\n",
    "                                cond_images=X_train_batch.unsqueeze(1), \n",
    "                                unet_number=train_unet_number,\n",
    "                                max_batch_size = max_batch_size, \n",
    "                                        # auto divide the batch of 64 up into batch size of 4 and accumulate gradients, so it all fits in memory\n",
    "                            )\n",
    "                    trainer.update(unet_number = train_unet_number)\n",
    "\n",
    "                else:\n",
    "                    optimizer.zero_grad()\n",
    "                    if cond_image==False:\n",
    "                        loss=model (y_train_batch.unsqueeze(1) , x=X_train_batch, unet_number=train_unet_number)\n",
    "                    if cond_image==True:\n",
    "                        loss=model (y_train_batch.unsqueeze(1) ,x=None, cond_images=X_train_batch.unsqueeze(1), unet_number=train_unet_number)\n",
    "                    \n",
    "                    loss.backward( )\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                loss_total=loss_total+loss.item()\n",
    "                \n",
    "                if steps % print_every == 0:\n",
    "                    print(\".\", end=\"\")\n",
    "                    \n",
    "                if steps>0:\n",
    "                    if steps % print_loss == 0:\n",
    "\n",
    "                        if plot_unscaled:\n",
    "                            #test before scaling...\n",
    "                            plt.plot (y_train_batch.unsqueeze(1)[0,0,:].cpu().detach().numpy(),label= 'Unscaled GT')\n",
    "                            plt.legend()\n",
    "                            plt.show()\n",
    "\n",
    "                    \n",
    "                        GT=y_train_batch.cpu().detach() \n",
    "                        \n",
    "                        GT=resize_image_to(\n",
    "                            GT.unsqueeze(1),\n",
    "                            model.imagen.image_sizes[train_unet_number-1],\n",
    "\n",
    "                        )\n",
    "\n",
    "                        norm_loss=loss_total/print_loss\n",
    "                        print (f\"\\nTOTAL LOSS at epoch={e}, step={steps}: {norm_loss}\")\n",
    "\n",
    "                        loss_list.append (norm_loss)\n",
    "                        loss_total=0\n",
    "\n",
    "                        plt.plot (loss_list, label='Loss')\n",
    "                        plt.legend()\n",
    "\n",
    "                        outname = prefix+ f\"loss_{e}_{steps}.jpg\"\n",
    "                        plt.savefig(outname, dpi=200)\n",
    "                        plt.show()\n",
    "                        \n",
    "                        ####\n",
    "                        num_samples = min (num_samples,y_train_batch.shape[0] )\n",
    "                        print (f\"Producing {num_samples} samples...\")\n",
    "                        \n",
    "                    \n",
    "                        if cond_image == True:\n",
    "                            use_text_embedd=False\n",
    "                        else:\n",
    "                            use_text_embedd=True\n",
    "                            \n",
    "                        sample_loop (model,\n",
    "                            test_loader,\n",
    "                            cond_scales=cond_scales,# #list of cond scales - each sampled...\n",
    "                            num_samples=num_samples, #how many samples produced every time tested.....\n",
    "                            timesteps=64,\n",
    "                                    flag=steps,\n",
    "                                     #reverse=False,\n",
    "                                     foldproteins=foldproteins,use_text_embedd= use_text_embedd,\n",
    "                                    )   \n",
    "                        \n",
    "                        #index_word': '{\"1\": \"~\", \"2\": \"h\", \"3\": \"e\", \"4\": \"s\", \"5\": \"t\", \"6\": \"g\", \"7\": \"b\", \"8\": \"i\"}', \n",
    "                        #'word_index': '{\"~\": 1, \"h\": 2, \"e\": 3, \"s\": 4, \"t\": 5, \"g\": 6, \"b\": 7, \"i\": 8}'}\n",
    "                        \n",
    "                        AH_code=2/Xnormfac\n",
    "                        BS_code=3/Xnormfac\n",
    "                        unstr_code= 1/Xnormfac\n",
    "                        \n",
    "                        print (\"SAMPLING FOR DE NOVO:\")\n",
    "                        \n",
    "                        sample_sequence (model,\n",
    "                           x_data=['~~~HHHHHHHHHHHHHHH~~'],\n",
    "                             flag=steps,cond_scales=1.,foldproteins=True,\n",
    "                           )\n",
    "                        sample_sequence (model,\n",
    "                           x_data=['~~~HHHHHHHHHHHHHHH~~~~HHHHHHHHHHHHHH~~~'],\n",
    "                             flag=steps,cond_scales=1.,foldproteins=True,\n",
    "                           )\n",
    "                        sample_sequence (model,\n",
    "                           x_data=['~~EEESSTTS~SEEEEEEEEE~SBS~EEEEEE~~'],\n",
    "                             flag=steps,cond_scales=1.,foldproteins=True,\n",
    "                           )\n",
    "                    \n",
    "                if steps>0:\n",
    "                    if save_model and steps % print_loss==0:\n",
    "                        fname=f\"{prefix}trainer_save-model-epoch_{e}.pt\"\n",
    "                        trainer.save(fname)\n",
    "                        print (f\"Model saved: \", fname)\n",
    "                        fname=f\"{prefix}statedict_save-model-epoch_{e}.pt\"\n",
    "                        torch.save(model.state_dict(), fname)\n",
    "                        print (f\"Statedict model saved: \", fname)\n",
    "\n",
    "                steps=steps+1\n",
    "                                         \n",
    "            print (f\"\\n\\n-------------------\\nTime for epoch {e}={(time.time()-start)/60}\\n-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "71e205a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install py3Dmol\n",
    "#poymol vis: https://gist.github.com/bougui505/11401240    \n",
    "\n",
    "def foldandsavePDB (sequence, filename_out, num_cycle=16, flag=0):\n",
    "    filename=f\"{prefix}fasta_in_{flag}.fasta\"\n",
    "    print (\"Writing FASTA file: \", filename)\n",
    "    OUTFILE=f\"{filename_out}_{flag}\"\n",
    "    with open (filename, mode ='w') as f:\n",
    "        f.write (f'>{OUTFILE}\\n')\n",
    "        f.write (f'{sequence}')\n",
    "        \n",
    "    print (f\"Now run OmegaFold.... on device={device}\")    \n",
    "    !omegafold $filename $prefix --num_cycle $num_cycle --device=$device\n",
    "    print (\"Done OmegaFold\")\n",
    "    \n",
    "    PDB_result=f\"{prefix}{OUTFILE}.PDB\"\n",
    "    print (f\"Resulting PDB file...:  {PDB_result}\")\n",
    "    \n",
    "    return PDB_result\n",
    "\n",
    "import py3Dmol\n",
    "def plot_plddt_legend(dpi=100):\n",
    "  thresh = ['plDDT:','Very low (<50)','Low (60)','OK (70)','Confident (80)','Very high (>90)']\n",
    "  plt.figure(figsize=(1,0.1),dpi=dpi)\n",
    "  ########################################\n",
    "  for c in [\"#FFFFFF\",\"#FF0000\",\"#FFFF00\",\"#00FF00\",\"#00FFFF\",\"#0000FF\"]:\n",
    "    plt.bar(0, 0, color=c)\n",
    "  plt.legend(thresh, frameon=False,\n",
    "             loc='center', ncol=6,\n",
    "             handletextpad=1,\n",
    "             columnspacing=1,\n",
    "             markerscale=0.5,)\n",
    "  plt.axis(False)\n",
    "  return plt\n",
    "color = \"lDDT\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
    "show_sidechains = False #@param {type:\"boolean\"}\n",
    "show_mainchains = False #@param {type:\"boolean\"}\n",
    "\n",
    "def show_pdb(pdb_file, flag=0,   show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
    "  model_name = f\"Flag_{flag}\"\n",
    "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
    "  view.addModel(open(pdb_file,'r').read(),'pdb')\n",
    "\n",
    "  if color == \"lDDT\":\n",
    "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
    "  elif color == \"rainbow\":\n",
    "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
    "  elif color == \"chain\":\n",
    "    chains = len(queries[0][1]) + 1 if is_complex else 1\n",
    "    for n,chain,color in zip(range(chains),list(\"ABCDEFGH\"),\n",
    "                     [\"lime\",\"cyan\",\"magenta\",\"yellow\",\"salmon\",\"white\",\"blue\",\"orange\"]):\n",
    "      view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
    "  if show_sidechains:\n",
    "    BB = ['C','O','N']\n",
    "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
    "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
    "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
    "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})  \n",
    "  if show_mainchains:\n",
    "    BB = ['C','O','N','CA']\n",
    "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "\n",
    "  view.zoomTo()\n",
    "  if color == \"lDDT\":\n",
    "      plot_plddt_legend().show() \n",
    "  return view\n",
    "\n",
    "def get_avg_Bfac (file='./output_v3/[0.0 0.5 0.0 0.0 0.0 0.0 0.0 0.0].pdb'):\n",
    "    p = PDBParser()\n",
    "    avg_B=0\n",
    "    bfac_list=[]\n",
    "    \n",
    "    structure = p.get_structure(\"X\", file)\n",
    "    for PDBmodel in structure:\n",
    "        for chain in PDBmodel:\n",
    "             for residue in chain:\n",
    "                     for atom in residue:\n",
    "                       \n",
    "                        Bfac=atom.get_bfactor()\n",
    "                        bfac_list.append(Bfac)\n",
    "                        avg_B=avg_B+Bfac\n",
    "                       \n",
    "    avg_B=avg_B/len (bfac_list)\n",
    "    print (f\"For {file}, average B-factor={avg_B}\")\n",
    "    plt.plot (bfac_list, label='lDDT')\n",
    "    plt.xlabel ('Atom #'   )\n",
    "    plt.ylabel ('iDDT')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return avg_B, bfac_list\n",
    "\n",
    "def sample_sequence_normalized_Bfac (seccs=[0.3, 0.3, 0.1, 0., 0., 0., 0., 0. ]):\n",
    "    sample_numbers=torch.tensor([seccs])\n",
    "    sample_numbers=torch.nn.functional.normalize (sample_numbers, dim=1)\n",
    "    sample_numbers=sample_numbers/torch.sum(sample_numbers)\n",
    "\n",
    "    PDB=sample_sequence (model,\n",
    "                    X=sample_numbers,\n",
    "                     flag=0,cond_scales=1, foldproteins=True,\n",
    "                   )\n",
    "\n",
    "    avg,_ = get_avg_Bfac (file=PDB[0])\n",
    "\n",
    "    return PDB, avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929753a",
   "metadata": {},
   "source": [
    "## Define model and train or load weights, inference, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eb118289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e6d2f200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix='./output_model_B/'\n",
    "if not os.path.exists(prefix):\n",
    "        os.mkdir (prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "430fe3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_dim=1\n",
    "train_unet_number=1 #have only one unet, so must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22b4c12a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 1\n"
     ]
    }
   ],
   "source": [
    "#model parameters\n",
    "\n",
    "dim=256\n",
    "text_embed_dim = 512\n",
    "embed_dim_position=32\n",
    "text_embed_dim=text_embed_dim+embed_dim_position\n",
    "cond_dim = 512\n",
    "cond_images_channels=1\n",
    " \n",
    "unet = OneD_Unet(\n",
    "            dim = dim,  \n",
    "            text_embed_dim = text_embed_dim,\n",
    "            cond_dim = cond_dim, #this is where text embeddings are projected to... \n",
    "            dim_mults = (1, 2, 4, 8),\n",
    "            \n",
    "            num_resnet_blocks = 1, \n",
    "            layer_attns = (False, True, True, False),\n",
    "            layer_cross_attns = (False, True, True, False),\n",
    "            channels=pred_dim,\n",
    "            channels_out=pred_dim ,       \n",
    "        \n",
    "        attn_dim_head = 64,\n",
    "        attn_heads = 8,\n",
    "        ff_mult = 2.,\n",
    "        lowres_cond = False,                # for cascading diffusion - https://cascaded-diffusion.github.io/\n",
    "        cond_images_channels = cond_images_channels,\n",
    "        layer_attns_depth =1, \n",
    "        layer_attns_add_text_cond = True,   # whether to condition the self-attention blocks with the text embeddings, as described in Appendix D.3.1\n",
    "        attend_at_middle = True,            # whether to have a layer of attention at the bottleneck (can turn off for higher resolution in cascading DDPM, before bringing in efficient attention)\n",
    "       \n",
    "        use_linear_attn = False,\n",
    "        use_linear_cross_attn = False,\n",
    "        cond_on_text = True,\n",
    "        max_text_len = max_length,\n",
    "        init_dim = None,\n",
    "        resnet_groups = 8,#8,\n",
    "        init_conv_kernel_size =7,           # kernel size of initial conv, if not using cross embed\n",
    "        init_cross_embed = False, #TODO - fix ouput size calcs for conv1d\n",
    "        init_cross_embed_kernel_sizes = (3, 7, 15),\n",
    "        cross_embed_downsample = False,\n",
    "        cross_embed_downsample_kernel_sizes = (2, 4),\n",
    "        attn_pool_text = True,\n",
    "        attn_pool_num_latents = 32,   #perceiver model latents \n",
    "        dropout = 0.,\n",
    "        memory_efficient = False,\n",
    "        init_conv_to_final_conv_residual = False,\n",
    "        use_global_context_attn = True,\n",
    "        scale_skip_connection = True,\n",
    "        final_resnet_block = True, #True,\n",
    "        final_conv_kernel_size = 3,#3,\n",
    "        cosine_sim_attn = True,\n",
    "        self_cond = False,\n",
    "        combine_upsample_fmaps = True,      # combine feature maps from all upsample blocks, used in unet squared successfully\n",
    "        pixel_shuffle_upsample = False   ,     # may address checkboard artifacts\n",
    "   \n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3ef246c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model B: Generative protein diffusion model, residue-based\n",
      "Use conditioning image during training....\n",
      "Channels in=1, channels out=1\n",
      "256 1\n",
      "Device used in ImagenEluc:  cuda:0\n",
      "Total model: \n",
      "Total model parameters:  262388274  trainable parameters:  262388274\n",
      "Unet only: \n",
      "Total model parameters:  262381970  trainable parameters:  262381970\n"
     ]
    }
   ],
   "source": [
    "pred_dim=1\n",
    "model_B =ProteinDesigner_B(\n",
    "                            unet,\n",
    "                           timesteps=(96,), dim=dim, pred_dim=pred_dim, \n",
    "                     loss_type=0, elucidated=True,\n",
    "                  padding_idx=0,\n",
    "              \n",
    "                 max_text_len=max_length,\n",
    "               cond_images_channels=pred_dim, #f >0 then wil use cond_images instead of text embdding (or can use both)\n",
    "                )  .to(device)  \n",
    "print (\"Total model: \")\n",
    "params ( model_B)\n",
    "print (\"Unet only: \")\n",
    "params (model_B.imagen.unets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec24aea8-e95f-4d8d-9ea8-4b06fa9e4681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output_model_B/'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26c7c4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model=False #do not train if false\n",
    "\n",
    "if train_model:\n",
    "    train_loop (model,\n",
    "                train_loader,\n",
    "               test_loader,\n",
    "                optimizer=None,\n",
    "                print_every=100,\n",
    "                epochs= 6000,\n",
    "                start_ep=0,\n",
    "            start_step=0,\n",
    "                train_unet_number=1,\n",
    "            print_loss =    50*len (train_loader)-1,\n",
    "            trainer=trainer,\n",
    "            plot_unscaled=False, \n",
    "            max_batch_size =256, \n",
    "            save_model=True,\n",
    "            cond_scales=[1.],\n",
    "            num_samples=1,\n",
    "            foldproteins=True,\n",
    "            cond_image=True,\n",
    "               )\n",
    "else:  #load model\n",
    "    fname=f\"{prefix}Model_B_final.pt\"\n",
    "    model_B.load_state_dict(torch.load(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e06846e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing 1 samples...from image conditingig x_data  ...\n",
      "['~~HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH~~']\n",
      "Device:  cuda:0\n",
      "X_cond= None\n",
      "Conditioning target sequence provided via x_data ... ['~~HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH~~']\n",
      "x_data from target sequence= tensor([[[0.2222, 0.2222, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "          0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "          0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "          0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "          0.2222, 0.2222, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0') torch.Size([1, 1, 128])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7501355dba4c8381766336bb91c9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0439ef445f56426b8544c4d24dc9dc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5PklEQVR4nO2de5QkdXn3v09Vdfdc9jIzywrLLribhBAGZFfOsMIRiYpZLipeohHMGzCCaKIn6tHkaDxHou/l5PJG3wgJZF/AS14lGgOGxAVBAlkVuQzIZd0VWVmEWRd22Nnr7Ex3V9Xz/lG/X9Wvqqu6a7p751LzfM7Z091161/37n7r6e/z/J4fMTMEQRCE4mLN9QAEQRCEY4sIvSAIQsERoRcEQSg4IvSCIAgFR4ReEASh4DhzPYA0jjvuOF67du1cD0MQBGHB8Oijj77MzCvT9s1LoV+7di1GR0fnehiCIAgLBiL6ZdY+sW4EQRAKjgi9IAhCwRGhFwRBKDjz0qMXBKF41Ot1jI2NYXp6eq6HsqDp6enBmjVrUCqVcp8jQi8IwqwwNjaGpUuXYu3atSCiuR7OgoSZsW/fPoyNjWHdunW5z2tp3RDRSUR0HxFtJ6KfEtFH1fYhIrqHiJ5Rj4MZ51+pjnmGiK7MPTJBEArF9PQ0VqxYISLfAUSEFStWzPhXUR6P3gXwCWYeBnAOgA8T0TCATwG4l5lPAXCvep0c1BCAawG8BsBGANdm3RAEQSg+IvKd08532FLomXkPMz+mnh8GsAPAagBvA/BVddhXAbw95fQLAdzDzBPMvB/APQAumvEo24SZ8e1HxzBd92brLQVBEOYdM6q6IaK1AF4N4CEAxzPzHrXrRQDHp5yyGsALxusxtS3t2tcQ0SgRjY6Pj89kWJn8YnwSn/yXJ/CfP9vblesJgrCwsW0bGzZswBlnnIF3v/vdOHr0aNvXet/73odvf/vbAICrr74a27dvzzz2/vvvxwMPPDDj91i7di1efvnltseoyS30RLQEwL8C+BgzHzL3cbB6SUcrmDDzZmYeYeaRlStTZ/HOmJrrxx4FQVjc9Pb24vHHH8e2bdtQLpdx4403xva7rtvWdW+66SYMDw9n7m9X6LtFLqEnohICkf86M9+mNr9ERKvU/lUA0sLm3QBOMl6vUdtmBc8P7j2uL6toCYIQ53Wvex127tyJ+++/H6973etw6aWXYnh4GJ7n4U//9E9x9tln48wzz8Q//uM/Agis4I985CM49dRT8aY3vQl790aS9/rXvz5s23LXXXfhrLPOwvr163HBBRfgueeew4033ogvfvGL2LBhA37wgx9gfHwcv/u7v4uzzz4bZ599Nn70ox8BAPbt24dNmzbh9NNPx9VXX41urQDYsrySAuf/ZgA7mPkLxq47AFwJ4C/V47+lnP49AP/LSMBuAvDpjkY8Azz1JXm+RPSCMJ/43L//FNt/daj1gTNg+MRluPatp+c61nVd3HnnnbjooiBl+Nhjj2Hbtm1Yt24dNm/ejOXLl+ORRx5BtVrFa1/7WmzatAk/+clP8PTTT2P79u146aWXMDw8jPe///2x646Pj+MDH/gAtm7dinXr1mFiYgJDQ0P40Ic+hCVLluCTn/wkAOC9730vPv7xj+O8887D888/jwsvvBA7duzA5z73OZx33nn47Gc/i+9+97u4+eabu/Ld5Kmjfy2APwDwFBE9rrb9OQKB/xYRXQXglwB+DwCIaATAh5j5amaeIKL/DuARdd7nmXmiKyPPgUT0giCYTE1NYcOGDQCCiP6qq67CAw88gI0bN4Z16XfffTeefPLJ0H8/ePAgnnnmGWzduhWXX345bNvGiSeeiDe+8Y0N13/wwQdx/vnnh9caGhpKHcf3v//9mKd/6NAhHDlyBFu3bsVttwWmyZvf/GYMDnanSLGl0DPzDwFk1fNckHL8KICrjde3ALil3QF2ghZ6T4ReEOYVeSPvbqM9+iT9/f3hc2bGddddhwsvvDB2zJYtW7o2Dt/38eCDD6Knp6dr12xGoXvdhBG9J0IvCEI+LrzwQtxwww2o1+sAgJ///OeYnJzE+eefj29+85vwPA979uzBfffd13DuOeecg61bt2LXrl0AgImJwMBYunQpDh8+HB63adMmXHfddeFrffM5//zz8Y1vfAMAcOedd2L//v1d+UyLQ+jFoxcEISdXX301hoeHcdZZZ+GMM87ABz/4Qbiui3e84x045ZRTMDw8jCuuuALnnntuw7krV67E5s2b8c53vhPr16/He97zHgDAW9/6Vtx+++1hMvZLX/oSRkdHceaZZ2J4eDis/rn22muxdetWnH766bjttttw8sknd+UzUbeyut1kZGSEu7HwyH/9fBxX3vIw/uyiU/HHr/+NLoxMEIR22bFjB0477bS5HkYhSPsuiehRZh5JO77gEX0QyXsdWDfjh6v4h/t3dq3MSRAEYbYpuNAHj51U3dy74yX89V1P44WJqS6NShAEYXYpuNCriL4Doa+rcydr7c2YEwQhQn4Zd04732HBhT547CSi97XQV0XoBaETenp6sG/fPhH7DtD96GdallnohUfcMKJvv+rGCyN66YApCJ2wZs0ajI2NoVtNCxcreoWpmVBoofdV5FDvIBmrhf6oRPSC0BGlUmlGqyIJ3WNRWDedePS6X84REXpBEBYoBRf6QOk78ejDiF6sG0EQFigFF3r92LlHLxG9IAgLlYILfecRvRtG9CL0giAsTAou9J13r4zKK2fPurnv6b246QfPztr7CYJQbAot9G4X+tG7c1BH/52f7MbNP9w1a+8nCEKxKbTQ6/JK12vfo9fXmM1krOuxrHMrCELXyLOU4C0A3gJgLzOfobZ9E8Cp6pABAAeYeUPKuc8BOAzAA+BmdVY7VrhdsG7mIhlb93xURegFQegSeSZMfQXA9QC+pjcw83v0cyL6WwAHm5z/BmZ+ud0BdoLfBevGm4NkrOszqq6UcwqC0B3yLCW4lYjWpu1TC4f/HoDGxRPnAV2ZMDUHydi656PuMXyfYVlZqzgKgiDko1OP/nUAXmLmZzL2M4C7iehRIrqm2YWI6BoiGiWi0W71wgjLKztogeDOQfdKPd5aB7kFQRAETadCfzmAW5vsP4+ZzwJwMYAPE9H5WQcy82ZmHmHmkZUrV3Y4rADdvmChlVfWlcBX6yL0giB0TttCT0QOgHcC+GbWMcy8Wz3uBXA7gI3tvl87ROWV7QvmXJRX6h744tMLgtANOono3wTgZ8w8lraTiPqJaKl+DmATgG0dvN+M8bsxYUr9Kpiqex1dZyboclCpvBEEoRu0FHoiuhXAjwGcSkRjRHSV2nUZErYNEZ1IRFvUy+MB/JCIngDwMIDvMvNd3Rt6a3Q03kmbYrNiZ6o+OxG29uhF6AVB6AZ5qm4uz9j+vpRtvwJwiXr+LID1HY6vI7oS0RvnTlZdLKkc+xb+dV9H9GLdCILQOYWeGdsdjz46d7Z8eonoBUHoJoUWer8LVTdmheNsVd5I1Y0gCN2k0EKvI+OOFgc3FjKerVr6utTRC4LQRQot9N2oo3d9hp6cOlttELRdVJ2l5K8gCMWm0ELfjV43vs9Y2lMCAByZJetGPHpBELpJoYU+TMZ2YIG4vo9lvUGlzdFZSsbWpY5eEIQuUmihD/vRdxTRA8vCiH52hV560guC0A0KLfTaAunMo/extEdF9LOw+IjvM/RwpY5eEIRuUGih70ZE7zFQcWyUHWtWqm7qRt2+WDeCIHSDQgt9d1aY8mFbhCUVZ1YmTJktlaWOXhCEblBoofcMoWduT+w9H7AtQl/ZxtFZqLoxhb7miXUjCELnLAqhTz6fCb7PsInQX3ZmJRkbs24kohcEoQssGqFv16d3fR+2Teiv2LOSjK174tELgtBdCi30ZvuCdoXeZwQRfcWZlWRszKOXqhtBELpAoYXeFHevzZ70ru/DsQLrZjaSsWZEL3X0giB0g0ILvR+zbtoTTd8HLIvQV7FnpXuleXMS60YQhG6QZ4WpW4hoLxFtM7b9BRHtJqLH1Z9LMs69iIieJqKdRPSpbg48D24XkrGxiH426ujFoxcEocvkiei/AuCilO1fZOYN6s+W5E4isgH8PYCLAQwDuJyIhjsZ7EzpRjLWUxF9f8XJXV7pdzIT9xh69J2MSxCEhUtLoWfmrQAm2rj2RgA7mflZZq4B+GcAb2vjOm3TjfJKz/dVeaWNmue39M3v2vYiNnz+7lhL47/7/jN41w0P5Hq/Y+XRH56u4+z/+X1seWpP164pCMLCoBOP/iNE9KSydgZT9q8G8ILxekxtS4WIriGiUSIaHR8f72BYEV4Xqm48n2GriB5o3ZP+7p++iEPTLg4crYfbnts3iWf2Hsn1fnrRkZ6S1VXrZvS5/dg3WcPzE0e7dk1BEBYG7Qr9DQB+HcAGAHsA/G2nA2Hmzcw8wswjK1eu7PRyACKRBtpvVRwJvQ0AmGxRS//QruDHTywy9/zci5bopHF/2enqhKlwXOL7C8Kioy2hZ+aXmNljZh/A/0Vg0yTZDeAk4/UatW3W8HxGxQk+YtsRPXOQjFURfbMSy7H9R7H7wBSAuNDXXR91j3NZMdqj7684XfXoH961r2FcgiAsDtoSeiJaZbx8B4BtKYc9AuAUIlpHRGUAlwG4o533axffZ5SV0LffAkElY8uthf6R56JUhmm7aHHNU4evj11Scbrm0U/VPDw5djAYlwi9ICw68pRX3grgxwBOJaIxIroKwF8T0VNE9CSANwD4uDr2RCLaAgDM7AL4CIDvAdgB4FvM/NNj9DlScbsQ0evyyr5yYN00a4Pw8K5I6Oux5mRK6HPYN/q8JRWnax79T57fH37+uiuVN4Kw2HBaHcDMl6dsvjnj2F8BuMR4vQVAQ+nlbOEzo68UfESvjQlTzMEiIBZF1k2zxmYP7ZpAf9nGZM1LWDeBuOaZcBV69BW7a0L/0K4JWASUHUusG0FYhBR6Zmwsom+jBYK2e5wcVTfjh6t4dnwS5/zaCgDxpGc7EX1fFz36h3dNYPjEZVjWUxKhF4RFSKGF3uvQo9flmZZRdXMkIyrXts15pxwHIBJ3IPLd80y40tVBS8oO6h53PMmp5vp47Pn92Lh2BcqOFRuXIAiLg5bWzUJi2+6DGOwvY/VAL4B41U29HaE3I3qVjD2aYd08vGsfeks2Xn1yMKWglpKMzdPPXo9ziVqntub56LFsHDjaWANvW4TfOmFZWEKaxlO7D6Dq+ti4bgj3P71XGqUJwiKkUEL/rhsfwBXnrsWfX3IagGREP3OB00JvW4TeUvM6+ifGDmL9ScvDpG0sGavENU8tvY7otVVUrfvoKdm48suP4IkXDjQc/z/efgb+2zmvzLze4y8E1TZnvXIAJVs8ekFYjBRK6EtWXMgCoQ+EtxOP3iKCZRHKtpXpmx+ermP1wDKUbPULImbd6GRs/vLKfnXDCN6vhD0HpnD+b67EledGov5H/+8xvLC/+UxX/Z6DfWWUHIrdgARBWBwUSugdm2KC7nFk3bTl0Wvrxg6skbJjZVofVddHxbFQUsfWvLRkbGuPvm5MmNLXBYBD03WcevwSXHDa8eGxQ/1lTBypNb1ezfVBFNhPEtELwuKkUMlYx7bC8kTfZzCjozr6MBlLrYV+uu6jUrJDq6iekozNE9G7Rh09EAh9zfUxXfextKcUO3aov4z9R5sLfd3zUbYtEAW/SMSjF4TFR6GEvmRF1oQW6YqybjqK6FWys9wkIq7WPfSULJSVdRNLxrpa6PPV0RMBvYZ1c3g6aJC2rCf+A2yov4x9k82Fvur64c1Hqm4EYXFSLKF3rDCZqUW63ElE70fllfpamRG966GnZKd69Fpc8yRj6x6jZFvhuKuuj8PTwXnLehsj+okWQl/z/PBXjVg3grA4KZTQO2ZE7+uIvvOqG8cU+hSh9HxG3WP0OKbQB+cyc/g8T3ml6/koWRSOu+b6OKQi+jTrpqXQu344ppJN0gJBEBYhhUrGmhFrZN3EhXcmmOWVADI97ul6YMn0lIxkrDrOfN9mfXI0dc+HY1uh5VR1/XAcSetmRX8Zh6dd1Ax7Jom5TyJ6QVicFCuitym0aDwvGdF3Qeid9MVAIqG3o6Snp4U+Oj7vhKmSHUX01bqHQ1PpEf1gfxkAmiZka64f5g3EoxeExUmxhN5KiejVRKdOqm7sFlU302pbT8m0SBqFPu+EKceyIqGPefSNET2ApvZNzTOSsVJ1IwiLkkIJfcmoow+TsXb7Hr2+lk7GVjIi4qqK6LXdUjK6RJrCmq/XDcOxKbxWK48eaCH0Yt0IwqKnYEJvRPQ6GVtqv+rG53gytpTp0Scjegs1dZPQNwbbotzWTdm2wnFXXR+Hpl0QAUsrjeWVAJqWWJrWTfD9SDJWEBYbeRYeuYWI9hLRNmPb3xDRz9Ti4LcT0UDGuc+pBUoeJ6LRLo47Fce2wqZgDRF9GwLnJssrs4RetUXQNpFZb6+FdaC3lC8Z6/oqotdCH3j0S8pOOA6NFvr9ea0b8egFYVGSJ6L/CoCLEtvuAXAGM58J4OcAPt3k/Dcw8wZmHmlviPkpWdRQR69LC9uK6HOWV4bJWGW3mF6+FvyBvhImay6Ym48jWNEqXnVzaLreUEMfXLMMotYRfSX06Al1z285BkEQikVLoWfmrQAmEtvuVksFAsCDCBb+nnPMXjc6kerYBMeisDXCTAirboxkbD0loq82WDfU4NEP9JXBDEzVm0f1wYQpCqPwmkrGLu1prIS1LcJAbwkTk9XM65kRfcm2wNz+soqCICxMuuHRvx/AnRn7GMDdRPQoEV3T7CJEdA0RjRLR6Pj4eFsDCaybeERvWwTboo5mxtp5I3pl3Zi5An38YF8Qkbfy6V0/qKO3reAGpa2bZT2NET3QetJUzKNP6cMjCELx6UjoiegzAFwAX8845DxmPgvAxQA+TETnZ12LmTcz8wgzj6xcubKt8QTWTdyjtykQzHY8+rC80vDoU+vo3Uah18nYuhHRA60rb+oeh1ZRxbFQrWdH9ACwor8yo6qbYEwS0QvCYqJtoSei9wF4C4Df5wzTl5l3q8e9AG4HsLHd98tDWtVNJxG9m4joKxl19Nq6qRhJz7rbmIwFWq8b6xpWS6VkN/XogRwRvRe1QAjtIInoBWFR0ZbQE9FFAP4MwKXMnLryBRH1E9FS/RzAJgDb0o7tFo5RPmgKfcm22poZ62dYN8n7WtK6SZsZq2extupgaUb0usqnWUQ/mMe6MZKx5pgEQVgc5CmvvBXAjwGcSkRjRHQVgOsBLAVwjyqdvFEdeyIRbVGnHg/gh0T0BICHAXyXme86Jp9CUbKjpKvbRkTPzLhn+0uhEIbllRQJb1oyM3VmbMKjX54zote9boBgDsC0alOc5dGv6C9j/9F65iLiadaNzI4VhMVFy6ZmzHx5yuabM479FYBL1PNnAazvaHQzxLGs0KP3DX/dsSjXzNide4/gA18bxU1XjOBNw8dH5ZXGClNAvCMk0FheaU6s0o+DfTqib5WM5bAxWsWxMDFZg8/IjOiH+svwfMah6XqYB9Awc9Cm2E549BLRC8KiomAzY6NIWgu+TQQ7scRgFnqpv6NKuN2U8kqgMSKergeVLXpCk9kCoZ6oummVjNW9boCgpcLLaqnAZh49kF5Lr39NNET0IvSCsKgomNBboTjHI3orl3UTirMScj9RdZMllNN1L2xZAACVFI9+eV9e64bD96k4Fl4+EtTINyuvBNJnx+p8RZjc7aBlsyAIC5dCCb1jEzyf4fvc4NHnScYmZ7Om1dGbx2mqanUpTcm2whJGXWaZ17qpe35o3ZQdC/uU0DezboCMiF6NsyzWjSAsagol9KGQ+X6sYibvzNgwClfnppVXmsdpput+mIgFgJJDDb8O+ssOSjaF9lAWrs9hTqDiWND3p1bWTVrlTSj0Ye4gviiKIAiLg0IJvS5LdD2OReM60m9FWPuurZuUFaaA9Ihe96YB9ISpeNVNySH0V5xcEb3p0WtaRfTNhT4+M1Y8ekFYXBRL6HUDMy9p3eT16NVs1kR5ZSvrJhnRx7pXGvZJf9lpWUfvekbVjXHNLI++p2Sjv2ynC73nxcZdDmfGitALwmKiUEKvBbLu+ynllfmTsQ0J3WTVTUoytseIvpPdK4mCcfRX7JarTOleN0AkzEB2RA8AQ0vSJ01VEx59WZKxgrAoKZjQN0b0jp4wlUPckrXv+hxtpWRZN9P1xmSsz0Eyt6aqaIgIfWWnaVMzZo5X3ZQigTavn2Sor9w8GevEq4YkGSsIi4tCCb326OtelIy1KDsZ+x9P/govTEQdHJIlkTqiVzqf27oxBbXuRd0jg4g+sFPuf3ovHn/hQOw6+uZUCpO/gbgvaxLNA4FPn1ZeGVXdpCdja66PL/9oV9jDXxCEYlIooTcFNk8LhI9/83F84+Hnw9dJ6ybLo092sJx2vXB1qWAcSlA9X82iDV4HHn2w+MgnvvUEvnTvM7HrhL8gjDp6INuf1yzrLYXrypokJ0yVE/MAHnx2Hz7379vxk8QNRxCEYlEooddlia6qpQeyPXrPD2ySaWMhkORiIck6+qzyymrdb/DogSDpWTe6UfZXHEzWXPxi/Aj2TdbCGvnw/dWvjqgFQnDNZv48oJK/KQnWekLok9aNzhdMt1gMRRCEhU2xhN5Kj+gd22rw6JN+fHBevOomucJUVlOwqhufGWtGzmab4P6Kjcmqh4d2BQt2JX31KCcQ/wWRVUOvKTlR//u0z9iYjNVC76V+HkEQikWhhF4nHV2PY4uGpEX0aUJfTSRh886MnU5E9OYCH3WPI49eWTcPK6FP+uraK09aN7ki+hSfvZqsow8j+uBz6WUNRegFodgUSuh1RO+aM2NJe/SJKFzVmJs2TLIRmc8MiwCi5ISpuNURVN2YM2OjiL7umhG9g6rr48e/2AcgaKIWs47UmMuJqptWHr1Zzmmit1VCoQ8+h74BTNUavwNBEIpHsYQ+rCoxyyut3BF9ODPWSMbqmweQXofuKpvILH80F/ioeT5K6pdGXzk4Zu/hKk5btQxAfEarfn9nhh692bUz9hkTHj0RxY7VQp+2PKIgCMWhUEIf1tEbEb1lAbZlNUwSSvfoG1sgGDqfOmEqueiIOY6amyyvjAT74jNOABAXev2rw0l46q0iet21M7n4SNKj18fqzyfWjSAsDnIJPRHdQkR7iWibsW2IiO4homfU42DGuVeqY54hoiu7NfA0zF43LSP6RC+a4HljC4RYRG83llcmlxEE4knPWsK6AYCBvhJes24IQCKi95J19Pk8erOZW+wzJjx6/TyZjJUJVIJQbPJG9F8BcFFi26cA3MvMpwC4V72OQURDAK4F8BoEC4Nfm3VD6AZm+aA52cm2G+vowzbChmjXEtaN5wcevYaIwnVcNcnVpcxx1LxEeaWybs5eO4QVSyoAEhF9Vh19i6qbrD7zaUIfNFzj2NgloheEYpNL6Jl5K4CJxOa3Afiqev5VAG9POfVCAPcw8wQz7wdwDxpvGF0jsm441r4gbSnBWrNkrFFHb5tKj8bEp47uK6kzY+MtDXRE/5p1Q1iR0ke+Hlo3yZmxra0boFGw9WdzjM9g3qjEuhGExUEnHv3xzLxHPX8RwWLgSVYDeMF4Paa2NUBE1xDRKBGNjo+PtzUgx0iC6vJKi5C6wlS1mUev6+iZYVvxr6jsWOFNAoiiYrOlsNkl0pwZe9oJy/Dbv7kSF79qFZb3lmBbFCuxrCc89dNWLcUbTl2J9ScNNP3cWT1saurXhK4aCo6lxjp6sW4EodC0XBw8D8zMRNRRS0Rm3gxgMwCMjIy0da2SFUXSnu+HpZFp/eibJmO1deMx7MStsNG6SUnGOlELhMC6CW4Cy/tK+Or7N4bHDfaVYhG92YgNAAb6yvjyH0bHZ37ujAVFam60MHh0bOTRi3UjCIuDTiL6l4hoFQCox70px+wGcJLxeo3adkwIWyB4Pjw/qqtP63UTCr3XaMOE1g3Hk7FAIOIx6yYtGWtE2DVjacAkg31lTExGbRC0ADvJu0sLkjNeNTXXj/nz+lgprxSExUUnQn8HAF1FcyWAf0s55nsANhHRoErCblLbjgmhdeOriF59uqZVN02sm2R5JaAi+lh5ZaPQZ5VXJgm6TkbNyHReIevGkEXZzk7GJoXeTMaKdSMIi4O85ZW3AvgxgFOJaIyIrgLwlwB+h4ieAfAm9RpENEJENwEAM08A+O8AHlF/Pq+2HRO0dZMW0Xs+gzkSwma9btyMCVNAsP5qK+vGnFhlJmOTrFhSxj4jog/r6JN3lxY0S8Y2RPS2Fc7sFetGEBYHuTx6Zr48Y9cFKceOArjaeH0LgFvaGt0M0a0HXI/D9gWAUV/vc4OfnRbR1wzrJlF0o5Kx0Q2jWXllso4+SWDdNNbR6549eclaC7bmNv6aKDkU3pyk6kYQFgeFmhmrBb3m+bEl+XTljGnfpE6Y0k3NVGTteY0RfcWIiAEzok/pR+/6qVG1ZkV/GQem6uG4Qo9+xhF9VG1kkmXdyIQpQVhcFErozaUEPT9YXSrYHkX0GjMZqy2daIUpVXXDDKtlHb0ur2y0bsKqmwzPfai/DGbgwNFaOG4gyjXkpZKVjM20biSiF4TFRKGE3rYIREFE7vl+GOHrSU+e1xjRM0c3gPQJU/H3CKybNI/eiOhVRD5d98CMTOtmKDE7Nlp4pD2PPin01VTrJojoPZ9TK48EQSgehRJ6IBDZuorotcBHHn2jTWM+120RtOAGQp8dEQPmhKnoOEv1wJ+sBvtKGdbNUF8wO1YLfXLhkbxkJmPTyitV1dCU0R5ZyisFodgUT+htUlU3UXllqkefJvRJ68ZnJF2UpHUz7XooO1aDxVOyLUxW3fB5GkP9caFvt44+6q2T6OeTUtpZsgl1l8MaekCsG0EoOoUTeke17PU4SmrqCLmeJfSJxKynWv56qeWVCY++7qMnJWIvOxaOqDVZM5OxS+L9brSFlFV3n4XZcsGk2YQpEXpBWDwUTuhLNqGmI3oVZDfz6IGMUkvfV8nY5PWTHr0X8+fN446qiD4rGTvQFzQr0/1ukguP5CVzZmxKMraUsG6IxKMXhKJTOKF3LEtZN1E0HrZGyPDoq4Z1Y7b8TYvoK47V0I8+TejLNmFSRc1Z1k3FsbG04oQRfd1v16OPykpN0uro9fqyWuiXVhyJ6AWh4BRP6G2KyivDZGxrj97zGT5HrYTralvr8ko/NitWU3IsHK019+gBYGhJ2UjGBpVCZrfJPIQTpnJYNyWVTNZjG+gri9ALQsEpnNCXbCvsdZMsrzTr6KuJPvTa9tDrutZ9/asgIfTGhCMgiOjNFsXmOMKqm2ZC31/G/qORRz9T20aPKfgc+Xrd+IxwbMt7S2LdCELBKaDQq6obNiN65dE3ScZqO6a/rCJ6Zd1Y1BjR+xxE30BQR58W0ZdtC0eUR1/JSMYCQYnlviNR1U1phrNigSZ19GkTptTrQ1NBM7XlvaWGJK4gCMWicELvhHX0RkTfZGasfq5FsldF9JHP3yj0QOSHT7sZyVgnSsa2iujN8sqsmvtm2BbBtigm9Myc0Y8++DwHtdD3lWK/bgRBKB6FE3q9glJQA5+YMJWwa8yeNFok+yt2uD9YYarRutHnAEFEn2bdxJOx2XaM9uiZg+UPZ5qI1ZTseJ/8qEFaRkQ/HUX0NdePdfYUBKFYFE7ogzp6nUgNtqV59DXXxxKVeK26fjgrtk9ZNzWXM5Ox+nwgWHgkNRlrRNLNovShvjJqno8jVbdpS+NWJMs+9Y0rzaMHooher0eb9PcFQSgOxRN6ixpKI1OrbjwfS3qc8LkWyX5t3WQlY5VwVsOIPruOPjyniXifsLwHAPDiwWnVcbO9iD6ZJNY3osaZsXGhX94bCL0kZAWhuBRO6MtOVEdvNam6CSL6UvhcC2OfLq/U10gkYysJjz6rvNKMpLNmxgLA6oFeAMDYgakOrRsr/FViji/5ayJKxrqoOFY4dimxFITi0rbQE9GpRPS48ecQEX0scczrieigccxnOx5xCxy1Pmyw3mu8TbGXmDC1tOKEz8PyShWda+smrbxSnwNkl1eakXQzO2b1YCD0u/dPqbxBe38l5lqw5vgaJ0wFn+fQdB29ZbvBihIEoXjkWmEqDWZ+GsAGACAiG8Gi37enHPoDZn5Lu+8zUxzbCv1mHY2HEb3hQ1ddw7pxvUjolfi7YQuExmZlwTm66iZjwpRhwTRLxr5iaQ8ci/CrA50JfcmmWPWMtpayPPpDU3X0luyGG5cgCMWjbaFPcAGAXzDzL7t0vbbRVTcWRdU2WR59OAvW49DqWGJW3bQor9TH9GRMmArPaSLetkVYNdCD3Qem2p4wpd+v7jZG9MkaftOjj0X0ngdBEIpJtzz6ywDcmrHvXCJ6gojuJKLTsy5ARNcQ0SgRjY6Pj7c9ELPXjd3So1c2jeeHvwJ6E1U3DeWVuheO60frxWbU0YfPW0Tpqwd6I+umjQlTelwx6yZH1U1vyY5yDq5U3QhCUelY6ImoDOBSAP+SsvsxAK9k5vUArgPwnazrMPNmZh5h5pGVK1e2PR7HjqpuWi08okspq0YyNll1kyX0Vc83VpdKnxmbPCeL1QN9QUTvdRjRe40Twsp2/Cakx3K05gXWTcbC4oIgFIduRPQXA3iMmV9K7mDmQ8x8RD3fAqBERMd14T0zKes6ek6J6BNtiiuOFa4YFfW6iVfdNJswFa4ulda9ciYR/WAvXjo0jam6N+NFR8xxpbVeTlthStNbtsMbgXj0glBcuiH0lyPDtiGiE0i1YiSijer99nXhPTMJu1d6RkQfVt1EK0d5PqPsWGE3yoaZsW56r5uKUaWiFwZPr6PPl4wFgDUDvfAZeGHiaGbv+laUEl01MydMOdH1YxG9CL0gFJaOkrFE1A/gdwB80Nj2IQBg5hsBvAvAHxGRC2AKwGV8jOfaO1YQ2To2GS0QAjFLLgIeCr3nRXX0OqJXvwoyk7Guj6masm5SrBkdxZfs1m2HdYnloWm3of99Xsp2vNdNNaO8spSI6KNe9pKMFYSi0pHQM/MkgBWJbTcaz68HcH0n7zFTSmE/es7sXmmKYGTd6BYIOqLP7kcPBNbPS4emAQArl1ZSxmHFHpuhJ00BM19dyny/PMlYU/j7pI5eEBYFhZsZa/a6yepeaZYeauumpmyYfiNBCzSu9mR69LsPTAGIInITbfG0SsQCwKqBnvB5J71u0pOx6TNjgcBy0uOsitALQmEpnNCXVK8bN6XqRs+MrTVYN0ZErzx6XVGTVXWjhb7sWDiuv7OIvuLYeIX6VdBuC4TkyldZydiYdVOSZKwgLAaKJ/TGIhzJqhst5qYIBtYNG03Ngoh+WkX4SaEPZ8Z6Pnbvn8Lqgd4Ge8c8rtlkKRP9q6Ddqptk90r9C6VR6KOxxqwbKa8UhMJSOKHXQjld942IPj4z1qwxL4URfWTnWISwdNJOrjBlR1bH2IGpmL9uogW1VcWNZs1gn7p+u90raUYTpoDAuhGPXhCKT+GE3hRWLfQ64E569GXHQsW2UHODqhvHIlgWoWRbkdAnovVgfyCqOqJPQwtoXs9dX6eTiD6tBUJjU7NEHb0T/QISBKGYFE7oTY9bR+NEgThHHn208pNZR2/66lkePRCI5eHpOl4+Uk1NxOpjgHzJWMC0btqvo09LxiZ/UVgWhd9RX1mamgnCYqB4Qm9ErKZI26p9MRDv7GgmY027RUf0af572bHwy31HAQBrMoR+JslYIJg0BaD9XjfKo9fTFGpeMCEsrYZfj6m3ZNTRi9ALQmEpnNCXM4TesSx4Xkp5paqjr3k+yqoLpWndpFXBlB0Lz45PAkC2R++0m4xtv+oGiCeckwuDh2NT79FTskEU/KqRBcIFobgUTuidFI9eP49mxqqFs207sm5cP0yExqyblIi47Fj41cHsGvrgGupaTj7hXj3Qi5JNWKrWcJ0p+v20117zvEzbSG/Xs4D1zU4QhGLSrX7084Ys6yZYeUqJYNK6URF9KUygUmZ5JRAII3Ow74RlPQ379THBtfLdS/srDm7/49di7XH9uY5PYpaVAsFnzBJ607oBGmvwBUEoFoUT+lJKMhYIRDksr/SiGvOyUV6pBdBplYxVFs8Jy3oyq2TKM7RuAOCM1ctzH5vErO8Hmgu93t5bjsYoQi8IxaWA1k2TiD5zwpSPmsuxBGo1o7xSnwdk+/P6GkDj4tzHimQ9fK3JsoRhRK+tG8eSCVOCUGAKKPQZHr1NKROm4hF9FIVTZh293g9k+/PAzGfGdko5tG6iz5j13mLdCMLionBCn1V1U7Ks9PJKY+ERLeCObWHabWbdtI7oI4++vSqamZL06KvNrBs1plDoE50vBUEoFoUTesfKrrqJPPp490qfgam6F+shn9UCAYhEvGlEr6pt8k6Y6pRkPXyeZKxeArHsWNK9UhAKTMcqRETPEdFTRPQ4EY2m7Cci+hIR7SSiJ4norE7fsxnNJ0zFq25KyroBgCPTbsyjn9JCnxKRzyyinyWhT7Qy0Eslpo7NsdCrauj1a7FuBKG4dKvq5g3M/HLGvosBnKL+vAbADerxmBDrdWNE407Co7ctgm1RKMiTVTfWn0avg5VeRx9YHs0j+tn16PXkKC3YgRWVHdH3lqPlDyuOhSNV99gPUhCEOWE2VOhtAL7GAQ8CGCCiVcfqzcyl+OIRvZWaqAwj+qqb6qtn1dED8zWiNz5jE+um11jnVsorBaHYdEOFGMDdRPQoEV2Tsn81gBeM12NqWwwiuoaIRolodHx8vO3BZIl02aZY6WFYYaMeJ2teeG6W/aNZubSCV67oS10UPBqHhaU9Do5bUm77s8yEtGRslnWzcmkZxy+rxM4VoReE4tIN6+Y8Zt5NRK8AcA8R/YyZt870Isy8GcBmABgZGWl7AfFShkgv7y2HS/+ZpZRaDD2fU0si04T+Ty74DVx13rqm47Atwj0f/20M9rfX0mCmRIt8B4J9eNrFkp70v97PvHk4JuxSRy8IxabjiJ6Zd6vHvQBuB7AxcchuACcZr9eobceErDr6Ff1lTExWAajSwxRrxWyBkHYNTV/ZSV0QPMkJy3tQcbKj/m5SNiJ6Zsbh6TqWZfTNWVJxMNQf/dKQZKwgFJuOhJ6I+oloqX4OYBOAbYnD7gBwhaq+OQfAQWbe08n7NiMW0RuJ1MH+MiYma2DmoLNjSrJUP3cyrjGfMWfGTteDtst5G6SJ0AtCsenUujkewO2qTM8B8A1mvouIPgQAzHwjgC0ALgGwE8BRAH/Y4Xs2xUnMhtWs6C+j7jGOVN1YotJMWKb1p0mL6Ocjpkd/eLoOAFjWm++vV5KxglBsOhJ6Zn4WwPqU7TcazxnAhzt5n5mQFY1rq2JispaajAXS13ldaEJf8xiHlNDnjegr4tELQqEp3MxYMxo3o/shVf2yb7KWWl4JRGLpZFxjPhN69K6Pg1NBTfyyjGRsw7lOfHUqQRCKReGE3kzGmssADvWpiP5ILW7d2I1Cb/r8aUsJzkd0ywXTusnt0asJYroXkCAIxaJ4Qp9oTawJrZujtVgLX7PWPErQps+unc+Yi3wfmg4i+uV5PfpEi2NBEIpF4YSeiEKBN6PxFUsMjz4jGZtm3SwUj962CETtRfQlW4ReEIpM4YQeiOwbMxrvLdmoOFYuoc+adDWfIaJghqvHOBR69PnLKwFIQlYQCkohhb6k+t2YIk1EatJUYN1U0iZMpVTdLJRkLBD1lT88XYdjUdiGuOV5Yt0IQqEp3JqxgJrhWm2MxoeWlJtG9Gb3Ss1CScYCwQ2q5vqouh6W9ZbCNsSt0LkJ6UkvCMWkkEKvo/BkND7YVw7KK730qpu0tggLKqJ3goh+qu5hac7SSiCeyBUEoXgU07pRwpWMxnW/m1gdfWp5ZXqJ5nwn8Oh9HJrK7nOThr7pyXKCglBMCin0OhmbjMaH+ivYP1mPWTeWRZE3n2LdLKiI3g567h+edmcW0UsyVhAKTTGFXpdXUlLoSzhSdeH6HPfmE5F8zKNfIHX0QDDuuuvjUJPOlWmIdSMIxaaQQh/VwzdG9Jq0JKxOSma1Op7v6FYGh6bajOhF6AWhkBRa6JOzWmM92O1GoU9deGRBRfQUllcu6525Ry9VN4JQTAop9Doib0jGLokvtpF8npwwRbTwkrFTNQ+TtTarbsSjF4RCUkih1xOm0sorNc2amWUlc+c7ZcfCxNEagPyzYvV5gFg3glBUCin0mRF9f0ZEn2hwpl8vpEQsENyo9h0JhF48ekEQNG0LPRGdRET3EdF2IvopEX005ZjXE9FBInpc/flsZ8PNh25KlozIl/eWoDeZQl9xChLR2xYOTunVpdqpuvGOybgEQZhbOpkZ6wL4BDM/ptaNfZSI7mHm7YnjfsDMb+ngfWaMbjOcjMgti8LZsenJ2Hh55ULy54FoHgDQXkRf96QfvSAUkbYjembew8yPqeeHAewAsLpbA+sEJ8OjB6LKm9RkbMK6WWgRvTmjty2PXpKxglBIuuLRE9FaAK8G8FDK7nOJ6AkiupOITm9yjWuIaJSIRsfHxzsaT9imOK/QJ8oqm50/nzF/pbQzYUrKKwWhmHQs9ES0BMC/AvgYMx9K7H4MwCuZeT2A6wB8J+s6zLyZmUeYeWTlypUdjalkW7AIqd0btdBXcpRXLjShN2f0Lsu5uhQQfE9l25JkrCAUlI6EnohKCET+68x8W3I/Mx9i5iPq+RYAJSI6rpP3zINjUaZIhxG9bYfbyo4N2zgna8LVfMf8lbKkMrP0S9kRoReEotJJ1Q0BuBnADmb+QsYxJ6jjQEQb1fvta/c98+LYVmZp5IoM68b0t0sZ5ZnzHX2D6i/bseUQ8xC0T5CqG0EoIp1U3bwWwB8AeIqIHlfb/hzAyQDAzDcCeBeAPyIiF8AUgMuY+ZiXdpRtykykDiqhN4W97FBipamFmYzV1UZ514o10YuWCIJQPNoWemb+IYCmSsjM1wO4vt33aJfX/NoKHJ520/etW4GNa4ewanlvuO3cXz8uVlqYtrj4QkDfoGbiz2uW9ZTCGnxBEIpFIVeYuuRVq3DJq1al7hs+cRm+9aFzY9suXX8iLl1/Yvg6WGg7+1fBfEWXh7YT0Z840IvdB6a6PSRBEOYBhWyB0A1KTXz++Youk1w2g8lSmtWDvdi9X4ReEIqICH0GjkUN/eznO51E9KsHerH/aB1Ha+mWlyAICxcR+gzKjrXwyivVjakdj37NYJCzkKheEIqHCH0GJdtasBOm2o3oAWBMfHpBKBwi9Bk4dvakq/lKWHXTjtBLRC8IhUWEPoMFmYwNPfqZWzevWNoDxyKpvBGEAiJCn0HZthZcMjasuplBL3qNbRFWDfRIRC8IBUSEPgPHpgUX0UcefXvTI1ZLLb0gFJJCTpjqBr83chL6ygvr63nV6uV485mr8OqTBto6f/VAH3608+XuDkoQhDlnYSnZLHLFuWvneggzZnlfCX//3rPaPn/1YC9eOjyNmuvHmr4JgrCwkf/NQsiagV4wAy8enJ7roQiC0EVE6IUQXWI5duDoHI9EEIRuIkIvhOhJU1J5IwjFQoReCFk10AMAUnkjCAVDhF4IqTg2XrG0IhG9IBSMTteMvYiIniainUT0qZT9FSL6ptr/EBGt7eT9hGPP6kGppReEotHJmrE2gL8HcDGAYQCXE9Fw4rCrAOxn5t8A8EUAf9Xu+wmzg0yaEoTi0Ukd/UYAO5n5WQAgon8G8DYA241j3gbgL9TzbwO4nohoNtaNFdpj9WAvtjy1B7/zhf+a66EIwqJjsK/csAJeN+hE6FcDeMF4PQbgNVnHMLNLRAcBrADQMP2SiK4BcA0AnHzyyR0MS+iEd7x6NXbvn4Iv92JBmHXa6Tybh3kzM5aZNwPYDAAjIyOiMnPEb52wDNd3MLtWEIT5RyfJ2N0ATjJer1HbUo8hIgfAcgD7OnhPQRAEYYZ0IvSPADiFiNYRURnAZQDuSBxzB4Ar1fN3AfhP8ecFQRBml7atG+W5fwTA9wDYAG5h5p8S0ecBjDLzHQBuBvBPRLQTwASCm4EgCIIwi3Tk0TPzFgBbEts+azyfBvDuTt5DEARB6AyZGSsIglBwROgFQRAKjgi9IAhCwRGhFwRBKDg0H6sdiWgcwC/bPP04pMy8XUDI+OcWGf/csZDHDsz9+F/JzCvTdsxLoe8EIhpl5pG5Hke7yPjnFhn/3LGQxw7M7/GLdSMIglBwROgFQRAKThGFfvNcD6BDZPxzi4x/7ljIYwfm8fgL59ELgiAIcYoY0QuCIAgGIvSCIAgFpzBC32qh8vkGEZ1ERPcR0XYi+ikRfVRtHyKie4joGfU4ONdjbQYR2UT0EyL6D/V6nVoIfqdaGL4812PMgogGiOjbRPQzItpBROcupO+fiD6u/u1sI6JbiahnPn//RHQLEe0lom3GttTvmwK+pD7Hk0Q056vhZIz/b9S/nyeJ6HYiGjD2fVqN/2kiunBOBq0ohNDnXKh8vuEC+AQzDwM4B8CH1Zg/BeBeZj4FwL3q9XzmowB2GK//CsAX1YLw+xEsED9f+TsAdzHzbwFYj+BzLIjvn4hWA/gTACPMfAaCVuGXYX5//18BcFFiW9b3fTGAU9SfawDcMEtjbMZX0Dj+ewCcwcxnAvg5gE8DgPq/fBmA09U5/6B0ak4ohNDDWKicmWsA9ELl8xZm3sPMj6nnhxGIzGoE4/6qOuyrAN4+JwPMARGtAfBmADep1wTgjQgWggfm8fiJaDmA8xGsmQBmrjHzASyg7x9Bm/FetXpbH4A9mMffPzNvRbAuhUnW9/02AF/jgAcBDBDRqlkZaAZp42fmu5nZVS8fRLDSHhCM/5+ZucrMuwDsRKBTc0JRhD5tofLVczSWGUNEawG8GsBDAI5n5j1q14sAjp+rceXg/wD4MwC+er0CwAHjH/58/ntYB2AcwJeV9XQTEfVjgXz/zLwbwP8G8DwCgT8I4FEsnO9fk/V9L8T/0+8HcKd6Pq/GXxShX7AQ0RIA/wrgY8x8yNynll2cl/WvRPQWAHuZ+dG5HkubOADOAnADM78awCQSNs08//4HEUSN6wCcCKAfjbbCgmI+f9+tIKLPILBjvz7XY0mjKEKfZ6HyeQcRlRCI/NeZ+Ta1+SX9E1U97p2r8bXgtQAuJaLnEFhlb0TgeQ8oKwGY338PYwDGmPkh9frbCIR/oXz/bwKwi5nHmbkO4DYEfycL5fvXZH3fC+b/NBG9D8BbAPy+sSb2vBp/UYQ+z0Ll8wrlZ98MYAczf8HYZS6ofiWAf5vtseWBmT/NzGuYeS2C7/s/mfn3AdyHYCF4YH6P/0UALxDRqWrTBQC2Y4F8/wgsm3OIqE/9W9LjXxDfv0HW930HgCtU9c05AA4aFs+8gYguQmBfXsrMR41ddwC4jIgqRLQOQVL54bkYIwCAmQvxB8AlCLLevwDwmbkeT47xnofgZ+qTAB5Xfy5B4HPfC+AZAN8HMDTXY83xWV4P4D/U819D8A96J4B/AVCZ6/E1GfcGAKPq7+A7AAYX0vcP4HMAfgZgG4B/AlCZz98/gFsR5BPqCH5RXZX1fQMgBJV0vwDwFILqovk4/p0IvHj9f/hG4/jPqPE/DeDiuRy7tEAQBEEoOEWxbgRBEIQMROgFQRAKjgi9IAhCwRGhFwRBKDgi9IIgCAVHhF4QBKHgiNALgiAUnP8PKDLjmbSqNyoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "For None or ~~HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH~~, predicted sequence QGWAGRGPLMQAVQFAFIRDSHIQQQRLAQFARG\n",
      "Writing FASTA file:  ./output_model_B/fasta_in_812.fasta\n",
      "Now run OmegaFold.... on device=cuda:0\n",
      "INFO:root:Loading weights from /home/mbuehler/.cache/omegafold_ckpt/model.pt\n",
      "INFO:root:Constructing OmegaFold\n",
      "INFO:root:Reading ./output_model_B/fasta_in_812.fasta\n",
      "INFO:root:Predicting 1th chain in ./output_model_B/fasta_in_812.fasta\n",
      "INFO:root:34 residues in this chain.\n",
      "INFO:root:Finished prediction in 15.96 seconds.\n",
      "INFO:root:Saving prediction to ./output_model_B/temp_812.pdb\n",
      "INFO:root:Saved\n",
      "INFO:root:Done!\n",
      "Done OmegaFold\n",
      "Resulting PDB file...:  ./output_model_B/temp_812.PDB\n",
      "Properly named PDB file produced: ./output_model_B/~~HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH~~_812_0.pdb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x10 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16788863678521886\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16788863678521886\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16788863678521886 = null;\nvar warn = document.getElementById(\"3dmolwarning_16788863678521886\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16788863678521886 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788863678521886\"),{backgroundColor:\"white\"});\nviewer_16788863678521886.zoomTo();\n\tviewer_16788863678521886.addModel(\"ATOM      1  N   GLN A   0      16.013  -3.487 -23.447  1.00 52.84           N  \\nATOM      2  CA  GLN A   0      16.230  -2.554 -22.347  1.00 52.84           C  \\nATOM      3  C   GLN A   0      14.918  -2.215 -21.645  1.00 52.84           C  \\nATOM      4  O   GLN A   0      14.718  -1.081 -21.205  1.00 52.84           O  \\nATOM      5  CB  GLN A   0      16.901  -1.275 -22.852  1.00 52.84           C  \\nATOM      6  CG  GLN A   0      18.419  -1.294 -22.746  1.00 52.84           C  \\nATOM      7  CD  GLN A   0      19.067  -0.080 -23.386  1.00 52.84           C  \\nATOM      8  OE1 GLN A   0      18.397   0.727 -24.038  1.00 52.84           O  \\nATOM      9  NE2 GLN A   0      20.377   0.057 -23.206  1.00 52.84           N  \\nATOM     10  N   GLY A   1      13.903  -3.192 -21.633  1.00 62.65           N  \\nATOM     11  CA  GLY A   1      12.547  -3.059 -21.126  1.00 62.65           C  \\nATOM     12  C   GLY A   1      12.445  -3.280 -19.628  1.00 62.65           C  \\nATOM     13  O   GLY A   1      11.524  -2.777 -18.982  1.00 62.65           O  \\nATOM     14  N   TRP A   2      13.568  -3.709 -18.939  1.00 61.13           N  \\nATOM     15  CA  TRP A   2      13.383  -4.032 -17.528  1.00 61.13           C  \\nATOM     16  C   TRP A   2      13.804  -2.865 -16.642  1.00 61.13           C  \\nATOM     17  O   TRP A   2      13.465  -2.823 -15.457  1.00 61.13           O  \\nATOM     18  CB  TRP A   2      14.178  -5.286 -17.154  1.00 61.13           C  \\nATOM     19  CG  TRP A   2      14.012  -6.423 -18.118  1.00 61.13           C  \\nATOM     20  CD1 TRP A   2      12.893  -6.736 -18.839  1.00 61.13           C  \\nATOM     21  CD2 TRP A   2      14.998  -7.401 -18.463  1.00 61.13           C  \\nATOM     22  NE1 TRP A   2      13.124  -7.850 -19.612  1.00 61.13           N  \\nATOM     23  CE2 TRP A   2      14.407  -8.277 -19.400  1.00 61.13           C  \\nATOM     24  CE3 TRP A   2      16.325  -7.621 -18.070  1.00 61.13           C  \\nATOM     25  CZ2 TRP A   2      15.100  -9.358 -19.951  1.00 61.13           C  \\nATOM     26  CZ3 TRP A   2      17.012  -8.697 -18.620  1.00 61.13           C  \\nATOM     27  CH2 TRP A   2      16.396  -9.551 -19.550  1.00 61.13           C  \\nATOM     28  N   ALA A   3      14.667  -1.996 -17.208  1.00 63.05           N  \\nATOM     29  CA  ALA A   3      15.277  -1.019 -16.309  1.00 63.05           C  \\nATOM     30  C   ALA A   3      14.227  -0.073 -15.733  1.00 63.05           C  \\nATOM     31  O   ALA A   3      14.353   0.386 -14.596  1.00 63.05           O  \\nATOM     32  CB  ALA A   3      16.359  -0.227 -17.039  1.00 63.05           C  \\nATOM     33  N   GLY A   4      13.044  -0.108 -16.331  1.00 63.69           N  \\nATOM     34  CA  GLY A   4      12.111   0.886 -15.824  1.00 63.69           C  \\nATOM     35  C   GLY A   4      11.092   0.309 -14.859  1.00 63.69           C  \\nATOM     36  O   GLY A   4      10.358   1.054 -14.205  1.00 63.69           O  \\nATOM     37  N   ARG A   5      11.128  -1.014 -14.684  1.00 65.68           N  \\nATOM     38  CA  ARG A   5      10.090  -1.559 -13.814  1.00 65.68           C  \\nATOM     39  C   ARG A   5      10.524  -1.519 -12.352  1.00 65.68           C  \\nATOM     40  O   ARG A   5       9.696  -1.650 -11.449  1.00 65.68           O  \\nATOM     41  CB  ARG A   5       9.746  -2.994 -14.219  1.00 65.68           C  \\nATOM     42  CG  ARG A   5       9.013  -3.100 -15.547  1.00 65.68           C  \\nATOM     43  CD  ARG A   5       8.558  -4.525 -15.827  1.00 65.68           C  \\nATOM     44  NE  ARG A   5       8.081  -4.678 -17.199  1.00 65.68           N  \\nATOM     45  CZ  ARG A   5       7.321  -5.681 -17.629  1.00 65.68           C  \\nATOM     46  NH1 ARG A   5       6.934  -6.643 -16.800  1.00 65.68           N  \\nATOM     47  NH2 ARG A   5       6.943  -5.722 -18.899  1.00 65.68           N  \\nATOM     48  N   GLY A   6      11.885  -1.244 -12.155  1.00 75.29           N  \\nATOM     49  CA  GLY A   6      12.314  -1.287 -10.766  1.00 75.29           C  \\nATOM     50  C   GLY A   6      11.736  -0.162  -9.929  1.00 75.29           C  \\nATOM     51  O   GLY A   6      11.129  -0.408  -8.884  1.00 75.29           O  \\nATOM     52  N   PRO A   7      11.814   1.001 -10.470  1.00 78.58           N  \\nATOM     53  CA  PRO A   7      11.333   2.095  -9.623  1.00 78.58           C  \\nATOM     54  C   PRO A   7       9.818   2.068  -9.429  1.00 78.58           C  \\nATOM     55  O   PRO A   7       9.326   2.392  -8.345  1.00 78.58           O  \\nATOM     56  CB  PRO A   7      11.763   3.349 -10.389  1.00 78.58           C  \\nATOM     57  CG  PRO A   7      12.844   2.882 -11.310  1.00 78.58           C  \\nATOM     58  CD  PRO A   7      12.648   1.415 -11.571  1.00 78.58           C  \\nATOM     59  N   LEU A   8       9.134   1.549 -10.525  1.00 84.88           N  \\nATOM     60  CA  LEU A   8       7.683   1.522 -10.373  1.00 84.88           C  \\nATOM     61  C   LEU A   8       7.261   0.447  -9.377  1.00 84.88           C  \\nATOM     62  O   LEU A   8       6.366   0.670  -8.559  1.00 84.88           O  \\nATOM     63  CB  LEU A   8       7.007   1.276 -11.724  1.00 84.88           C  \\nATOM     64  CG  LEU A   8       7.065   2.426 -12.730  1.00 84.88           C  \\nATOM     65  CD1 LEU A   8       6.460   1.996 -14.063  1.00 84.88           C  \\nATOM     66  CD2 LEU A   8       6.345   3.654 -12.182  1.00 84.88           C  \\nATOM     67  N   MET A   9       8.038  -0.666  -9.390  1.00 84.49           N  \\nATOM     68  CA  MET A   9       7.706  -1.749  -8.468  1.00 84.49           C  \\nATOM     69  C   MET A   9       8.008  -1.348  -7.027  1.00 84.49           C  \\nATOM     70  O   MET A   9       7.261  -1.696  -6.112  1.00 84.49           O  \\nATOM     71  CB  MET A   9       8.476  -3.020  -8.830  1.00 84.49           C  \\nATOM     72  CG  MET A   9       7.995  -3.684 -10.109  1.00 84.49           C  \\nATOM     73  SD  MET A   9       6.248  -4.235 -10.001  1.00 84.49           S  \\nATOM     74  CE  MET A   9       6.444  -5.719  -8.974  1.00 84.49           C  \\nATOM     75  N   GLN A  10       9.043  -0.570  -6.909  1.00 88.14           N  \\nATOM     76  CA  GLN A  10       9.397  -0.098  -5.574  1.00 88.14           C  \\nATOM     77  C   GLN A  10       8.354   0.881  -5.042  1.00 88.14           C  \\nATOM     78  O   GLN A  10       7.976   0.817  -3.871  1.00 88.14           O  \\nATOM     79  CB  GLN A  10      10.777   0.561  -5.585  1.00 88.14           C  \\nATOM     80  CG  GLN A  10      11.920  -0.411  -5.847  1.00 88.14           C  \\nATOM     81  CD  GLN A  10      13.258   0.287  -6.008  1.00 88.14           C  \\nATOM     82  OE1 GLN A  10      13.333   1.400  -6.537  1.00 88.14           O  \\nATOM     83  NE2 GLN A  10      14.324  -0.364  -5.555  1.00 88.14           N  \\nATOM     84  N   ALA A  11       7.944   1.758  -5.992  1.00 91.01           N  \\nATOM     85  CA  ALA A  11       6.923   2.723  -5.592  1.00 91.01           C  \\nATOM     86  C   ALA A  11       5.637   2.018  -5.170  1.00 91.01           C  \\nATOM     87  O   ALA A  11       5.032   2.372  -4.156  1.00 91.01           O  \\nATOM     88  CB  ALA A  11       6.641   3.701  -6.729  1.00 91.01           C  \\nATOM     89  N   VAL A  12       5.343   0.970  -5.890  1.00 91.80           N  \\nATOM     90  CA  VAL A  12       4.133   0.210  -5.595  1.00 91.80           C  \\nATOM     91  C   VAL A  12       4.285  -0.505  -4.254  1.00 91.80           C  \\nATOM     92  O   VAL A  12       3.364  -0.504  -3.435  1.00 91.80           O  \\nATOM     93  CB  VAL A  12       3.818  -0.811  -6.711  1.00 91.80           C  \\nATOM     94  CG1 VAL A  12       2.710  -1.766  -6.271  1.00 91.80           C  \\nATOM     95  CG2 VAL A  12       3.425  -0.089  -7.999  1.00 91.80           C  \\nATOM     96  N   GLN A  13       5.439  -1.032  -3.968  1.00 92.29           N  \\nATOM     97  CA  GLN A  13       5.693  -1.727  -2.711  1.00 92.29           C  \\nATOM     98  C   GLN A  13       5.580  -0.775  -1.523  1.00 92.29           C  \\nATOM     99  O   GLN A  13       4.956  -1.106  -0.513  1.00 92.29           O  \\nATOM    100  CB  GLN A  13       7.074  -2.383  -2.729  1.00 92.29           C  \\nATOM    101  CG  GLN A  13       7.163  -3.606  -3.631  1.00 92.29           C  \\nATOM    102  CD  GLN A  13       8.575  -4.147  -3.749  1.00 92.29           C  \\nATOM    103  OE1 GLN A  13       9.463  -3.779  -2.973  1.00 92.29           O  \\nATOM    104  NE2 GLN A  13       8.795  -5.025  -4.722  1.00 92.29           N  \\nATOM    105  N   PHE A  14       6.146   0.399  -1.733  1.00 94.59           N  \\nATOM    106  CA  PHE A  14       6.107   1.359  -0.636  1.00 94.59           C  \\nATOM    107  C   PHE A  14       4.674   1.781  -0.336  1.00 94.59           C  \\nATOM    108  O   PHE A  14       4.283   1.883   0.829  1.00 94.59           O  \\nATOM    109  CB  PHE A  14       6.959   2.589  -0.966  1.00 94.59           C  \\nATOM    110  CG  PHE A  14       8.414   2.432  -0.617  1.00 94.59           C  \\nATOM    111  CD1 PHE A  14       8.825   2.406   0.711  1.00 94.59           C  \\nATOM    112  CD2 PHE A  14       9.371   2.311  -1.616  1.00 94.59           C  \\nATOM    113  CE1 PHE A  14      10.172   2.261   1.037  1.00 94.59           C  \\nATOM    114  CE2 PHE A  14      10.718   2.166  -1.297  1.00 94.59           C  \\nATOM    115  CZ  PHE A  14      11.117   2.142   0.030  1.00 94.59           C  \\nATOM    116  N   ALA A  15       3.952   1.959  -1.381  1.00 94.71           N  \\nATOM    117  CA  ALA A  15       2.562   2.375  -1.216  1.00 94.71           C  \\nATOM    118  C   ALA A  15       1.756   1.315  -0.471  1.00 94.71           C  \\nATOM    119  O   ALA A  15       0.972   1.637   0.424  1.00 94.71           O  \\nATOM    120  CB  ALA A  15       1.928   2.664  -2.575  1.00 94.71           C  \\nATOM    121  N   PHE A  16       2.049   0.081  -0.824  1.00 94.59           N  \\nATOM    122  CA  PHE A  16       1.319  -0.997  -0.167  1.00 94.59           C  \\nATOM    123  C   PHE A  16       1.701  -1.091   1.305  1.00 94.59           C  \\nATOM    124  O   PHE A  16       0.833  -1.236   2.169  1.00 94.59           O  \\nATOM    125  CB  PHE A  16       1.587  -2.333  -0.866  1.00 94.59           C  \\nATOM    126  CG  PHE A  16       0.619  -2.644  -1.974  1.00 94.59           C  \\nATOM    127  CD1 PHE A  16      -0.675  -3.064  -1.689  1.00 94.59           C  \\nATOM    128  CD2 PHE A  16       1.002  -2.517  -3.303  1.00 94.59           C  \\nATOM    129  CE1 PHE A  16      -1.574  -3.352  -2.713  1.00 94.59           C  \\nATOM    130  CE2 PHE A  16       0.109  -2.804  -4.332  1.00 94.59           C  \\nATOM    131  CZ  PHE A  16      -1.178  -3.222  -4.035  1.00 94.59           C  \\nATOM    132  N   ILE A  17       2.957  -1.023   1.548  1.00 94.05           N  \\nATOM    133  CA  ILE A  17       3.430  -1.158   2.921  1.00 94.05           C  \\nATOM    134  C   ILE A  17       2.888  -0.009   3.768  1.00 94.05           C  \\nATOM    135  O   ILE A  17       2.422  -0.222   4.890  1.00 94.05           O  \\nATOM    136  CB  ILE A  17       4.973  -1.193   2.988  1.00 94.05           C  \\nATOM    137  CG1 ILE A  17       5.505  -2.491   2.369  1.00 94.05           C  \\nATOM    138  CG2 ILE A  17       5.455  -1.036   4.433  1.00 94.05           C  \\nATOM    139  CD1 ILE A  17       6.999  -2.470   2.076  1.00 94.05           C  \\nATOM    140  N   ARG A  18       2.942   1.142   3.207  1.00 94.04           N  \\nATOM    141  CA  ARG A  18       2.415   2.311   3.904  1.00 94.04           C  \\nATOM    142  C   ARG A  18       0.920   2.163   4.168  1.00 94.04           C  \\nATOM    143  O   ARG A  18       0.459   2.379   5.290  1.00 94.04           O  \\nATOM    144  CB  ARG A  18       2.681   3.584   3.098  1.00 94.04           C  \\nATOM    145  CG  ARG A  18       2.158   4.851   3.755  1.00 94.04           C  \\nATOM    146  CD  ARG A  18       2.319   6.064   2.851  1.00 94.04           C  \\nATOM    147  NE  ARG A  18       1.804   7.278   3.479  1.00 94.04           N  \\nATOM    148  CZ  ARG A  18       0.924   8.105   2.923  1.00 94.04           C  \\nATOM    149  NH1 ARG A  18       0.441   7.864   1.709  1.00 94.04           N  \\nATOM    150  NH2 ARG A  18       0.523   9.181   3.584  1.00 94.04           N  \\nATOM    151  N   ASP A  19       0.143   1.752   3.218  1.00 93.98           N  \\nATOM    152  CA  ASP A  19      -1.304   1.601   3.338  1.00 93.98           C  \\nATOM    153  C   ASP A  19      -1.661   0.503   4.338  1.00 93.98           C  \\nATOM    154  O   ASP A  19      -2.584   0.662   5.139  1.00 93.98           O  \\nATOM    155  CB  ASP A  19      -1.927   1.294   1.975  1.00 93.98           C  \\nATOM    156  CG  ASP A  19      -3.432   1.491   1.953  1.00 93.98           C  \\nATOM    157  OD1 ASP A  19      -3.909   2.593   2.304  1.00 93.98           O  \\nATOM    158  OD2 ASP A  19      -4.149   0.536   1.584  1.00 93.98           O  \\nATOM    159  N   SER A  20      -0.895  -0.599   4.309  1.00 94.87           N  \\nATOM    160  CA  SER A  20      -1.146  -1.699   5.234  1.00 94.87           C  \\nATOM    161  C   SER A  20      -0.897  -1.275   6.678  1.00 94.87           C  \\nATOM    162  O   SER A  20      -1.631  -1.676   7.584  1.00 94.87           O  \\nATOM    163  CB  SER A  20      -0.267  -2.902   4.889  1.00 94.87           C  \\nATOM    164  OG  SER A  20       1.097  -2.622   5.156  1.00 94.87           O  \\nATOM    165  N   HIS A  21       0.077  -0.422   6.865  1.00 92.93           N  \\nATOM    166  CA  HIS A  21       0.402   0.031   8.212  1.00 92.93           C  \\nATOM    167  C   HIS A  21      -0.674   0.966   8.754  1.00 92.93           C  \\nATOM    168  O   HIS A  21      -1.074   0.852   9.915  1.00 92.93           O  \\nATOM    169  CB  HIS A  21       1.762   0.732   8.228  1.00 92.93           C  \\nATOM    170  CG  HIS A  21       2.921  -0.210   8.309  1.00 92.93           C  \\nATOM    171  ND1 HIS A  21       3.460  -0.626   9.507  1.00 92.93           N  \\nATOM    172  CD2 HIS A  21       3.641  -0.819   7.337  1.00 92.93           C  \\nATOM    173  CE1 HIS A  21       4.466  -1.452   9.268  1.00 92.93           C  \\nATOM    174  NE2 HIS A  21       4.596  -1.586   7.959  1.00 92.93           N  \\nATOM    175  N   ILE A  22      -1.204   1.810   7.899  1.00 94.15           N  \\nATOM    176  CA  ILE A  22      -2.227   2.765   8.312  1.00 94.15           C  \\nATOM    177  C   ILE A  22      -3.531   2.029   8.610  1.00 94.15           C  \\nATOM    178  O   ILE A  22      -4.190   2.303   9.616  1.00 94.15           O  \\nATOM    179  CB  ILE A  22      -2.457   3.847   7.233  1.00 94.15           C  \\nATOM    180  CG1 ILE A  22      -1.212   4.730   7.087  1.00 94.15           C  \\nATOM    181  CG2 ILE A  22      -3.691   4.691   7.569  1.00 94.15           C  \\nATOM    182  CD1 ILE A  22      -1.277   5.703   5.918  1.00 94.15           C  \\nATOM    183  N   GLN A  23      -3.798   1.119   7.734  1.00 95.05           N  \\nATOM    184  CA  GLN A  23      -5.006   0.325   7.930  1.00 95.05           C  \\nATOM    185  C   GLN A  23      -4.952  -0.442   9.248  1.00 95.05           C  \\nATOM    186  O   GLN A  23      -5.941  -0.495   9.983  1.00 95.05           O  \\nATOM    187  CB  GLN A  23      -5.206  -0.646   6.765  1.00 95.05           C  \\nATOM    188  CG  GLN A  23      -6.439  -1.529   6.905  1.00 95.05           C  \\nATOM    189  CD  GLN A  23      -7.736  -0.746   6.806  1.00 95.05           C  \\nATOM    190  OE1 GLN A  23      -7.796   0.300   6.152  1.00 95.05           O  \\nATOM    191  NE2 GLN A  23      -8.782  -1.247   7.454  1.00 95.05           N  \\nATOM    192  N   GLN A  24      -3.813  -1.002   9.576  1.00 94.18           N  \\nATOM    193  CA  GLN A  24      -3.655  -1.757  10.814  1.00 94.18           C  \\nATOM    194  C   GLN A  24      -3.795  -0.850  12.033  1.00 94.18           C  \\nATOM    195  O   GLN A  24      -4.382  -1.245  13.043  1.00 94.18           O  \\nATOM    196  CB  GLN A  24      -2.301  -2.468  10.841  1.00 94.18           C  \\nATOM    197  CG  GLN A  24      -2.206  -3.647   9.883  1.00 94.18           C  \\nATOM    198  CD  GLN A  24      -3.068  -4.820  10.310  1.00 94.18           C  \\nATOM    199  OE1 GLN A  24      -3.140  -5.156  11.496  1.00 94.18           O  \\nATOM    200  NE2 GLN A  24      -3.728  -5.453   9.345  1.00 94.18           N  \\nATOM    201  N   GLN A  25      -3.279   0.356  11.847  1.00 94.12           N  \\nATOM    202  CA  GLN A  25      -3.364   1.299  12.957  1.00 94.12           C  \\nATOM    203  C   GLN A  25      -4.814   1.674  13.249  1.00 94.12           C  \\nATOM    204  O   GLN A  25      -5.222   1.741  14.410  1.00 94.12           O  \\nATOM    205  CB  GLN A  25      -2.546   2.556  12.659  1.00 94.12           C  \\nATOM    206  CG  GLN A  25      -1.041   2.327  12.671  1.00 94.12           C  \\nATOM    207  CD  GLN A  25      -0.256   3.559  12.259  1.00 94.12           C  \\nATOM    208  OE1 GLN A  25      -0.696   4.334  11.403  1.00 94.12           O  \\nATOM    209  NE2 GLN A  25       0.911   3.748  12.865  1.00 94.12           N  \\nATOM    210  N   ARG A  26      -5.557   1.776  12.172  1.00 92.16           N  \\nATOM    211  CA  ARG A  26      -6.953   2.158  12.355  1.00 92.16           C  \\nATOM    212  C   ARG A  26      -7.750   1.030  13.002  1.00 92.16           C  \\nATOM    213  O   ARG A  26      -8.572   1.273  13.887  1.00 92.16           O  \\nATOM    214  CB  ARG A  26      -7.584   2.544  11.015  1.00 92.16           C  \\nATOM    215  CG  ARG A  26      -7.108   3.882  10.472  1.00 92.16           C  \\nATOM    216  CD  ARG A  26      -8.037   4.415   9.390  1.00 92.16           C  \\nATOM    217  NE  ARG A  26      -8.073   3.531   8.227  1.00 92.16           N  \\nATOM    218  CZ  ARG A  26      -7.282   3.644   7.164  1.00 92.16           C  \\nATOM    219  NH1 ARG A  26      -6.372   4.610   7.094  1.00 92.16           N  \\nATOM    220  NH2 ARG A  26      -7.400   2.784   6.161  1.00 92.16           N  \\nATOM    221  N   LEU A  27      -7.414  -0.192  12.534  1.00 95.75           N  \\nATOM    222  CA  LEU A  27      -8.109  -1.340  13.107  1.00 95.75           C  \\nATOM    223  C   LEU A  27      -7.778  -1.491  14.588  1.00 95.75           C  \\nATOM    224  O   LEU A  27      -8.665  -1.758  15.403  1.00 95.75           O  \\nATOM    225  CB  LEU A  27      -7.738  -2.621  12.356  1.00 95.75           C  \\nATOM    226  CG  LEU A  27      -8.484  -3.890  12.770  1.00 95.75           C  \\nATOM    227  CD1 LEU A  27      -9.964  -3.771  12.424  1.00 95.75           C  \\nATOM    228  CD2 LEU A  27      -7.870  -5.114  12.101  1.00 95.75           C  \\nATOM    229  N   ALA A  28      -6.511  -1.243  14.915  1.00 94.26           N  \\nATOM    230  CA  ALA A  28      -6.083  -1.378  16.305  1.00 94.26           C  \\nATOM    231  C   ALA A  28      -6.740  -0.320  17.187  1.00 94.26           C  \\nATOM    232  O   ALA A  28      -7.119  -0.601  18.326  1.00 94.26           O  \\nATOM    233  CB  ALA A  28      -4.562  -1.279  16.405  1.00 94.26           C  \\nATOM    234  N   GLN A  29      -6.978   0.805  16.593  1.00 91.86           N  \\nATOM    235  CA  GLN A  29      -7.614   1.878  17.350  1.00 91.86           C  \\nATOM    236  C   GLN A  29      -9.080   1.559  17.630  1.00 91.86           C  \\nATOM    237  O   GLN A  29      -9.580   1.825  18.724  1.00 91.86           O  \\nATOM    238  CB  GLN A  29      -7.499   3.206  16.600  1.00 91.86           C  \\nATOM    239  CG  GLN A  29      -6.081   3.757  16.539  1.00 91.86           C  \\nATOM    240  CD  GLN A  29      -5.970   4.997  15.672  1.00 91.86           C  \\nATOM    241  OE1 GLN A  29      -6.555   5.066  14.585  1.00 91.86           O  \\nATOM    242  NE2 GLN A  29      -5.219   5.986  16.145  1.00 91.86           N  \\nATOM    243  N   PHE A  30      -9.621   0.862  16.729  1.00 91.81           N  \\nATOM    244  CA  PHE A  30     -11.034   0.549  16.902  1.00 91.81           C  \\nATOM    245  C   PHE A  30     -11.219  -0.603  17.881  1.00 91.81           C  \\nATOM    246  O   PHE A  30     -12.224  -0.666  18.593  1.00 91.81           O  \\nATOM    247  CB  PHE A  30     -11.678   0.202  15.555  1.00 91.81           C  \\nATOM    248  CG  PHE A  30     -12.148   1.403  14.780  1.00 91.81           C  \\nATOM    249  CD1 PHE A  30     -13.242   2.143  15.213  1.00 91.81           C  \\nATOM    250  CD2 PHE A  30     -11.496   1.792  13.617  1.00 91.81           C  \\nATOM    251  CE1 PHE A  30     -13.680   3.254  14.497  1.00 91.81           C  \\nATOM    252  CE2 PHE A  30     -11.928   2.902  12.896  1.00 91.81           C  \\nATOM    253  CZ  PHE A  30     -13.020   3.631  13.337  1.00 91.81           C  \\nATOM    254  N   ALA A  31     -10.156  -1.445  17.891  1.00 91.52           N  \\nATOM    255  CA  ALA A  31     -10.266  -2.623  18.747  1.00 91.52           C  \\nATOM    256  C   ALA A  31     -10.089  -2.252  20.217  1.00 91.52           C  \\nATOM    257  O   ALA A  31     -10.693  -2.870  21.097  1.00 91.52           O  \\nATOM    258  CB  ALA A  31      -9.236  -3.674  18.339  1.00 91.52           C  \\nATOM    259  N   ARG A  32      -9.328  -1.083  20.452  1.00 86.88           N  \\nATOM    260  CA  ARG A  32      -9.076  -0.684  21.833  1.00 86.88           C  \\nATOM    261  C   ARG A  32     -10.232   0.145  22.383  1.00 86.88           C  \\nATOM    262  O   ARG A  32     -10.480   0.150  23.591  1.00 86.88           O  \\nATOM    263  CB  ARG A  32      -7.770   0.106  21.935  1.00 86.88           C  \\nATOM    264  CG  ARG A  32      -6.520  -0.749  21.795  1.00 86.88           C  \\nATOM    265  CD  ARG A  32      -5.256   0.049  22.080  1.00 86.88           C  \\nATOM    266  NE  ARG A  32      -4.912   0.930  20.968  1.00 86.88           N  \\nATOM    267  CZ  ARG A  32      -3.747   1.556  20.830  1.00 86.88           C  \\nATOM    268  NH1 ARG A  32      -2.787   1.410  21.736  1.00 86.88           N  \\nATOM    269  NH2 ARG A  32      -3.540   2.335  19.778  1.00 86.88           N  \\nATOM    270  N   GLY A  33     -10.937   0.861  21.443  1.00 70.68           N  \\nATOM    271  CA  GLY A  33     -12.054   1.677  21.891  1.00 70.68           C  \\nATOM    272  C   GLY A  33     -13.337   0.887  22.069  1.00 70.68           C  \\nATOM    273  O   GLY A  33     -14.149   1.200  22.942  1.00 70.68           O  \\nTER     274      GLY A  33                                                       \\nEND   \\n\",\"pdb\");\n\tviewer_16788863678521886.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n\tviewer_16788863678521886.zoomTo();\nviewer_16788863678521886.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_16788863678521886\"  style=\"position: relative; width: 640px; height: 480px\">\n",
       "        <p id=\"3dmolwarning_16788863678521886\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
       "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
       "}\n",
       "\n",
       "var viewer_16788863678521886 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_16788863678521886\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_16788863678521886 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788863678521886\"),{backgroundColor:\"white\"});\n",
       "viewer_16788863678521886.zoomTo();\n",
       "\tviewer_16788863678521886.addModel(\"ATOM      1  N   GLN A   0      16.013  -3.487 -23.447  1.00 52.84           N  \\nATOM      2  CA  GLN A   0      16.230  -2.554 -22.347  1.00 52.84           C  \\nATOM      3  C   GLN A   0      14.918  -2.215 -21.645  1.00 52.84           C  \\nATOM      4  O   GLN A   0      14.718  -1.081 -21.205  1.00 52.84           O  \\nATOM      5  CB  GLN A   0      16.901  -1.275 -22.852  1.00 52.84           C  \\nATOM      6  CG  GLN A   0      18.419  -1.294 -22.746  1.00 52.84           C  \\nATOM      7  CD  GLN A   0      19.067  -0.080 -23.386  1.00 52.84           C  \\nATOM      8  OE1 GLN A   0      18.397   0.727 -24.038  1.00 52.84           O  \\nATOM      9  NE2 GLN A   0      20.377   0.057 -23.206  1.00 52.84           N  \\nATOM     10  N   GLY A   1      13.903  -3.192 -21.633  1.00 62.65           N  \\nATOM     11  CA  GLY A   1      12.547  -3.059 -21.126  1.00 62.65           C  \\nATOM     12  C   GLY A   1      12.445  -3.280 -19.628  1.00 62.65           C  \\nATOM     13  O   GLY A   1      11.524  -2.777 -18.982  1.00 62.65           O  \\nATOM     14  N   TRP A   2      13.568  -3.709 -18.939  1.00 61.13           N  \\nATOM     15  CA  TRP A   2      13.383  -4.032 -17.528  1.00 61.13           C  \\nATOM     16  C   TRP A   2      13.804  -2.865 -16.642  1.00 61.13           C  \\nATOM     17  O   TRP A   2      13.465  -2.823 -15.457  1.00 61.13           O  \\nATOM     18  CB  TRP A   2      14.178  -5.286 -17.154  1.00 61.13           C  \\nATOM     19  CG  TRP A   2      14.012  -6.423 -18.118  1.00 61.13           C  \\nATOM     20  CD1 TRP A   2      12.893  -6.736 -18.839  1.00 61.13           C  \\nATOM     21  CD2 TRP A   2      14.998  -7.401 -18.463  1.00 61.13           C  \\nATOM     22  NE1 TRP A   2      13.124  -7.850 -19.612  1.00 61.13           N  \\nATOM     23  CE2 TRP A   2      14.407  -8.277 -19.400  1.00 61.13           C  \\nATOM     24  CE3 TRP A   2      16.325  -7.621 -18.070  1.00 61.13           C  \\nATOM     25  CZ2 TRP A   2      15.100  -9.358 -19.951  1.00 61.13           C  \\nATOM     26  CZ3 TRP A   2      17.012  -8.697 -18.620  1.00 61.13           C  \\nATOM     27  CH2 TRP A   2      16.396  -9.551 -19.550  1.00 61.13           C  \\nATOM     28  N   ALA A   3      14.667  -1.996 -17.208  1.00 63.05           N  \\nATOM     29  CA  ALA A   3      15.277  -1.019 -16.309  1.00 63.05           C  \\nATOM     30  C   ALA A   3      14.227  -0.073 -15.733  1.00 63.05           C  \\nATOM     31  O   ALA A   3      14.353   0.386 -14.596  1.00 63.05           O  \\nATOM     32  CB  ALA A   3      16.359  -0.227 -17.039  1.00 63.05           C  \\nATOM     33  N   GLY A   4      13.044  -0.108 -16.331  1.00 63.69           N  \\nATOM     34  CA  GLY A   4      12.111   0.886 -15.824  1.00 63.69           C  \\nATOM     35  C   GLY A   4      11.092   0.309 -14.859  1.00 63.69           C  \\nATOM     36  O   GLY A   4      10.358   1.054 -14.205  1.00 63.69           O  \\nATOM     37  N   ARG A   5      11.128  -1.014 -14.684  1.00 65.68           N  \\nATOM     38  CA  ARG A   5      10.090  -1.559 -13.814  1.00 65.68           C  \\nATOM     39  C   ARG A   5      10.524  -1.519 -12.352  1.00 65.68           C  \\nATOM     40  O   ARG A   5       9.696  -1.650 -11.449  1.00 65.68           O  \\nATOM     41  CB  ARG A   5       9.746  -2.994 -14.219  1.00 65.68           C  \\nATOM     42  CG  ARG A   5       9.013  -3.100 -15.547  1.00 65.68           C  \\nATOM     43  CD  ARG A   5       8.558  -4.525 -15.827  1.00 65.68           C  \\nATOM     44  NE  ARG A   5       8.081  -4.678 -17.199  1.00 65.68           N  \\nATOM     45  CZ  ARG A   5       7.321  -5.681 -17.629  1.00 65.68           C  \\nATOM     46  NH1 ARG A   5       6.934  -6.643 -16.800  1.00 65.68           N  \\nATOM     47  NH2 ARG A   5       6.943  -5.722 -18.899  1.00 65.68           N  \\nATOM     48  N   GLY A   6      11.885  -1.244 -12.155  1.00 75.29           N  \\nATOM     49  CA  GLY A   6      12.314  -1.287 -10.766  1.00 75.29           C  \\nATOM     50  C   GLY A   6      11.736  -0.162  -9.929  1.00 75.29           C  \\nATOM     51  O   GLY A   6      11.129  -0.408  -8.884  1.00 75.29           O  \\nATOM     52  N   PRO A   7      11.814   1.001 -10.470  1.00 78.58           N  \\nATOM     53  CA  PRO A   7      11.333   2.095  -9.623  1.00 78.58           C  \\nATOM     54  C   PRO A   7       9.818   2.068  -9.429  1.00 78.58           C  \\nATOM     55  O   PRO A   7       9.326   2.392  -8.345  1.00 78.58           O  \\nATOM     56  CB  PRO A   7      11.763   3.349 -10.389  1.00 78.58           C  \\nATOM     57  CG  PRO A   7      12.844   2.882 -11.310  1.00 78.58           C  \\nATOM     58  CD  PRO A   7      12.648   1.415 -11.571  1.00 78.58           C  \\nATOM     59  N   LEU A   8       9.134   1.549 -10.525  1.00 84.88           N  \\nATOM     60  CA  LEU A   8       7.683   1.522 -10.373  1.00 84.88           C  \\nATOM     61  C   LEU A   8       7.261   0.447  -9.377  1.00 84.88           C  \\nATOM     62  O   LEU A   8       6.366   0.670  -8.559  1.00 84.88           O  \\nATOM     63  CB  LEU A   8       7.007   1.276 -11.724  1.00 84.88           C  \\nATOM     64  CG  LEU A   8       7.065   2.426 -12.730  1.00 84.88           C  \\nATOM     65  CD1 LEU A   8       6.460   1.996 -14.063  1.00 84.88           C  \\nATOM     66  CD2 LEU A   8       6.345   3.654 -12.182  1.00 84.88           C  \\nATOM     67  N   MET A   9       8.038  -0.666  -9.390  1.00 84.49           N  \\nATOM     68  CA  MET A   9       7.706  -1.749  -8.468  1.00 84.49           C  \\nATOM     69  C   MET A   9       8.008  -1.348  -7.027  1.00 84.49           C  \\nATOM     70  O   MET A   9       7.261  -1.696  -6.112  1.00 84.49           O  \\nATOM     71  CB  MET A   9       8.476  -3.020  -8.830  1.00 84.49           C  \\nATOM     72  CG  MET A   9       7.995  -3.684 -10.109  1.00 84.49           C  \\nATOM     73  SD  MET A   9       6.248  -4.235 -10.001  1.00 84.49           S  \\nATOM     74  CE  MET A   9       6.444  -5.719  -8.974  1.00 84.49           C  \\nATOM     75  N   GLN A  10       9.043  -0.570  -6.909  1.00 88.14           N  \\nATOM     76  CA  GLN A  10       9.397  -0.098  -5.574  1.00 88.14           C  \\nATOM     77  C   GLN A  10       8.354   0.881  -5.042  1.00 88.14           C  \\nATOM     78  O   GLN A  10       7.976   0.817  -3.871  1.00 88.14           O  \\nATOM     79  CB  GLN A  10      10.777   0.561  -5.585  1.00 88.14           C  \\nATOM     80  CG  GLN A  10      11.920  -0.411  -5.847  1.00 88.14           C  \\nATOM     81  CD  GLN A  10      13.258   0.287  -6.008  1.00 88.14           C  \\nATOM     82  OE1 GLN A  10      13.333   1.400  -6.537  1.00 88.14           O  \\nATOM     83  NE2 GLN A  10      14.324  -0.364  -5.555  1.00 88.14           N  \\nATOM     84  N   ALA A  11       7.944   1.758  -5.992  1.00 91.01           N  \\nATOM     85  CA  ALA A  11       6.923   2.723  -5.592  1.00 91.01           C  \\nATOM     86  C   ALA A  11       5.637   2.018  -5.170  1.00 91.01           C  \\nATOM     87  O   ALA A  11       5.032   2.372  -4.156  1.00 91.01           O  \\nATOM     88  CB  ALA A  11       6.641   3.701  -6.729  1.00 91.01           C  \\nATOM     89  N   VAL A  12       5.343   0.970  -5.890  1.00 91.80           N  \\nATOM     90  CA  VAL A  12       4.133   0.210  -5.595  1.00 91.80           C  \\nATOM     91  C   VAL A  12       4.285  -0.505  -4.254  1.00 91.80           C  \\nATOM     92  O   VAL A  12       3.364  -0.504  -3.435  1.00 91.80           O  \\nATOM     93  CB  VAL A  12       3.818  -0.811  -6.711  1.00 91.80           C  \\nATOM     94  CG1 VAL A  12       2.710  -1.766  -6.271  1.00 91.80           C  \\nATOM     95  CG2 VAL A  12       3.425  -0.089  -7.999  1.00 91.80           C  \\nATOM     96  N   GLN A  13       5.439  -1.032  -3.968  1.00 92.29           N  \\nATOM     97  CA  GLN A  13       5.693  -1.727  -2.711  1.00 92.29           C  \\nATOM     98  C   GLN A  13       5.580  -0.775  -1.523  1.00 92.29           C  \\nATOM     99  O   GLN A  13       4.956  -1.106  -0.513  1.00 92.29           O  \\nATOM    100  CB  GLN A  13       7.074  -2.383  -2.729  1.00 92.29           C  \\nATOM    101  CG  GLN A  13       7.163  -3.606  -3.631  1.00 92.29           C  \\nATOM    102  CD  GLN A  13       8.575  -4.147  -3.749  1.00 92.29           C  \\nATOM    103  OE1 GLN A  13       9.463  -3.779  -2.973  1.00 92.29           O  \\nATOM    104  NE2 GLN A  13       8.795  -5.025  -4.722  1.00 92.29           N  \\nATOM    105  N   PHE A  14       6.146   0.399  -1.733  1.00 94.59           N  \\nATOM    106  CA  PHE A  14       6.107   1.359  -0.636  1.00 94.59           C  \\nATOM    107  C   PHE A  14       4.674   1.781  -0.336  1.00 94.59           C  \\nATOM    108  O   PHE A  14       4.283   1.883   0.829  1.00 94.59           O  \\nATOM    109  CB  PHE A  14       6.959   2.589  -0.966  1.00 94.59           C  \\nATOM    110  CG  PHE A  14       8.414   2.432  -0.617  1.00 94.59           C  \\nATOM    111  CD1 PHE A  14       8.825   2.406   0.711  1.00 94.59           C  \\nATOM    112  CD2 PHE A  14       9.371   2.311  -1.616  1.00 94.59           C  \\nATOM    113  CE1 PHE A  14      10.172   2.261   1.037  1.00 94.59           C  \\nATOM    114  CE2 PHE A  14      10.718   2.166  -1.297  1.00 94.59           C  \\nATOM    115  CZ  PHE A  14      11.117   2.142   0.030  1.00 94.59           C  \\nATOM    116  N   ALA A  15       3.952   1.959  -1.381  1.00 94.71           N  \\nATOM    117  CA  ALA A  15       2.562   2.375  -1.216  1.00 94.71           C  \\nATOM    118  C   ALA A  15       1.756   1.315  -0.471  1.00 94.71           C  \\nATOM    119  O   ALA A  15       0.972   1.637   0.424  1.00 94.71           O  \\nATOM    120  CB  ALA A  15       1.928   2.664  -2.575  1.00 94.71           C  \\nATOM    121  N   PHE A  16       2.049   0.081  -0.824  1.00 94.59           N  \\nATOM    122  CA  PHE A  16       1.319  -0.997  -0.167  1.00 94.59           C  \\nATOM    123  C   PHE A  16       1.701  -1.091   1.305  1.00 94.59           C  \\nATOM    124  O   PHE A  16       0.833  -1.236   2.169  1.00 94.59           O  \\nATOM    125  CB  PHE A  16       1.587  -2.333  -0.866  1.00 94.59           C  \\nATOM    126  CG  PHE A  16       0.619  -2.644  -1.974  1.00 94.59           C  \\nATOM    127  CD1 PHE A  16      -0.675  -3.064  -1.689  1.00 94.59           C  \\nATOM    128  CD2 PHE A  16       1.002  -2.517  -3.303  1.00 94.59           C  \\nATOM    129  CE1 PHE A  16      -1.574  -3.352  -2.713  1.00 94.59           C  \\nATOM    130  CE2 PHE A  16       0.109  -2.804  -4.332  1.00 94.59           C  \\nATOM    131  CZ  PHE A  16      -1.178  -3.222  -4.035  1.00 94.59           C  \\nATOM    132  N   ILE A  17       2.957  -1.023   1.548  1.00 94.05           N  \\nATOM    133  CA  ILE A  17       3.430  -1.158   2.921  1.00 94.05           C  \\nATOM    134  C   ILE A  17       2.888  -0.009   3.768  1.00 94.05           C  \\nATOM    135  O   ILE A  17       2.422  -0.222   4.890  1.00 94.05           O  \\nATOM    136  CB  ILE A  17       4.973  -1.193   2.988  1.00 94.05           C  \\nATOM    137  CG1 ILE A  17       5.505  -2.491   2.369  1.00 94.05           C  \\nATOM    138  CG2 ILE A  17       5.455  -1.036   4.433  1.00 94.05           C  \\nATOM    139  CD1 ILE A  17       6.999  -2.470   2.076  1.00 94.05           C  \\nATOM    140  N   ARG A  18       2.942   1.142   3.207  1.00 94.04           N  \\nATOM    141  CA  ARG A  18       2.415   2.311   3.904  1.00 94.04           C  \\nATOM    142  C   ARG A  18       0.920   2.163   4.168  1.00 94.04           C  \\nATOM    143  O   ARG A  18       0.459   2.379   5.290  1.00 94.04           O  \\nATOM    144  CB  ARG A  18       2.681   3.584   3.098  1.00 94.04           C  \\nATOM    145  CG  ARG A  18       2.158   4.851   3.755  1.00 94.04           C  \\nATOM    146  CD  ARG A  18       2.319   6.064   2.851  1.00 94.04           C  \\nATOM    147  NE  ARG A  18       1.804   7.278   3.479  1.00 94.04           N  \\nATOM    148  CZ  ARG A  18       0.924   8.105   2.923  1.00 94.04           C  \\nATOM    149  NH1 ARG A  18       0.441   7.864   1.709  1.00 94.04           N  \\nATOM    150  NH2 ARG A  18       0.523   9.181   3.584  1.00 94.04           N  \\nATOM    151  N   ASP A  19       0.143   1.752   3.218  1.00 93.98           N  \\nATOM    152  CA  ASP A  19      -1.304   1.601   3.338  1.00 93.98           C  \\nATOM    153  C   ASP A  19      -1.661   0.503   4.338  1.00 93.98           C  \\nATOM    154  O   ASP A  19      -2.584   0.662   5.139  1.00 93.98           O  \\nATOM    155  CB  ASP A  19      -1.927   1.294   1.975  1.00 93.98           C  \\nATOM    156  CG  ASP A  19      -3.432   1.491   1.953  1.00 93.98           C  \\nATOM    157  OD1 ASP A  19      -3.909   2.593   2.304  1.00 93.98           O  \\nATOM    158  OD2 ASP A  19      -4.149   0.536   1.584  1.00 93.98           O  \\nATOM    159  N   SER A  20      -0.895  -0.599   4.309  1.00 94.87           N  \\nATOM    160  CA  SER A  20      -1.146  -1.699   5.234  1.00 94.87           C  \\nATOM    161  C   SER A  20      -0.897  -1.275   6.678  1.00 94.87           C  \\nATOM    162  O   SER A  20      -1.631  -1.676   7.584  1.00 94.87           O  \\nATOM    163  CB  SER A  20      -0.267  -2.902   4.889  1.00 94.87           C  \\nATOM    164  OG  SER A  20       1.097  -2.622   5.156  1.00 94.87           O  \\nATOM    165  N   HIS A  21       0.077  -0.422   6.865  1.00 92.93           N  \\nATOM    166  CA  HIS A  21       0.402   0.031   8.212  1.00 92.93           C  \\nATOM    167  C   HIS A  21      -0.674   0.966   8.754  1.00 92.93           C  \\nATOM    168  O   HIS A  21      -1.074   0.852   9.915  1.00 92.93           O  \\nATOM    169  CB  HIS A  21       1.762   0.732   8.228  1.00 92.93           C  \\nATOM    170  CG  HIS A  21       2.921  -0.210   8.309  1.00 92.93           C  \\nATOM    171  ND1 HIS A  21       3.460  -0.626   9.507  1.00 92.93           N  \\nATOM    172  CD2 HIS A  21       3.641  -0.819   7.337  1.00 92.93           C  \\nATOM    173  CE1 HIS A  21       4.466  -1.452   9.268  1.00 92.93           C  \\nATOM    174  NE2 HIS A  21       4.596  -1.586   7.959  1.00 92.93           N  \\nATOM    175  N   ILE A  22      -1.204   1.810   7.899  1.00 94.15           N  \\nATOM    176  CA  ILE A  22      -2.227   2.765   8.312  1.00 94.15           C  \\nATOM    177  C   ILE A  22      -3.531   2.029   8.610  1.00 94.15           C  \\nATOM    178  O   ILE A  22      -4.190   2.303   9.616  1.00 94.15           O  \\nATOM    179  CB  ILE A  22      -2.457   3.847   7.233  1.00 94.15           C  \\nATOM    180  CG1 ILE A  22      -1.212   4.730   7.087  1.00 94.15           C  \\nATOM    181  CG2 ILE A  22      -3.691   4.691   7.569  1.00 94.15           C  \\nATOM    182  CD1 ILE A  22      -1.277   5.703   5.918  1.00 94.15           C  \\nATOM    183  N   GLN A  23      -3.798   1.119   7.734  1.00 95.05           N  \\nATOM    184  CA  GLN A  23      -5.006   0.325   7.930  1.00 95.05           C  \\nATOM    185  C   GLN A  23      -4.952  -0.442   9.248  1.00 95.05           C  \\nATOM    186  O   GLN A  23      -5.941  -0.495   9.983  1.00 95.05           O  \\nATOM    187  CB  GLN A  23      -5.206  -0.646   6.765  1.00 95.05           C  \\nATOM    188  CG  GLN A  23      -6.439  -1.529   6.905  1.00 95.05           C  \\nATOM    189  CD  GLN A  23      -7.736  -0.746   6.806  1.00 95.05           C  \\nATOM    190  OE1 GLN A  23      -7.796   0.300   6.152  1.00 95.05           O  \\nATOM    191  NE2 GLN A  23      -8.782  -1.247   7.454  1.00 95.05           N  \\nATOM    192  N   GLN A  24      -3.813  -1.002   9.576  1.00 94.18           N  \\nATOM    193  CA  GLN A  24      -3.655  -1.757  10.814  1.00 94.18           C  \\nATOM    194  C   GLN A  24      -3.795  -0.850  12.033  1.00 94.18           C  \\nATOM    195  O   GLN A  24      -4.382  -1.245  13.043  1.00 94.18           O  \\nATOM    196  CB  GLN A  24      -2.301  -2.468  10.841  1.00 94.18           C  \\nATOM    197  CG  GLN A  24      -2.206  -3.647   9.883  1.00 94.18           C  \\nATOM    198  CD  GLN A  24      -3.068  -4.820  10.310  1.00 94.18           C  \\nATOM    199  OE1 GLN A  24      -3.140  -5.156  11.496  1.00 94.18           O  \\nATOM    200  NE2 GLN A  24      -3.728  -5.453   9.345  1.00 94.18           N  \\nATOM    201  N   GLN A  25      -3.279   0.356  11.847  1.00 94.12           N  \\nATOM    202  CA  GLN A  25      -3.364   1.299  12.957  1.00 94.12           C  \\nATOM    203  C   GLN A  25      -4.814   1.674  13.249  1.00 94.12           C  \\nATOM    204  O   GLN A  25      -5.222   1.741  14.410  1.00 94.12           O  \\nATOM    205  CB  GLN A  25      -2.546   2.556  12.659  1.00 94.12           C  \\nATOM    206  CG  GLN A  25      -1.041   2.327  12.671  1.00 94.12           C  \\nATOM    207  CD  GLN A  25      -0.256   3.559  12.259  1.00 94.12           C  \\nATOM    208  OE1 GLN A  25      -0.696   4.334  11.403  1.00 94.12           O  \\nATOM    209  NE2 GLN A  25       0.911   3.748  12.865  1.00 94.12           N  \\nATOM    210  N   ARG A  26      -5.557   1.776  12.172  1.00 92.16           N  \\nATOM    211  CA  ARG A  26      -6.953   2.158  12.355  1.00 92.16           C  \\nATOM    212  C   ARG A  26      -7.750   1.030  13.002  1.00 92.16           C  \\nATOM    213  O   ARG A  26      -8.572   1.273  13.887  1.00 92.16           O  \\nATOM    214  CB  ARG A  26      -7.584   2.544  11.015  1.00 92.16           C  \\nATOM    215  CG  ARG A  26      -7.108   3.882  10.472  1.00 92.16           C  \\nATOM    216  CD  ARG A  26      -8.037   4.415   9.390  1.00 92.16           C  \\nATOM    217  NE  ARG A  26      -8.073   3.531   8.227  1.00 92.16           N  \\nATOM    218  CZ  ARG A  26      -7.282   3.644   7.164  1.00 92.16           C  \\nATOM    219  NH1 ARG A  26      -6.372   4.610   7.094  1.00 92.16           N  \\nATOM    220  NH2 ARG A  26      -7.400   2.784   6.161  1.00 92.16           N  \\nATOM    221  N   LEU A  27      -7.414  -0.192  12.534  1.00 95.75           N  \\nATOM    222  CA  LEU A  27      -8.109  -1.340  13.107  1.00 95.75           C  \\nATOM    223  C   LEU A  27      -7.778  -1.491  14.588  1.00 95.75           C  \\nATOM    224  O   LEU A  27      -8.665  -1.758  15.403  1.00 95.75           O  \\nATOM    225  CB  LEU A  27      -7.738  -2.621  12.356  1.00 95.75           C  \\nATOM    226  CG  LEU A  27      -8.484  -3.890  12.770  1.00 95.75           C  \\nATOM    227  CD1 LEU A  27      -9.964  -3.771  12.424  1.00 95.75           C  \\nATOM    228  CD2 LEU A  27      -7.870  -5.114  12.101  1.00 95.75           C  \\nATOM    229  N   ALA A  28      -6.511  -1.243  14.915  1.00 94.26           N  \\nATOM    230  CA  ALA A  28      -6.083  -1.378  16.305  1.00 94.26           C  \\nATOM    231  C   ALA A  28      -6.740  -0.320  17.187  1.00 94.26           C  \\nATOM    232  O   ALA A  28      -7.119  -0.601  18.326  1.00 94.26           O  \\nATOM    233  CB  ALA A  28      -4.562  -1.279  16.405  1.00 94.26           C  \\nATOM    234  N   GLN A  29      -6.978   0.805  16.593  1.00 91.86           N  \\nATOM    235  CA  GLN A  29      -7.614   1.878  17.350  1.00 91.86           C  \\nATOM    236  C   GLN A  29      -9.080   1.559  17.630  1.00 91.86           C  \\nATOM    237  O   GLN A  29      -9.580   1.825  18.724  1.00 91.86           O  \\nATOM    238  CB  GLN A  29      -7.499   3.206  16.600  1.00 91.86           C  \\nATOM    239  CG  GLN A  29      -6.081   3.757  16.539  1.00 91.86           C  \\nATOM    240  CD  GLN A  29      -5.970   4.997  15.672  1.00 91.86           C  \\nATOM    241  OE1 GLN A  29      -6.555   5.066  14.585  1.00 91.86           O  \\nATOM    242  NE2 GLN A  29      -5.219   5.986  16.145  1.00 91.86           N  \\nATOM    243  N   PHE A  30      -9.621   0.862  16.729  1.00 91.81           N  \\nATOM    244  CA  PHE A  30     -11.034   0.549  16.902  1.00 91.81           C  \\nATOM    245  C   PHE A  30     -11.219  -0.603  17.881  1.00 91.81           C  \\nATOM    246  O   PHE A  30     -12.224  -0.666  18.593  1.00 91.81           O  \\nATOM    247  CB  PHE A  30     -11.678   0.202  15.555  1.00 91.81           C  \\nATOM    248  CG  PHE A  30     -12.148   1.403  14.780  1.00 91.81           C  \\nATOM    249  CD1 PHE A  30     -13.242   2.143  15.213  1.00 91.81           C  \\nATOM    250  CD2 PHE A  30     -11.496   1.792  13.617  1.00 91.81           C  \\nATOM    251  CE1 PHE A  30     -13.680   3.254  14.497  1.00 91.81           C  \\nATOM    252  CE2 PHE A  30     -11.928   2.902  12.896  1.00 91.81           C  \\nATOM    253  CZ  PHE A  30     -13.020   3.631  13.337  1.00 91.81           C  \\nATOM    254  N   ALA A  31     -10.156  -1.445  17.891  1.00 91.52           N  \\nATOM    255  CA  ALA A  31     -10.266  -2.623  18.747  1.00 91.52           C  \\nATOM    256  C   ALA A  31     -10.089  -2.252  20.217  1.00 91.52           C  \\nATOM    257  O   ALA A  31     -10.693  -2.870  21.097  1.00 91.52           O  \\nATOM    258  CB  ALA A  31      -9.236  -3.674  18.339  1.00 91.52           C  \\nATOM    259  N   ARG A  32      -9.328  -1.083  20.452  1.00 86.88           N  \\nATOM    260  CA  ARG A  32      -9.076  -0.684  21.833  1.00 86.88           C  \\nATOM    261  C   ARG A  32     -10.232   0.145  22.383  1.00 86.88           C  \\nATOM    262  O   ARG A  32     -10.480   0.150  23.591  1.00 86.88           O  \\nATOM    263  CB  ARG A  32      -7.770   0.106  21.935  1.00 86.88           C  \\nATOM    264  CG  ARG A  32      -6.520  -0.749  21.795  1.00 86.88           C  \\nATOM    265  CD  ARG A  32      -5.256   0.049  22.080  1.00 86.88           C  \\nATOM    266  NE  ARG A  32      -4.912   0.930  20.968  1.00 86.88           N  \\nATOM    267  CZ  ARG A  32      -3.747   1.556  20.830  1.00 86.88           C  \\nATOM    268  NH1 ARG A  32      -2.787   1.410  21.736  1.00 86.88           N  \\nATOM    269  NH2 ARG A  32      -3.540   2.335  19.778  1.00 86.88           N  \\nATOM    270  N   GLY A  33     -10.937   0.861  21.443  1.00 70.68           N  \\nATOM    271  CA  GLY A  33     -12.054   1.677  21.891  1.00 70.68           C  \\nATOM    272  C   GLY A  33     -13.337   0.887  22.069  1.00 70.68           C  \\nATOM    273  O   GLY A  33     -14.149   1.200  22.942  1.00 70.68           O  \\nTER     274      GLY A  33                                                       \\nEND   \\n\",\"pdb\");\n",
       "\tviewer_16788863678521886.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n",
       "\tviewer_16788863678521886.zoomTo();\n",
       "viewer_16788863678521886.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'./output_model_B/~~HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH~~_812_0.pdb'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample_sequence (model_B,\n",
    "   x_data=['~~HHHHHHHHHHHHHHHHHHHHHHHHHHHHHH~~'],\n",
    "     flag=812,cond_scales=1.,foldproteins=True,\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f82ea72-8005-470a-bb96-3fe16dc0ce70",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing 1 samples...from image conditingig x_data  ...\n",
      "['~~EEEEEETTEEEEEE~~']\n",
      "Device:  cuda:0\n",
      "X_cond= None\n",
      "Conditioning target sequence provided via x_data ... ['~~EEEEEETTEEEEEE~~']\n",
      "x_data from target sequence= tensor([[[0.2222, 0.2222, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "          0.4444, 0.4444, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "          0.2222, 0.2222, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0') torch.Size([1, 1, 128])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c756b19fb69b488e862dbfcb2a75a0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b941cba81daf4cd5bb69dd7a44906e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "For None or ~~EEEEEETTEEEEEE~~, predicted sequence GVCRCLCRRGVCRCDCTR\n",
      "Writing FASTA file:  ./output_model_B/fasta_in_820.fasta\n",
      "Now run OmegaFold.... on device=cuda:0\n",
      "INFO:root:Loading weights from /home/mbuehler/.cache/omegafold_ckpt/model.pt\n",
      "INFO:root:Constructing OmegaFold\n",
      "INFO:root:Reading ./output_model_B/fasta_in_820.fasta\n",
      "INFO:root:Predicting 1th chain in ./output_model_B/fasta_in_820.fasta\n",
      "INFO:root:18 residues in this chain.\n",
      "INFO:root:Finished prediction in 30.40 seconds.\n",
      "INFO:root:Saving prediction to ./output_model_B/temp_820.pdb\n",
      "INFO:root:Saved\n",
      "INFO:root:Done!\n",
      "Done OmegaFold\n",
      "Resulting PDB file...:  ./output_model_B/temp_820.PDB\n",
      "Properly named PDB file produced: ./output_model_B/~~EEEEEETTEEEEEE~~_820_0.pdb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x10 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_1678886588104604\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_1678886588104604\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_1678886588104604 = null;\nvar warn = document.getElementById(\"3dmolwarning_1678886588104604\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_1678886588104604 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_1678886588104604\"),{backgroundColor:\"white\"});\nviewer_1678886588104604.zoomTo();\n\tviewer_1678886588104604.addModel(\"ATOM      1  N   GLY A   0      -0.328  -7.622   1.653  1.00 76.03           N  \\nATOM      2  CA  GLY A   0       0.086  -6.278   1.281  1.00 76.03           C  \\nATOM      3  C   GLY A   0      -0.898  -5.585   0.358  1.00 76.03           C  \\nATOM      4  O   GLY A   0      -1.235  -6.109  -0.706  1.00 76.03           O  \\nATOM      5  N   VAL A   1      -1.814  -5.085   1.039  1.00 90.19           N  \\nATOM      6  CA  VAL A   1      -2.823  -4.328   0.305  1.00 90.19           C  \\nATOM      7  C   VAL A   1      -2.199  -3.061  -0.274  1.00 90.19           C  \\nATOM      8  O   VAL A   1      -1.409  -2.389   0.394  1.00 90.19           O  \\nATOM      9  CB  VAL A   1      -4.027  -3.968   1.204  1.00 90.19           C  \\nATOM     10  CG1 VAL A   1      -5.105  -3.245   0.398  1.00 90.19           C  \\nATOM     11  CG2 VAL A   1      -4.597  -5.224   1.860  1.00 90.19           C  \\nATOM     12  N   CYS A   2      -2.347  -2.930  -1.574  1.00 94.66           N  \\nATOM     13  CA  CYS A   2      -1.876  -1.719  -2.236  1.00 94.66           C  \\nATOM     14  C   CYS A   2      -3.021  -0.739  -2.460  1.00 94.66           C  \\nATOM     15  O   CYS A   2      -4.133  -1.145  -2.800  1.00 94.66           O  \\nATOM     16  CB  CYS A   2      -1.216  -2.060  -3.572  1.00 94.66           C  \\nATOM     17  SG  CYS A   2       0.248  -3.106  -3.415  1.00 94.66           S  \\nATOM     18  N   ARG A   3      -2.867   0.434  -2.151  1.00 95.07           N  \\nATOM     19  CA  ARG A   3      -3.828   1.503  -2.401  1.00 95.07           C  \\nATOM     20  C   ARG A   3      -3.233   2.571  -3.313  1.00 95.07           C  \\nATOM     21  O   ARG A   3      -2.078   2.967  -3.142  1.00 95.07           O  \\nATOM     22  CB  ARG A   3      -4.286   2.133  -1.085  1.00 95.07           C  \\nATOM     23  CG  ARG A   3      -5.102   1.199  -0.206  1.00 95.07           C  \\nATOM     24  CD  ARG A   3      -5.582   1.892   1.062  1.00 95.07           C  \\nATOM     25  NE  ARG A   3      -6.301   0.973   1.940  1.00 95.07           N  \\nATOM     26  CZ  ARG A   3      -6.384   1.097   3.262  1.00 95.07           C  \\nATOM     27  NH1 ARG A   3      -5.792   2.108   3.887  1.00 95.07           N  \\nATOM     28  NH2 ARG A   3      -7.065   0.203   3.964  1.00 95.07           N  \\nATOM     29  N   CYS A   4      -3.874   2.887  -4.318  1.00 94.72           N  \\nATOM     30  CA  CYS A   4      -3.426   3.920  -5.246  1.00 94.72           C  \\nATOM     31  C   CYS A   4      -4.280   5.175  -5.119  1.00 94.72           C  \\nATOM     32  O   CYS A   4      -5.489   5.089  -4.897  1.00 94.72           O  \\nATOM     33  CB  CYS A   4      -3.471   3.405  -6.684  1.00 94.72           C  \\nATOM     34  SG  CYS A   4      -2.437   1.952  -6.970  1.00 94.72           S  \\nATOM     35  N   LEU A   5      -3.651   6.259  -5.029  1.00 93.77           N  \\nATOM     36  CA  LEU A   5      -4.357   7.534  -4.964  1.00 93.77           C  \\nATOM     37  C   LEU A   5      -3.888   8.473  -6.070  1.00 93.77           C  \\nATOM     38  O   LEU A   5      -2.687   8.576  -6.334  1.00 93.77           O  \\nATOM     39  CB  LEU A   5      -4.149   8.193  -3.597  1.00 93.77           C  \\nATOM     40  CG  LEU A   5      -4.862   9.527  -3.372  1.00 93.77           C  \\nATOM     41  CD1 LEU A   5      -6.358   9.303  -3.182  1.00 93.77           C  \\nATOM     42  CD2 LEU A   5      -4.269  10.255  -2.171  1.00 93.77           C  \\nATOM     43  N   CYS A   6      -4.782   9.213  -6.767  1.00 95.74           N  \\nATOM     44  CA  CYS A   6      -4.482  10.137  -7.855  1.00 95.74           C  \\nATOM     45  C   CYS A   6      -4.813  11.571  -7.461  1.00 95.74           C  \\nATOM     46  O   CYS A   6      -5.933  11.860  -7.036  1.00 95.74           O  \\nATOM     47  CB  CYS A   6      -5.258   9.753  -9.114  1.00 95.74           C  \\nATOM     48  SG  CYS A   6      -4.914   8.079  -9.700  1.00 95.74           S  \\nATOM     49  N   ARG A   7      -3.878  12.356  -7.433  1.00 94.61           N  \\nATOM     50  CA  ARG A   7      -4.058  13.773  -7.132  1.00 94.61           C  \\nATOM     51  C   ARG A   7      -3.410  14.647  -8.200  1.00 94.61           C  \\nATOM     52  O   ARG A   7      -2.251  14.436  -8.563  1.00 94.61           O  \\nATOM     53  CB  ARG A   7      -3.477  14.108  -5.757  1.00 94.61           C  \\nATOM     54  CG  ARG A   7      -4.213  13.451  -4.600  1.00 94.61           C  \\nATOM     55  CD  ARG A   7      -4.930  14.476  -3.732  1.00 94.61           C  \\nATOM     56  NE  ARG A   7      -3.998  15.198  -2.870  1.00 94.61           N  \\nATOM     57  CZ  ARG A   7      -4.034  15.189  -1.540  1.00 94.61           C  \\nATOM     58  NH1 ARG A   7      -4.960  14.492  -0.891  1.00 94.61           N  \\nATOM     59  NH2 ARG A   7      -3.137  15.882  -0.853  1.00 94.61           N  \\nATOM     60  N   ARG A   8      -4.091  15.658  -8.612  1.00 95.66           N  \\nATOM     61  CA  ARG A   8      -3.634  16.634  -9.597  1.00 95.66           C  \\nATOM     62  C   ARG A   8      -3.016  15.943 -10.807  1.00 95.66           C  \\nATOM     63  O   ARG A   8      -1.981  16.379 -11.316  1.00 95.66           O  \\nATOM     64  CB  ARG A   8      -2.624  17.598  -8.971  1.00 95.66           C  \\nATOM     65  CG  ARG A   8      -3.227  18.537  -7.938  1.00 95.66           C  \\nATOM     66  CD  ARG A   8      -2.174  19.447  -7.321  1.00 95.66           C  \\nATOM     67  NE  ARG A   8      -2.781  20.558  -6.593  1.00 95.66           N  \\nATOM     68  CZ  ARG A   8      -2.110  21.435  -5.852  1.00 95.66           C  \\nATOM     69  NH1 ARG A   8      -0.791  21.348  -5.726  1.00 95.66           N  \\nATOM     70  NH2 ARG A   8      -2.763  22.408  -5.232  1.00 95.66           N  \\nATOM     71  N   GLY A   9      -3.564  14.712 -11.177  1.00 93.15           N  \\nATOM     72  CA  GLY A   9      -3.134  14.029 -12.386  1.00 93.15           C  \\nATOM     73  C   GLY A   9      -1.972  13.081 -12.156  1.00 93.15           C  \\nATOM     74  O   GLY A   9      -1.436  12.506 -13.105  1.00 93.15           O  \\nATOM     75  N   VAL A  10      -1.486  13.108 -10.937  1.00 95.73           N  \\nATOM     76  CA  VAL A  10      -0.404  12.191 -10.593  1.00 95.73           C  \\nATOM     77  C   VAL A  10      -0.940  11.068  -9.708  1.00 95.73           C  \\nATOM     78  O   VAL A  10      -1.599  11.326  -8.697  1.00 95.73           O  \\nATOM     79  CB  VAL A  10       0.755  12.923  -9.881  1.00 95.73           C  \\nATOM     80  CG1 VAL A  10       1.888  11.952  -9.555  1.00 95.73           C  \\nATOM     81  CG2 VAL A  10       1.267  14.076 -10.744  1.00 95.73           C  \\nATOM     82  N   CYS A  11      -0.671   9.768 -10.118  1.00 94.53           N  \\nATOM     83  CA  CYS A  11      -1.126   8.634  -9.321  1.00 94.53           C  \\nATOM     84  C   CYS A  11       0.037   7.990  -8.575  1.00 94.53           C  \\nATOM     85  O   CYS A  11       1.108   7.782  -9.148  1.00 94.53           O  \\nATOM     86  CB  CYS A  11      -1.812   7.596 -10.209  1.00 94.53           C  \\nATOM     87  SG  CYS A  11      -3.289   8.214 -11.044  1.00 94.53           S  \\nATOM     88  N   ARG A  12      -0.075   7.884  -7.318  1.00 95.23           N  \\nATOM     89  CA  ARG A  12       0.933   7.208  -6.506  1.00 95.23           C  \\nATOM     90  C   ARG A  12       0.333   6.015  -5.771  1.00 95.23           C  \\nATOM     91  O   ARG A  12      -0.785   6.094  -5.255  1.00 95.23           O  \\nATOM     92  CB  ARG A  12       1.558   8.181  -5.504  1.00 95.23           C  \\nATOM     93  CG  ARG A  12       2.546   9.156  -6.126  1.00 95.23           C  \\nATOM     94  CD  ARG A  12       3.200  10.042  -5.076  1.00 95.23           C  \\nATOM     95  NE  ARG A  12       4.649  10.100  -5.247  1.00 95.23           N  \\nATOM     96  CZ  ARG A  12       5.361  11.222  -5.310  1.00 95.23           C  \\nATOM     97  NH1 ARG A  12       4.768  12.407  -5.216  1.00 95.23           N  \\nATOM     98  NH2 ARG A  12       6.675  11.160  -5.467  1.00 95.23           N  \\nATOM     99  N   CYS A  13       0.962   4.941  -5.896  1.00 94.80           N  \\nATOM    100  CA  CYS A  13       0.521   3.714  -5.241  1.00 94.80           C  \\nATOM    101  C   CYS A  13       1.440   3.355  -4.080  1.00 94.80           C  \\nATOM    102  O   CYS A  13       2.651   3.568  -4.152  1.00 94.80           O  \\nATOM    103  CB  CYS A  13       0.473   2.560  -6.242  1.00 94.80           C  \\nATOM    104  SG  CYS A  13      -0.602   2.870  -7.660  1.00 94.80           S  \\nATOM    105  N   ASP A  14       0.890   2.993  -2.997  1.00 94.11           N  \\nATOM    106  CA  ASP A  14       1.628   2.564  -1.814  1.00 94.11           C  \\nATOM    107  C   ASP A  14       1.156   1.192  -1.339  1.00 94.11           C  \\nATOM    108  O   ASP A  14      -0.045   0.962  -1.185  1.00 94.11           O  \\nATOM    109  CB  ASP A  14       1.480   3.590  -0.688  1.00 94.11           C  \\nATOM    110  CG  ASP A  14       2.416   3.329   0.479  1.00 94.11           C  \\nATOM    111  OD1 ASP A  14       1.945   2.899   1.554  1.00 94.11           O  \\nATOM    112  OD2 ASP A  14       3.635   3.559   0.323  1.00 94.11           O  \\nATOM    113  N   CYS A  15       2.088   0.233  -1.142  1.00 94.28           N  \\nATOM    114  CA  CYS A  15       1.806  -1.147  -0.763  1.00 94.28           C  \\nATOM    115  C   CYS A  15       2.255  -1.423   0.667  1.00 94.28           C  \\nATOM    116  O   CYS A  15       3.321  -0.967   1.086  1.00 94.28           O  \\nATOM    117  CB  CYS A  15       2.497  -2.118  -1.720  1.00 94.28           C  \\nATOM    118  SG  CYS A  15       2.092  -1.839  -3.458  1.00 94.28           S  \\nATOM    119  N   THR A  16       1.473  -1.768   1.480  1.00 88.14           N  \\nATOM    120  CA  THR A  16       1.892  -2.200   2.809  1.00 88.14           C  \\nATOM    121  C   THR A  16       2.150  -3.703   2.833  1.00 88.14           C  \\nATOM    122  O   THR A  16       1.634  -4.441   1.990  1.00 88.14           O  \\nATOM    123  CB  THR A  16       0.836  -1.841   3.871  1.00 88.14           C  \\nATOM    124  OG1 THR A  16      -0.416  -2.440   3.514  1.00 88.14           O  \\nATOM    125  CG2 THR A  16       0.651  -0.331   3.975  1.00 88.14           C  \\nATOM    126  N   ARG A  17       3.328  -4.002   3.528  1.00 84.25           N  \\nATOM    127  CA  ARG A  17       3.627  -5.427   3.634  1.00 84.25           C  \\nATOM    128  C   ARG A  17       2.431  -6.199   4.180  1.00 84.25           C  \\nATOM    129  O   ARG A  17       1.747  -5.729   5.092  1.00 84.25           O  \\nATOM    130  CB  ARG A  17       4.850  -5.654   4.525  1.00 84.25           C  \\nATOM    131  CG  ARG A  17       6.172  -5.306   3.858  1.00 84.25           C  \\nATOM    132  CD  ARG A  17       7.361  -5.755   4.696  1.00 84.25           C  \\nATOM    133  NE  ARG A  17       8.566  -4.995   4.372  1.00 84.25           N  \\nATOM    134  CZ  ARG A  17       9.536  -4.706   5.235  1.00 84.25           C  \\nATOM    135  NH1 ARG A  17       9.461  -5.110   6.499  1.00 84.25           N  \\nATOM    136  NH2 ARG A  17      10.588  -4.009   4.833  1.00 84.25           N  \\nTER     137      ARG A  17                                                       \\nEND   \\n\",\"pdb\");\n\tviewer_1678886588104604.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n\tviewer_1678886588104604.zoomTo();\nviewer_1678886588104604.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_1678886588104604\"  style=\"position: relative; width: 640px; height: 480px\">\n",
       "        <p id=\"3dmolwarning_1678886588104604\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
       "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
       "}\n",
       "\n",
       "var viewer_1678886588104604 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_1678886588104604\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_1678886588104604 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_1678886588104604\"),{backgroundColor:\"white\"});\n",
       "viewer_1678886588104604.zoomTo();\n",
       "\tviewer_1678886588104604.addModel(\"ATOM      1  N   GLY A   0      -0.328  -7.622   1.653  1.00 76.03           N  \\nATOM      2  CA  GLY A   0       0.086  -6.278   1.281  1.00 76.03           C  \\nATOM      3  C   GLY A   0      -0.898  -5.585   0.358  1.00 76.03           C  \\nATOM      4  O   GLY A   0      -1.235  -6.109  -0.706  1.00 76.03           O  \\nATOM      5  N   VAL A   1      -1.814  -5.085   1.039  1.00 90.19           N  \\nATOM      6  CA  VAL A   1      -2.823  -4.328   0.305  1.00 90.19           C  \\nATOM      7  C   VAL A   1      -2.199  -3.061  -0.274  1.00 90.19           C  \\nATOM      8  O   VAL A   1      -1.409  -2.389   0.394  1.00 90.19           O  \\nATOM      9  CB  VAL A   1      -4.027  -3.968   1.204  1.00 90.19           C  \\nATOM     10  CG1 VAL A   1      -5.105  -3.245   0.398  1.00 90.19           C  \\nATOM     11  CG2 VAL A   1      -4.597  -5.224   1.860  1.00 90.19           C  \\nATOM     12  N   CYS A   2      -2.347  -2.930  -1.574  1.00 94.66           N  \\nATOM     13  CA  CYS A   2      -1.876  -1.719  -2.236  1.00 94.66           C  \\nATOM     14  C   CYS A   2      -3.021  -0.739  -2.460  1.00 94.66           C  \\nATOM     15  O   CYS A   2      -4.133  -1.145  -2.800  1.00 94.66           O  \\nATOM     16  CB  CYS A   2      -1.216  -2.060  -3.572  1.00 94.66           C  \\nATOM     17  SG  CYS A   2       0.248  -3.106  -3.415  1.00 94.66           S  \\nATOM     18  N   ARG A   3      -2.867   0.434  -2.151  1.00 95.07           N  \\nATOM     19  CA  ARG A   3      -3.828   1.503  -2.401  1.00 95.07           C  \\nATOM     20  C   ARG A   3      -3.233   2.571  -3.313  1.00 95.07           C  \\nATOM     21  O   ARG A   3      -2.078   2.967  -3.142  1.00 95.07           O  \\nATOM     22  CB  ARG A   3      -4.286   2.133  -1.085  1.00 95.07           C  \\nATOM     23  CG  ARG A   3      -5.102   1.199  -0.206  1.00 95.07           C  \\nATOM     24  CD  ARG A   3      -5.582   1.892   1.062  1.00 95.07           C  \\nATOM     25  NE  ARG A   3      -6.301   0.973   1.940  1.00 95.07           N  \\nATOM     26  CZ  ARG A   3      -6.384   1.097   3.262  1.00 95.07           C  \\nATOM     27  NH1 ARG A   3      -5.792   2.108   3.887  1.00 95.07           N  \\nATOM     28  NH2 ARG A   3      -7.065   0.203   3.964  1.00 95.07           N  \\nATOM     29  N   CYS A   4      -3.874   2.887  -4.318  1.00 94.72           N  \\nATOM     30  CA  CYS A   4      -3.426   3.920  -5.246  1.00 94.72           C  \\nATOM     31  C   CYS A   4      -4.280   5.175  -5.119  1.00 94.72           C  \\nATOM     32  O   CYS A   4      -5.489   5.089  -4.897  1.00 94.72           O  \\nATOM     33  CB  CYS A   4      -3.471   3.405  -6.684  1.00 94.72           C  \\nATOM     34  SG  CYS A   4      -2.437   1.952  -6.970  1.00 94.72           S  \\nATOM     35  N   LEU A   5      -3.651   6.259  -5.029  1.00 93.77           N  \\nATOM     36  CA  LEU A   5      -4.357   7.534  -4.964  1.00 93.77           C  \\nATOM     37  C   LEU A   5      -3.888   8.473  -6.070  1.00 93.77           C  \\nATOM     38  O   LEU A   5      -2.687   8.576  -6.334  1.00 93.77           O  \\nATOM     39  CB  LEU A   5      -4.149   8.193  -3.597  1.00 93.77           C  \\nATOM     40  CG  LEU A   5      -4.862   9.527  -3.372  1.00 93.77           C  \\nATOM     41  CD1 LEU A   5      -6.358   9.303  -3.182  1.00 93.77           C  \\nATOM     42  CD2 LEU A   5      -4.269  10.255  -2.171  1.00 93.77           C  \\nATOM     43  N   CYS A   6      -4.782   9.213  -6.767  1.00 95.74           N  \\nATOM     44  CA  CYS A   6      -4.482  10.137  -7.855  1.00 95.74           C  \\nATOM     45  C   CYS A   6      -4.813  11.571  -7.461  1.00 95.74           C  \\nATOM     46  O   CYS A   6      -5.933  11.860  -7.036  1.00 95.74           O  \\nATOM     47  CB  CYS A   6      -5.258   9.753  -9.114  1.00 95.74           C  \\nATOM     48  SG  CYS A   6      -4.914   8.079  -9.700  1.00 95.74           S  \\nATOM     49  N   ARG A   7      -3.878  12.356  -7.433  1.00 94.61           N  \\nATOM     50  CA  ARG A   7      -4.058  13.773  -7.132  1.00 94.61           C  \\nATOM     51  C   ARG A   7      -3.410  14.647  -8.200  1.00 94.61           C  \\nATOM     52  O   ARG A   7      -2.251  14.436  -8.563  1.00 94.61           O  \\nATOM     53  CB  ARG A   7      -3.477  14.108  -5.757  1.00 94.61           C  \\nATOM     54  CG  ARG A   7      -4.213  13.451  -4.600  1.00 94.61           C  \\nATOM     55  CD  ARG A   7      -4.930  14.476  -3.732  1.00 94.61           C  \\nATOM     56  NE  ARG A   7      -3.998  15.198  -2.870  1.00 94.61           N  \\nATOM     57  CZ  ARG A   7      -4.034  15.189  -1.540  1.00 94.61           C  \\nATOM     58  NH1 ARG A   7      -4.960  14.492  -0.891  1.00 94.61           N  \\nATOM     59  NH2 ARG A   7      -3.137  15.882  -0.853  1.00 94.61           N  \\nATOM     60  N   ARG A   8      -4.091  15.658  -8.612  1.00 95.66           N  \\nATOM     61  CA  ARG A   8      -3.634  16.634  -9.597  1.00 95.66           C  \\nATOM     62  C   ARG A   8      -3.016  15.943 -10.807  1.00 95.66           C  \\nATOM     63  O   ARG A   8      -1.981  16.379 -11.316  1.00 95.66           O  \\nATOM     64  CB  ARG A   8      -2.624  17.598  -8.971  1.00 95.66           C  \\nATOM     65  CG  ARG A   8      -3.227  18.537  -7.938  1.00 95.66           C  \\nATOM     66  CD  ARG A   8      -2.174  19.447  -7.321  1.00 95.66           C  \\nATOM     67  NE  ARG A   8      -2.781  20.558  -6.593  1.00 95.66           N  \\nATOM     68  CZ  ARG A   8      -2.110  21.435  -5.852  1.00 95.66           C  \\nATOM     69  NH1 ARG A   8      -0.791  21.348  -5.726  1.00 95.66           N  \\nATOM     70  NH2 ARG A   8      -2.763  22.408  -5.232  1.00 95.66           N  \\nATOM     71  N   GLY A   9      -3.564  14.712 -11.177  1.00 93.15           N  \\nATOM     72  CA  GLY A   9      -3.134  14.029 -12.386  1.00 93.15           C  \\nATOM     73  C   GLY A   9      -1.972  13.081 -12.156  1.00 93.15           C  \\nATOM     74  O   GLY A   9      -1.436  12.506 -13.105  1.00 93.15           O  \\nATOM     75  N   VAL A  10      -1.486  13.108 -10.937  1.00 95.73           N  \\nATOM     76  CA  VAL A  10      -0.404  12.191 -10.593  1.00 95.73           C  \\nATOM     77  C   VAL A  10      -0.940  11.068  -9.708  1.00 95.73           C  \\nATOM     78  O   VAL A  10      -1.599  11.326  -8.697  1.00 95.73           O  \\nATOM     79  CB  VAL A  10       0.755  12.923  -9.881  1.00 95.73           C  \\nATOM     80  CG1 VAL A  10       1.888  11.952  -9.555  1.00 95.73           C  \\nATOM     81  CG2 VAL A  10       1.267  14.076 -10.744  1.00 95.73           C  \\nATOM     82  N   CYS A  11      -0.671   9.768 -10.118  1.00 94.53           N  \\nATOM     83  CA  CYS A  11      -1.126   8.634  -9.321  1.00 94.53           C  \\nATOM     84  C   CYS A  11       0.037   7.990  -8.575  1.00 94.53           C  \\nATOM     85  O   CYS A  11       1.108   7.782  -9.148  1.00 94.53           O  \\nATOM     86  CB  CYS A  11      -1.812   7.596 -10.209  1.00 94.53           C  \\nATOM     87  SG  CYS A  11      -3.289   8.214 -11.044  1.00 94.53           S  \\nATOM     88  N   ARG A  12      -0.075   7.884  -7.318  1.00 95.23           N  \\nATOM     89  CA  ARG A  12       0.933   7.208  -6.506  1.00 95.23           C  \\nATOM     90  C   ARG A  12       0.333   6.015  -5.771  1.00 95.23           C  \\nATOM     91  O   ARG A  12      -0.785   6.094  -5.255  1.00 95.23           O  \\nATOM     92  CB  ARG A  12       1.558   8.181  -5.504  1.00 95.23           C  \\nATOM     93  CG  ARG A  12       2.546   9.156  -6.126  1.00 95.23           C  \\nATOM     94  CD  ARG A  12       3.200  10.042  -5.076  1.00 95.23           C  \\nATOM     95  NE  ARG A  12       4.649  10.100  -5.247  1.00 95.23           N  \\nATOM     96  CZ  ARG A  12       5.361  11.222  -5.310  1.00 95.23           C  \\nATOM     97  NH1 ARG A  12       4.768  12.407  -5.216  1.00 95.23           N  \\nATOM     98  NH2 ARG A  12       6.675  11.160  -5.467  1.00 95.23           N  \\nATOM     99  N   CYS A  13       0.962   4.941  -5.896  1.00 94.80           N  \\nATOM    100  CA  CYS A  13       0.521   3.714  -5.241  1.00 94.80           C  \\nATOM    101  C   CYS A  13       1.440   3.355  -4.080  1.00 94.80           C  \\nATOM    102  O   CYS A  13       2.651   3.568  -4.152  1.00 94.80           O  \\nATOM    103  CB  CYS A  13       0.473   2.560  -6.242  1.00 94.80           C  \\nATOM    104  SG  CYS A  13      -0.602   2.870  -7.660  1.00 94.80           S  \\nATOM    105  N   ASP A  14       0.890   2.993  -2.997  1.00 94.11           N  \\nATOM    106  CA  ASP A  14       1.628   2.564  -1.814  1.00 94.11           C  \\nATOM    107  C   ASP A  14       1.156   1.192  -1.339  1.00 94.11           C  \\nATOM    108  O   ASP A  14      -0.045   0.962  -1.185  1.00 94.11           O  \\nATOM    109  CB  ASP A  14       1.480   3.590  -0.688  1.00 94.11           C  \\nATOM    110  CG  ASP A  14       2.416   3.329   0.479  1.00 94.11           C  \\nATOM    111  OD1 ASP A  14       1.945   2.899   1.554  1.00 94.11           O  \\nATOM    112  OD2 ASP A  14       3.635   3.559   0.323  1.00 94.11           O  \\nATOM    113  N   CYS A  15       2.088   0.233  -1.142  1.00 94.28           N  \\nATOM    114  CA  CYS A  15       1.806  -1.147  -0.763  1.00 94.28           C  \\nATOM    115  C   CYS A  15       2.255  -1.423   0.667  1.00 94.28           C  \\nATOM    116  O   CYS A  15       3.321  -0.967   1.086  1.00 94.28           O  \\nATOM    117  CB  CYS A  15       2.497  -2.118  -1.720  1.00 94.28           C  \\nATOM    118  SG  CYS A  15       2.092  -1.839  -3.458  1.00 94.28           S  \\nATOM    119  N   THR A  16       1.473  -1.768   1.480  1.00 88.14           N  \\nATOM    120  CA  THR A  16       1.892  -2.200   2.809  1.00 88.14           C  \\nATOM    121  C   THR A  16       2.150  -3.703   2.833  1.00 88.14           C  \\nATOM    122  O   THR A  16       1.634  -4.441   1.990  1.00 88.14           O  \\nATOM    123  CB  THR A  16       0.836  -1.841   3.871  1.00 88.14           C  \\nATOM    124  OG1 THR A  16      -0.416  -2.440   3.514  1.00 88.14           O  \\nATOM    125  CG2 THR A  16       0.651  -0.331   3.975  1.00 88.14           C  \\nATOM    126  N   ARG A  17       3.328  -4.002   3.528  1.00 84.25           N  \\nATOM    127  CA  ARG A  17       3.627  -5.427   3.634  1.00 84.25           C  \\nATOM    128  C   ARG A  17       2.431  -6.199   4.180  1.00 84.25           C  \\nATOM    129  O   ARG A  17       1.747  -5.729   5.092  1.00 84.25           O  \\nATOM    130  CB  ARG A  17       4.850  -5.654   4.525  1.00 84.25           C  \\nATOM    131  CG  ARG A  17       6.172  -5.306   3.858  1.00 84.25           C  \\nATOM    132  CD  ARG A  17       7.361  -5.755   4.696  1.00 84.25           C  \\nATOM    133  NE  ARG A  17       8.566  -4.995   4.372  1.00 84.25           N  \\nATOM    134  CZ  ARG A  17       9.536  -4.706   5.235  1.00 84.25           C  \\nATOM    135  NH1 ARG A  17       9.461  -5.110   6.499  1.00 84.25           N  \\nATOM    136  NH2 ARG A  17      10.588  -4.009   4.833  1.00 84.25           N  \\nTER     137      ARG A  17                                                       \\nEND   \\n\",\"pdb\");\n",
       "\tviewer_1678886588104604.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n",
       "\tviewer_1678886588104604.zoomTo();\n",
       "viewer_1678886588104604.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'./output_model_B/~~EEEEEETTEEEEEE~~_820_0.pdb'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cycle= 32 #cycles used in OmegaFold\n",
    "sample_sequence (model_B,\n",
    "   x_data=['~~EEEEEETTEEEEEE~~'],\n",
    "     flag=820,cond_scales=1.,foldproteins=True,num_cycle=num_cycle,\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e4717e-379a-4cdd-beaf-49acf6a071e4",
   "metadata": {},
   "source": [
    "### Error analysis using DSSP, and iterative process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed9b25ab-147e-4456-acfa-14eee23f6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DSSP_result (fname):\n",
    "    pdb_list = [fname]\n",
    "\n",
    "    # parse structure\n",
    "    p = PDBParser()\n",
    "    for i in pdb_list:\n",
    "        structure = p.get_structure(i, fname)\n",
    "        # use only the first model\n",
    "        model = structure[0]\n",
    "        # calculate DSSP\n",
    "        dssp = DSSP(model, fname, file_type='PDB' )\n",
    "        # extract sequence and secondary structure from the DSSP tuple\n",
    "        sequence = ''\n",
    "        sec_structure = ''\n",
    "        for z in range(len(dssp)):\n",
    "            a_key = list(dssp.keys())[z]\n",
    "            sequence += dssp[a_key][1]\n",
    "            sec_structure += dssp[a_key][2]\n",
    "\n",
    "        #print(i)\n",
    "        #print(sequence)\n",
    "        #print(sec_structure)\n",
    "        #\n",
    "        # The DSSP codes for secondary structure used here are:\n",
    "        # =====     ====\n",
    "        # Code      Structure\n",
    "        # =====     ====\n",
    "        # H         Alpha helix (4-12)\n",
    "        # B         Isolated beta-bridge residue\n",
    "        # E         Strand\n",
    "        # G         3-10 helix\n",
    "        # I         Pi helix\n",
    "        # T         Turn\n",
    "        # S         Bend\n",
    "        # -         None\n",
    "        # =====     ====\n",
    "        #\n",
    "        \n",
    "        sec_structure = sec_structure.replace('-', '~')\n",
    "        sec_structure_3state=sec_structure\n",
    "\n",
    "        # if desired, convert DSSP's 8-state assignments into 3-state [C - coil, E - extended (beta-strand), H - helix]\n",
    "        sec_structure_3state = sec_structure_3state.replace('~', 'C')\n",
    "        sec_structure_3state = sec_structure_3state.replace('I', 'C')\n",
    "        sec_structure_3state = sec_structure_3state.replace('T', 'C')\n",
    "        sec_structure_3state = sec_structure_3state.replace('S', 'C')\n",
    "        sec_structure_3state = sec_structure_3state.replace('G', 'H')\n",
    "        sec_structure_3state = sec_structure_3state.replace('B', 'E')\n",
    "        return sec_structure,sec_structure_3state, sequence\n",
    "    \n",
    "    \n",
    "def string_diff (seq1, seq2):    \n",
    "    return   sum(1 for a, b in zip(seq1, seq2) if a != b) + abs(len(seq1) - len(seq2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "550aa226-002f-4b82-8bdf-9f5c86fd9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_adaptive (model, seq='~~EEEEEETTEEEEEE~~',flag=999999, errorthreshold=0.8, maxiter=10,\n",
    "                     inpaint_images=None,\n",
    "                     inpaint_masks =None,cond_scales=1.,\n",
    "                     inpaint_resample_times=5,):\n",
    "    \n",
    "    \n",
    "    fnamelist=[]\n",
    "    sequencelist=[]\n",
    "    errorlist=[]\n",
    "    DSSPresultlist=[]\n",
    "    \n",
    "    error=1.\n",
    "    i=0\n",
    "    if inpaint_images != None:\n",
    "        inpaint_images = [inpaint_images]\n",
    "        print (\"Use inpainting during iterative process...\")\n",
    "        \n",
    "    while i<maxiter and error>errorthreshold:\n",
    "        \n",
    "        num_cycle=16\n",
    "        fname=sample_sequence (model,\n",
    "           x_data=[seq],\n",
    "             flag=f'{flag}_{i}',cond_scales=cond_scales,foldproteins=True,num_cycle=num_cycle,\n",
    "                               inpaint_images=inpaint_images,\n",
    "                               inpaint_masks=inpaint_masks,\n",
    "                               inpaint_resample_times=inpaint_resample_times,\n",
    "           )\n",
    "        \n",
    "        DSSPresult,_,sequence=get_DSSP_result(fname) \n",
    "        error=string_diff (DSSPresult, seq)/len (seq)\n",
    "        \n",
    "        print (f\"Iteration {i}: PDB file predicted: \", fname, \"Error: \", error)\n",
    "\n",
    "        print (f\"Cond: {seq}\\nPred: {DSSPresult}\")\n",
    "        \n",
    "        fnamelist.append(fname)\n",
    "        sequencelist.append(sequence)\n",
    "        errorlist.append(error)\n",
    "        DSSPresultlist.append(DSSPresult)       \n",
    "        \n",
    "        i=i+1\n",
    "        \n",
    "\n",
    "    imin=np.argmin (errorlist) #get smallest error \n",
    "    \n",
    "    plt.plot (errorlist, 'o-r', label ='Error vs. iterations')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    sns.histplot(errorlist, bins = max (int (len(errorlist)/3 ),1) )\n",
    "    plt.title ('Error distribution')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    ################\n",
    "    print (\"####################################################\")\n",
    "    print (\"####################################################\")\n",
    "    print (\"####################################################\")\n",
    "    print (f\"FINAL RESULT at {imin}: \", fnamelist[imin], \"Error: \", errorlist[imin])\n",
    "    print (f\"Seq:  {sequencelist[imin]}\")\n",
    "    print (f\"Cond: {seq}\\nPred: {DSSPresultlist[imin]}\")\n",
    "    \n",
    "    tfname=fnamelist[imin][:-4]+'_FINAL.pdb'\n",
    "    shutil.copy (fnamelist[imin], tfname)\n",
    "    print (f\"FINAL FILE NAME at {imin}: \", tfname)\n",
    "    print (\"####################################################\")\n",
    "    print (\"####################################################\")\n",
    "    print (\"####################################################\")\n",
    "\n",
    "    return fnamelist[imin], errorlist[imin], seq, DSSPresultlist[imin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a02b9a7-316d-4387-b526-93a3fc37565d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing 1 samples...from image conditingig x_data  ...\n",
      "['~~EEEEEETTEEEEEE~~']\n",
      "Device:  cuda:0\n",
      "X_cond= None\n",
      "Conditioning target sequence provided via x_data ... ['~~EEEEEETTEEEEEE~~']\n",
      "x_data from target sequence= tensor([[[0.2222, 0.2222, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "          0.4444, 0.4444, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "          0.2222, 0.2222, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0') torch.Size([1, 1, 128])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e5f86fba2b4d11bc5c68066995eb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187967d482704565bceb41cc77ec23ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "For None or ~~EEEEEETTEEEEEE~~, predicted sequence GCCRCLCRRGVCRCICTR\n",
      "Writing FASTA file:  ./output_model_B/fasta_in_900.fasta\n",
      "Now run OmegaFold.... on device=cuda:0\n",
      "INFO:root:Loading weights from /home/mbuehler/.cache/omegafold_ckpt/model.pt\n",
      "INFO:root:Constructing OmegaFold\n",
      "INFO:root:Reading ./output_model_B/fasta_in_900.fasta\n",
      "INFO:root:Predicting 1th chain in ./output_model_B/fasta_in_900.fasta\n",
      "INFO:root:18 residues in this chain.\n",
      "INFO:root:Finished prediction in 16.99 seconds.\n",
      "INFO:root:Saving prediction to ./output_model_B/temp_900.pdb\n",
      "INFO:root:Saved\n",
      "INFO:root:Done!\n",
      "Done OmegaFold\n",
      "Resulting PDB file...:  ./output_model_B/temp_900.PDB\n",
      "Properly named PDB file produced: ./output_model_B/~~EEEEEETTEEEEEE~~_900_0.pdb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x10 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16788867613303041\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16788867613303041\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16788867613303041 = null;\nvar warn = document.getElementById(\"3dmolwarning_16788867613303041\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16788867613303041 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788867613303041\"),{backgroundColor:\"white\"});\nviewer_16788867613303041.zoomTo();\n\tviewer_16788867613303041.addModel(\"ATOM      1  N   GLY A   0      -7.300   7.139   4.003  1.00 71.46           N  \\nATOM      2  CA  GLY A   0      -6.910   7.696   2.718  1.00 71.46           C  \\nATOM      3  C   GLY A   0      -7.102   6.730   1.565  1.00 71.46           C  \\nATOM      4  O   GLY A   0      -6.406   5.716   1.475  1.00 71.46           O  \\nATOM      5  N   CYS A   1      -8.375   6.493   1.405  1.00 86.24           N  \\nATOM      6  CA  CYS A   1      -8.767   5.577   0.340  1.00 86.24           C  \\nATOM      7  C   CYS A   1      -8.369   6.125  -1.025  1.00 86.24           C  \\nATOM      8  O   CYS A   1      -8.443   7.333  -1.259  1.00 86.24           O  \\nATOM      9  CB  CYS A   1     -10.274   5.324   0.378  1.00 86.24           C  \\nATOM     10  SG  CYS A   1     -10.739   3.629  -0.036  1.00 86.24           S  \\nATOM     11  N   CYS A   2      -7.688   5.431  -1.790  1.00 91.19           N  \\nATOM     12  CA  CYS A   2      -7.290   5.789  -3.147  1.00 91.19           C  \\nATOM     13  C   CYS A   2      -8.124   5.036  -4.177  1.00 91.19           C  \\nATOM     14  O   CYS A   2      -8.444   3.862  -3.985  1.00 91.19           O  \\nATOM     15  CB  CYS A   2      -5.806   5.495  -3.366  1.00 91.19           C  \\nATOM     16  SG  CYS A   2      -4.716   6.348  -2.206  1.00 91.19           S  \\nATOM     17  N   ARG A   3      -8.640   5.689  -5.118  1.00 91.75           N  \\nATOM     18  CA  ARG A   3      -9.379   5.068  -6.213  1.00 91.75           C  \\nATOM     19  C   ARG A   3      -8.753   5.411  -7.560  1.00 91.75           C  \\nATOM     20  O   ARG A   3      -8.241   6.517  -7.749  1.00 91.75           O  \\nATOM     21  CB  ARG A   3     -10.845   5.506  -6.190  1.00 91.75           C  \\nATOM     22  CG  ARG A   3     -11.639   4.937  -5.025  1.00 91.75           C  \\nATOM     23  CD  ARG A   3     -13.116   5.294  -5.122  1.00 91.75           C  \\nATOM     24  NE  ARG A   3     -13.859   4.837  -3.951  1.00 91.75           N  \\nATOM     25  CZ  ARG A   3     -15.145   5.092  -3.721  1.00 91.75           C  \\nATOM     26  NH1 ARG A   3     -15.858   5.809  -4.583  1.00 91.75           N  \\nATOM     27  NH2 ARG A   3     -15.722   4.627  -2.623  1.00 91.75           N  \\nATOM     28  N   CYS A   4      -8.553   4.489  -8.420  1.00 90.71           N  \\nATOM     29  CA  CYS A   4      -8.031   4.696  -9.766  1.00 90.71           C  \\nATOM     30  C   CYS A   4      -9.161   4.957 -10.755  1.00 90.71           C  \\nATOM     31  O   CYS A   4     -10.187   4.276 -10.725  1.00 90.71           O  \\nATOM     32  CB  CYS A   4      -7.216   3.485 -10.217  1.00 90.71           C  \\nATOM     33  SG  CYS A   4      -5.706   3.226  -9.260  1.00 90.71           S  \\nATOM     34  N   LEU A   5      -9.069   5.998 -11.374  1.00 89.71           N  \\nATOM     35  CA  LEU A   5     -10.062   6.354 -12.382  1.00 89.71           C  \\nATOM     36  C   LEU A   5      -9.444   6.366 -13.775  1.00 89.71           C  \\nATOM     37  O   LEU A   5      -8.376   6.947 -13.980  1.00 89.71           O  \\nATOM     38  CB  LEU A   5     -10.674   7.723 -12.071  1.00 89.71           C  \\nATOM     39  CG  LEU A   5     -11.896   8.124 -12.898  1.00 89.71           C  \\nATOM     40  CD1 LEU A   5     -13.167   7.558 -12.274  1.00 89.71           C  \\nATOM     41  CD2 LEU A   5     -11.984   9.641 -13.022  1.00 89.71           C  \\nATOM     42  N   CYS A   6      -9.995   5.616 -14.766  1.00 92.13           N  \\nATOM     43  CA  CYS A   6      -9.503   5.540 -16.137  1.00 92.13           C  \\nATOM     44  C   CYS A   6     -10.422   6.297 -17.088  1.00 92.13           C  \\nATOM     45  O   CYS A   6     -11.624   6.029 -17.142  1.00 92.13           O  \\nATOM     46  CB  CYS A   6      -9.381   4.084 -16.583  1.00 92.13           C  \\nATOM     47  SG  CYS A   6      -8.252   3.104 -15.568  1.00 92.13           S  \\nATOM     48  N   ARG A   7      -9.952   7.302 -17.616  1.00 90.41           N  \\nATOM     49  CA  ARG A   7     -10.675   8.064 -18.630  1.00 90.41           C  \\nATOM     50  C   ARG A   7      -9.861   8.176 -19.914  1.00 90.41           C  \\nATOM     51  O   ARG A   7      -8.661   8.456 -19.872  1.00 90.41           O  \\nATOM     52  CB  ARG A   7     -11.025   9.459 -18.107  1.00 90.41           C  \\nATOM     53  CG  ARG A   7     -12.167   9.472 -17.104  1.00 90.41           C  \\nATOM     54  CD  ARG A   7     -13.304  10.379 -17.556  1.00 90.41           C  \\nATOM     55  NE  ARG A   7     -13.373  11.597 -16.753  1.00 90.41           N  \\nATOM     56  CZ  ARG A   7     -14.490  12.271 -16.492  1.00 90.41           C  \\nATOM     57  NH1 ARG A   7     -15.659  11.856 -16.969  1.00 90.41           N  \\nATOM     58  NH2 ARG A   7     -14.439  13.367 -15.750  1.00 90.41           N  \\nATOM     59  N   ARG A   8     -10.460   7.930 -21.022  1.00 91.63           N  \\nATOM     60  CA  ARG A   8      -9.896   8.033 -22.363  1.00 91.63           C  \\nATOM     61  C   ARG A   8      -8.537   7.344 -22.440  1.00 91.63           C  \\nATOM     62  O   ARG A   8      -7.618   7.844 -23.091  1.00 91.63           O  \\nATOM     63  CB  ARG A   8      -9.764   9.499 -22.780  1.00 91.63           C  \\nATOM     64  CG  ARG A   8     -11.078  10.143 -23.191  1.00 91.63           C  \\nATOM     65  CD  ARG A   8     -10.926  11.641 -23.419  1.00 91.63           C  \\nATOM     66  NE  ARG A   8     -11.930  12.149 -24.349  1.00 91.63           N  \\nATOM     67  CZ  ARG A   8     -11.996  13.405 -24.781  1.00 91.63           C  \\nATOM     68  NH1 ARG A   8     -11.113  14.309 -24.373  1.00 91.63           N  \\nATOM     69  NH2 ARG A   8     -12.951  13.761 -25.627  1.00 91.63           N  \\nATOM     70  N   GLY A   9      -8.344   6.234 -21.648  1.00 89.28           N  \\nATOM     71  CA  GLY A   9      -7.118   5.458 -21.741  1.00 89.28           C  \\nATOM     72  C   GLY A   9      -6.047   5.915 -20.769  1.00 89.28           C  \\nATOM     73  O   GLY A   9      -4.916   5.424 -20.807  1.00 89.28           O  \\nATOM     74  N   VAL A  10      -6.355   7.024 -20.108  1.00 92.87           N  \\nATOM     75  CA  VAL A  10      -5.420   7.481 -19.084  1.00 92.87           C  \\nATOM     76  C   VAL A  10      -5.957   7.126 -17.699  1.00 92.87           C  \\nATOM     77  O   VAL A  10      -7.118   7.401 -17.387  1.00 92.87           O  \\nATOM     78  CB  VAL A  10      -5.168   9.002 -19.185  1.00 92.87           C  \\nATOM     79  CG1 VAL A  10      -4.143   9.449 -18.144  1.00 92.87           C  \\nATOM     80  CG2 VAL A  10      -4.702   9.373 -20.591  1.00 92.87           C  \\nATOM     81  N   CYS A  11      -5.123   6.464 -16.902  1.00 90.92           N  \\nATOM     82  CA  CYS A  11      -5.552   6.099 -15.556  1.00 90.92           C  \\nATOM     83  C   CYS A  11      -4.860   6.965 -14.510  1.00 90.92           C  \\nATOM     84  O   CYS A  11      -3.651   7.191 -14.585  1.00 90.92           O  \\nATOM     85  CB  CYS A  11      -5.261   4.624 -15.283  1.00 90.92           C  \\nATOM     86  SG  CYS A  11      -6.171   3.492 -16.356  1.00 90.92           S  \\nATOM     87  N   ARG A  12      -5.654   7.629 -13.747  1.00 91.75           N  \\nATOM     88  CA  ARG A  12      -5.100   8.430 -12.661  1.00 91.75           C  \\nATOM     89  C   ARG A  12      -5.650   7.978 -11.312  1.00 91.75           C  \\nATOM     90  O   ARG A  12      -6.826   7.626 -11.201  1.00 91.75           O  \\nATOM     91  CB  ARG A  12      -5.402   9.915 -12.879  1.00 91.75           C  \\nATOM     92  CG  ARG A  12      -4.668  10.840 -11.921  1.00 91.75           C  \\nATOM     93  CD  ARG A  12      -5.023  12.300 -12.164  1.00 91.75           C  \\nATOM     94  NE  ARG A  12      -4.228  12.875 -13.246  1.00 91.75           N  \\nATOM     95  CZ  ARG A  12      -4.502  14.023 -13.861  1.00 91.75           C  \\nATOM     96  NH1 ARG A  12      -5.562  14.744 -13.510  1.00 91.75           N  \\nATOM     97  NH2 ARG A  12      -3.712  14.454 -14.833  1.00 91.75           N  \\nATOM     98  N   CYS A  13      -4.763   7.754 -10.388  1.00 91.55           N  \\nATOM     99  CA  CYS A  13      -5.160   7.397  -9.031  1.00 91.55           C  \\nATOM    100  C   CYS A  13      -5.410   8.643  -8.189  1.00 91.55           C  \\nATOM    101  O   CYS A  13      -4.632   9.597  -8.239  1.00 91.55           O  \\nATOM    102  CB  CYS A  13      -4.089   6.530  -8.369  1.00 91.55           C  \\nATOM    103  SG  CYS A  13      -3.790   4.966  -9.221  1.00 91.55           S  \\nATOM    104  N   ILE A  14      -6.489   8.719  -7.580  1.00 89.76           N  \\nATOM    105  CA  ILE A  14      -6.869   9.841  -6.730  1.00 89.76           C  \\nATOM    106  C   ILE A  14      -6.933   9.387  -5.273  1.00 89.76           C  \\nATOM    107  O   ILE A  14      -7.552   8.366  -4.962  1.00 89.76           O  \\nATOM    108  CB  ILE A  14      -8.223  10.446  -7.163  1.00 89.76           C  \\nATOM    109  CG1 ILE A  14      -8.163  10.898  -8.626  1.00 89.76           C  \\nATOM    110  CG2 ILE A  14      -8.613  11.609  -6.246  1.00 89.76           C  \\nATOM    111  CD1 ILE A  14      -9.525  11.179  -9.244  1.00 89.76           C  \\nATOM    112  N   CYS A  15      -6.176   9.997  -4.346  1.00 89.67           N  \\nATOM    113  CA  CYS A  15      -6.145   9.664  -2.927  1.00 89.67           C  \\nATOM    114  C   CYS A  15      -6.848  10.734  -2.100  1.00 89.67           C  \\nATOM    115  O   CYS A  15      -6.693  11.928  -2.361  1.00 89.67           O  \\nATOM    116  CB  CYS A  15      -4.704   9.501  -2.446  1.00 89.67           C  \\nATOM    117  SG  CYS A  15      -3.773   8.245  -3.350  1.00 89.67           S  \\nATOM    118  N   THR A  16      -7.871  10.459  -1.494  1.00 83.45           N  \\nATOM    119  CA  THR A  16      -8.499  11.407  -0.581  1.00 83.45           C  \\nATOM    120  C   THR A  16      -7.968  11.223   0.838  1.00 83.45           C  \\nATOM    121  O   THR A  16      -7.647  10.105   1.247  1.00 83.45           O  \\nATOM    122  CB  THR A  16     -10.031  11.253  -0.582  1.00 83.45           C  \\nATOM    123  OG1 THR A  16     -10.367   9.872  -0.399  1.00 83.45           O  \\nATOM    124  CG2 THR A  16     -10.632  11.740  -1.896  1.00 83.45           C  \\nATOM    125  N   ARG A  17      -7.305  12.282   1.291  1.00 81.34           N  \\nATOM    126  CA  ARG A  17      -6.930  12.243   2.701  1.00 81.34           C  \\nATOM    127  C   ARG A  17      -8.158  12.087   3.590  1.00 81.34           C  \\nATOM    128  O   ARG A  17      -9.171  12.759   3.383  1.00 81.34           O  \\nATOM    129  CB  ARG A  17      -6.160  13.508   3.088  1.00 81.34           C  \\nATOM    130  CG  ARG A  17      -4.698  13.492   2.669  1.00 81.34           C  \\nATOM    131  CD  ARG A  17      -3.921  14.645   3.290  1.00 81.34           C  \\nATOM    132  NE  ARG A  17      -2.535  14.669   2.832  1.00 81.34           N  \\nATOM    133  CZ  ARG A  17      -1.984  15.660   2.136  1.00 81.34           C  \\nATOM    134  NH1 ARG A  17      -2.695  16.731   1.803  1.00 81.34           N  \\nATOM    135  NH2 ARG A  17      -0.713  15.579   1.769  1.00 81.34           N  \\nTER     136      ARG A  17                                                       \\nEND   \\n\",\"pdb\");\n\tviewer_16788867613303041.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n\tviewer_16788867613303041.zoomTo();\nviewer_16788867613303041.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_16788867613303041\"  style=\"position: relative; width: 640px; height: 480px\">\n",
       "        <p id=\"3dmolwarning_16788867613303041\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
       "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
       "}\n",
       "\n",
       "var viewer_16788867613303041 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_16788867613303041\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_16788867613303041 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788867613303041\"),{backgroundColor:\"white\"});\n",
       "viewer_16788867613303041.zoomTo();\n",
       "\tviewer_16788867613303041.addModel(\"ATOM      1  N   GLY A   0      -7.300   7.139   4.003  1.00 71.46           N  \\nATOM      2  CA  GLY A   0      -6.910   7.696   2.718  1.00 71.46           C  \\nATOM      3  C   GLY A   0      -7.102   6.730   1.565  1.00 71.46           C  \\nATOM      4  O   GLY A   0      -6.406   5.716   1.475  1.00 71.46           O  \\nATOM      5  N   CYS A   1      -8.375   6.493   1.405  1.00 86.24           N  \\nATOM      6  CA  CYS A   1      -8.767   5.577   0.340  1.00 86.24           C  \\nATOM      7  C   CYS A   1      -8.369   6.125  -1.025  1.00 86.24           C  \\nATOM      8  O   CYS A   1      -8.443   7.333  -1.259  1.00 86.24           O  \\nATOM      9  CB  CYS A   1     -10.274   5.324   0.378  1.00 86.24           C  \\nATOM     10  SG  CYS A   1     -10.739   3.629  -0.036  1.00 86.24           S  \\nATOM     11  N   CYS A   2      -7.688   5.431  -1.790  1.00 91.19           N  \\nATOM     12  CA  CYS A   2      -7.290   5.789  -3.147  1.00 91.19           C  \\nATOM     13  C   CYS A   2      -8.124   5.036  -4.177  1.00 91.19           C  \\nATOM     14  O   CYS A   2      -8.444   3.862  -3.985  1.00 91.19           O  \\nATOM     15  CB  CYS A   2      -5.806   5.495  -3.366  1.00 91.19           C  \\nATOM     16  SG  CYS A   2      -4.716   6.348  -2.206  1.00 91.19           S  \\nATOM     17  N   ARG A   3      -8.640   5.689  -5.118  1.00 91.75           N  \\nATOM     18  CA  ARG A   3      -9.379   5.068  -6.213  1.00 91.75           C  \\nATOM     19  C   ARG A   3      -8.753   5.411  -7.560  1.00 91.75           C  \\nATOM     20  O   ARG A   3      -8.241   6.517  -7.749  1.00 91.75           O  \\nATOM     21  CB  ARG A   3     -10.845   5.506  -6.190  1.00 91.75           C  \\nATOM     22  CG  ARG A   3     -11.639   4.937  -5.025  1.00 91.75           C  \\nATOM     23  CD  ARG A   3     -13.116   5.294  -5.122  1.00 91.75           C  \\nATOM     24  NE  ARG A   3     -13.859   4.837  -3.951  1.00 91.75           N  \\nATOM     25  CZ  ARG A   3     -15.145   5.092  -3.721  1.00 91.75           C  \\nATOM     26  NH1 ARG A   3     -15.858   5.809  -4.583  1.00 91.75           N  \\nATOM     27  NH2 ARG A   3     -15.722   4.627  -2.623  1.00 91.75           N  \\nATOM     28  N   CYS A   4      -8.553   4.489  -8.420  1.00 90.71           N  \\nATOM     29  CA  CYS A   4      -8.031   4.696  -9.766  1.00 90.71           C  \\nATOM     30  C   CYS A   4      -9.161   4.957 -10.755  1.00 90.71           C  \\nATOM     31  O   CYS A   4     -10.187   4.276 -10.725  1.00 90.71           O  \\nATOM     32  CB  CYS A   4      -7.216   3.485 -10.217  1.00 90.71           C  \\nATOM     33  SG  CYS A   4      -5.706   3.226  -9.260  1.00 90.71           S  \\nATOM     34  N   LEU A   5      -9.069   5.998 -11.374  1.00 89.71           N  \\nATOM     35  CA  LEU A   5     -10.062   6.354 -12.382  1.00 89.71           C  \\nATOM     36  C   LEU A   5      -9.444   6.366 -13.775  1.00 89.71           C  \\nATOM     37  O   LEU A   5      -8.376   6.947 -13.980  1.00 89.71           O  \\nATOM     38  CB  LEU A   5     -10.674   7.723 -12.071  1.00 89.71           C  \\nATOM     39  CG  LEU A   5     -11.896   8.124 -12.898  1.00 89.71           C  \\nATOM     40  CD1 LEU A   5     -13.167   7.558 -12.274  1.00 89.71           C  \\nATOM     41  CD2 LEU A   5     -11.984   9.641 -13.022  1.00 89.71           C  \\nATOM     42  N   CYS A   6      -9.995   5.616 -14.766  1.00 92.13           N  \\nATOM     43  CA  CYS A   6      -9.503   5.540 -16.137  1.00 92.13           C  \\nATOM     44  C   CYS A   6     -10.422   6.297 -17.088  1.00 92.13           C  \\nATOM     45  O   CYS A   6     -11.624   6.029 -17.142  1.00 92.13           O  \\nATOM     46  CB  CYS A   6      -9.381   4.084 -16.583  1.00 92.13           C  \\nATOM     47  SG  CYS A   6      -8.252   3.104 -15.568  1.00 92.13           S  \\nATOM     48  N   ARG A   7      -9.952   7.302 -17.616  1.00 90.41           N  \\nATOM     49  CA  ARG A   7     -10.675   8.064 -18.630  1.00 90.41           C  \\nATOM     50  C   ARG A   7      -9.861   8.176 -19.914  1.00 90.41           C  \\nATOM     51  O   ARG A   7      -8.661   8.456 -19.872  1.00 90.41           O  \\nATOM     52  CB  ARG A   7     -11.025   9.459 -18.107  1.00 90.41           C  \\nATOM     53  CG  ARG A   7     -12.167   9.472 -17.104  1.00 90.41           C  \\nATOM     54  CD  ARG A   7     -13.304  10.379 -17.556  1.00 90.41           C  \\nATOM     55  NE  ARG A   7     -13.373  11.597 -16.753  1.00 90.41           N  \\nATOM     56  CZ  ARG A   7     -14.490  12.271 -16.492  1.00 90.41           C  \\nATOM     57  NH1 ARG A   7     -15.659  11.856 -16.969  1.00 90.41           N  \\nATOM     58  NH2 ARG A   7     -14.439  13.367 -15.750  1.00 90.41           N  \\nATOM     59  N   ARG A   8     -10.460   7.930 -21.022  1.00 91.63           N  \\nATOM     60  CA  ARG A   8      -9.896   8.033 -22.363  1.00 91.63           C  \\nATOM     61  C   ARG A   8      -8.537   7.344 -22.440  1.00 91.63           C  \\nATOM     62  O   ARG A   8      -7.618   7.844 -23.091  1.00 91.63           O  \\nATOM     63  CB  ARG A   8      -9.764   9.499 -22.780  1.00 91.63           C  \\nATOM     64  CG  ARG A   8     -11.078  10.143 -23.191  1.00 91.63           C  \\nATOM     65  CD  ARG A   8     -10.926  11.641 -23.419  1.00 91.63           C  \\nATOM     66  NE  ARG A   8     -11.930  12.149 -24.349  1.00 91.63           N  \\nATOM     67  CZ  ARG A   8     -11.996  13.405 -24.781  1.00 91.63           C  \\nATOM     68  NH1 ARG A   8     -11.113  14.309 -24.373  1.00 91.63           N  \\nATOM     69  NH2 ARG A   8     -12.951  13.761 -25.627  1.00 91.63           N  \\nATOM     70  N   GLY A   9      -8.344   6.234 -21.648  1.00 89.28           N  \\nATOM     71  CA  GLY A   9      -7.118   5.458 -21.741  1.00 89.28           C  \\nATOM     72  C   GLY A   9      -6.047   5.915 -20.769  1.00 89.28           C  \\nATOM     73  O   GLY A   9      -4.916   5.424 -20.807  1.00 89.28           O  \\nATOM     74  N   VAL A  10      -6.355   7.024 -20.108  1.00 92.87           N  \\nATOM     75  CA  VAL A  10      -5.420   7.481 -19.084  1.00 92.87           C  \\nATOM     76  C   VAL A  10      -5.957   7.126 -17.699  1.00 92.87           C  \\nATOM     77  O   VAL A  10      -7.118   7.401 -17.387  1.00 92.87           O  \\nATOM     78  CB  VAL A  10      -5.168   9.002 -19.185  1.00 92.87           C  \\nATOM     79  CG1 VAL A  10      -4.143   9.449 -18.144  1.00 92.87           C  \\nATOM     80  CG2 VAL A  10      -4.702   9.373 -20.591  1.00 92.87           C  \\nATOM     81  N   CYS A  11      -5.123   6.464 -16.902  1.00 90.92           N  \\nATOM     82  CA  CYS A  11      -5.552   6.099 -15.556  1.00 90.92           C  \\nATOM     83  C   CYS A  11      -4.860   6.965 -14.510  1.00 90.92           C  \\nATOM     84  O   CYS A  11      -3.651   7.191 -14.585  1.00 90.92           O  \\nATOM     85  CB  CYS A  11      -5.261   4.624 -15.283  1.00 90.92           C  \\nATOM     86  SG  CYS A  11      -6.171   3.492 -16.356  1.00 90.92           S  \\nATOM     87  N   ARG A  12      -5.654   7.629 -13.747  1.00 91.75           N  \\nATOM     88  CA  ARG A  12      -5.100   8.430 -12.661  1.00 91.75           C  \\nATOM     89  C   ARG A  12      -5.650   7.978 -11.312  1.00 91.75           C  \\nATOM     90  O   ARG A  12      -6.826   7.626 -11.201  1.00 91.75           O  \\nATOM     91  CB  ARG A  12      -5.402   9.915 -12.879  1.00 91.75           C  \\nATOM     92  CG  ARG A  12      -4.668  10.840 -11.921  1.00 91.75           C  \\nATOM     93  CD  ARG A  12      -5.023  12.300 -12.164  1.00 91.75           C  \\nATOM     94  NE  ARG A  12      -4.228  12.875 -13.246  1.00 91.75           N  \\nATOM     95  CZ  ARG A  12      -4.502  14.023 -13.861  1.00 91.75           C  \\nATOM     96  NH1 ARG A  12      -5.562  14.744 -13.510  1.00 91.75           N  \\nATOM     97  NH2 ARG A  12      -3.712  14.454 -14.833  1.00 91.75           N  \\nATOM     98  N   CYS A  13      -4.763   7.754 -10.388  1.00 91.55           N  \\nATOM     99  CA  CYS A  13      -5.160   7.397  -9.031  1.00 91.55           C  \\nATOM    100  C   CYS A  13      -5.410   8.643  -8.189  1.00 91.55           C  \\nATOM    101  O   CYS A  13      -4.632   9.597  -8.239  1.00 91.55           O  \\nATOM    102  CB  CYS A  13      -4.089   6.530  -8.369  1.00 91.55           C  \\nATOM    103  SG  CYS A  13      -3.790   4.966  -9.221  1.00 91.55           S  \\nATOM    104  N   ILE A  14      -6.489   8.719  -7.580  1.00 89.76           N  \\nATOM    105  CA  ILE A  14      -6.869   9.841  -6.730  1.00 89.76           C  \\nATOM    106  C   ILE A  14      -6.933   9.387  -5.273  1.00 89.76           C  \\nATOM    107  O   ILE A  14      -7.552   8.366  -4.962  1.00 89.76           O  \\nATOM    108  CB  ILE A  14      -8.223  10.446  -7.163  1.00 89.76           C  \\nATOM    109  CG1 ILE A  14      -8.163  10.898  -8.626  1.00 89.76           C  \\nATOM    110  CG2 ILE A  14      -8.613  11.609  -6.246  1.00 89.76           C  \\nATOM    111  CD1 ILE A  14      -9.525  11.179  -9.244  1.00 89.76           C  \\nATOM    112  N   CYS A  15      -6.176   9.997  -4.346  1.00 89.67           N  \\nATOM    113  CA  CYS A  15      -6.145   9.664  -2.927  1.00 89.67           C  \\nATOM    114  C   CYS A  15      -6.848  10.734  -2.100  1.00 89.67           C  \\nATOM    115  O   CYS A  15      -6.693  11.928  -2.361  1.00 89.67           O  \\nATOM    116  CB  CYS A  15      -4.704   9.501  -2.446  1.00 89.67           C  \\nATOM    117  SG  CYS A  15      -3.773   8.245  -3.350  1.00 89.67           S  \\nATOM    118  N   THR A  16      -7.871  10.459  -1.494  1.00 83.45           N  \\nATOM    119  CA  THR A  16      -8.499  11.407  -0.581  1.00 83.45           C  \\nATOM    120  C   THR A  16      -7.968  11.223   0.838  1.00 83.45           C  \\nATOM    121  O   THR A  16      -7.647  10.105   1.247  1.00 83.45           O  \\nATOM    122  CB  THR A  16     -10.031  11.253  -0.582  1.00 83.45           C  \\nATOM    123  OG1 THR A  16     -10.367   9.872  -0.399  1.00 83.45           O  \\nATOM    124  CG2 THR A  16     -10.632  11.740  -1.896  1.00 83.45           C  \\nATOM    125  N   ARG A  17      -7.305  12.282   1.291  1.00 81.34           N  \\nATOM    126  CA  ARG A  17      -6.930  12.243   2.701  1.00 81.34           C  \\nATOM    127  C   ARG A  17      -8.158  12.087   3.590  1.00 81.34           C  \\nATOM    128  O   ARG A  17      -9.171  12.759   3.383  1.00 81.34           O  \\nATOM    129  CB  ARG A  17      -6.160  13.508   3.088  1.00 81.34           C  \\nATOM    130  CG  ARG A  17      -4.698  13.492   2.669  1.00 81.34           C  \\nATOM    131  CD  ARG A  17      -3.921  14.645   3.290  1.00 81.34           C  \\nATOM    132  NE  ARG A  17      -2.535  14.669   2.832  1.00 81.34           N  \\nATOM    133  CZ  ARG A  17      -1.984  15.660   2.136  1.00 81.34           C  \\nATOM    134  NH1 ARG A  17      -2.695  16.731   1.803  1.00 81.34           N  \\nATOM    135  NH2 ARG A  17      -0.713  15.579   1.769  1.00 81.34           N  \\nTER     136      ARG A  17                                                       \\nEND   \\n\",\"pdb\");\n",
       "\tviewer_16788867613303041.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n",
       "\tviewer_16788867613303041.zoomTo();\n",
       "viewer_16788867613303041.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB file predicted:  ./output_model_B/~~EEEEEETTEEEEEE~~_900_0.pdb\n"
     ]
    }
   ],
   "source": [
    "num_cycle=16\n",
    "seq= '~~EEEEEETTEEEEEE~~'\n",
    "fname=sample_sequence (model_B,\n",
    "   x_data=[seq],\n",
    "     flag=900,cond_scales=1.,foldproteins=True,num_cycle=num_cycle,\n",
    "   )\n",
    "print (\"PDB file predicted: \", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "263c3914-4a6a-4d00-89c5-fbd4375ec582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:        ~~EEEEEETTEEEEEE~~\n",
      "RESULT:       ~~EEEEEETTEEEEEE~~\n",
      "AA sequence:  GCCRCLCRRGVCRCICTR\n",
      "Error:  0.0\n"
     ]
    }
   ],
   "source": [
    "#test for single case\n",
    "DSSPresult,_,sequence_res=get_DSSP_result(fname) \n",
    "print (f\"INPUT:        {seq}\\nRESULT:       {DSSPresult}\\nAA sequence:  {sequence_res}\")\n",
    "error=string_diff (DSSPresult, seq)/len (seq)\n",
    "print (\"Error: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2d52d798-3b52-4ac1-8244-37c8eb3a7d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing 1 samples...from image conditingig x_data  ...\n",
      "['~~EEEEEETTEEEEEE~~']\n",
      "Device:  cuda:0\n",
      "X_cond= None\n",
      "Conditioning target sequence provided via x_data ... ['~~EEEEEETTEEEEEE~~']\n",
      "x_data from target sequence= tensor([[[0.2222, 0.2222, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "          0.4444, 0.4444, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333, 0.3333,\n",
      "          0.2222, 0.2222, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0') torch.Size([1, 1, 128])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3179d90016a24276b5be8cf1ce7368e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73409a038a6045899a0b92046f9354cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "For None or ~~EEEEEETTEEEEEE~~, predicted sequence GDCRCLCRRGVCRCICTR\n",
      "Writing FASTA file:  ./output_model_B/fasta_in_99800_0.fasta\n",
      "Now run OmegaFold.... on device=cuda:0\n",
      "INFO:root:Loading weights from /home/mbuehler/.cache/omegafold_ckpt/model.pt\n",
      "INFO:root:Constructing OmegaFold\n",
      "INFO:root:Reading ./output_model_B/fasta_in_99800_0.fasta\n",
      "INFO:root:Predicting 1th chain in ./output_model_B/fasta_in_99800_0.fasta\n",
      "INFO:root:18 residues in this chain.\n",
      "INFO:root:Finished prediction in 16.57 seconds.\n",
      "INFO:root:Saving prediction to ./output_model_B/temp_99800_0.pdb\n",
      "INFO:root:Saved\n",
      "INFO:root:Done!\n",
      "Done OmegaFold\n",
      "Resulting PDB file...:  ./output_model_B/temp_99800_0.PDB\n",
      "Properly named PDB file produced: ./output_model_B/~~EEEEEETTEEEEEE~~_99800_0_0.pdb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x10 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16788868218654912\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16788868218654912\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16788868218654912 = null;\nvar warn = document.getElementById(\"3dmolwarning_16788868218654912\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16788868218654912 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788868218654912\"),{backgroundColor:\"white\"});\nviewer_16788868218654912.zoomTo();\n\tviewer_16788868218654912.addModel(\"ATOM      1  N   GLY A   0      -5.961  -8.547   1.644  1.00 69.46           N  \\nATOM      2  CA  GLY A   0      -5.091  -7.570   1.010  1.00 69.46           C  \\nATOM      3  C   GLY A   0      -5.847  -6.544   0.186  1.00 69.46           C  \\nATOM      4  O   GLY A   0      -6.463  -6.886  -0.826  1.00 69.46           O  \\nATOM      5  N   ASP A   1      -6.574  -5.729   0.964  1.00 87.58           N  \\nATOM      6  CA  ASP A   1      -7.395  -4.698   0.337  1.00 87.58           C  \\nATOM      7  C   ASP A   1      -6.552  -3.794  -0.560  1.00 87.58           C  \\nATOM      8  O   ASP A   1      -5.546  -3.236  -0.117  1.00 87.58           O  \\nATOM      9  CB  ASP A   1      -8.112  -3.863   1.400  1.00 87.58           C  \\nATOM     10  CG  ASP A   1      -9.364  -4.535   1.937  1.00 87.58           C  \\nATOM     11  OD1 ASP A   1     -10.354  -4.670   1.185  1.00 87.58           O  \\nATOM     12  OD2 ASP A   1      -9.362  -4.930   3.123  1.00 87.58           O  \\nATOM     13  N   CYS A   2      -6.778  -3.978  -1.816  1.00 94.46           N  \\nATOM     14  CA  CYS A   2      -6.119  -3.070  -2.749  1.00 94.46           C  \\nATOM     15  C   CYS A   2      -7.039  -1.916  -3.128  1.00 94.46           C  \\nATOM     16  O   CYS A   2      -8.243  -2.109  -3.308  1.00 94.46           O  \\nATOM     17  CB  CYS A   2      -5.681  -3.819  -4.007  1.00 94.46           C  \\nATOM     18  SG  CYS A   2      -4.554  -5.192  -3.681  1.00 94.46           S  \\nATOM     19  N   ARG A   3      -6.616  -0.784  -3.032  1.00 94.34           N  \\nATOM     20  CA  ARG A   3      -7.346   0.404  -3.463  1.00 94.34           C  \\nATOM     21  C   ARG A   3      -6.634   1.093  -4.623  1.00 94.34           C  \\nATOM     22  O   ARG A   3      -5.412   1.251  -4.601  1.00 94.34           O  \\nATOM     23  CB  ARG A   3      -7.518   1.381  -2.298  1.00 94.34           C  \\nATOM     24  CG  ARG A   3      -8.419   0.865  -1.188  1.00 94.34           C  \\nATOM     25  CD  ARG A   3      -8.623   1.906  -0.097  1.00 94.34           C  \\nATOM     26  NE  ARG A   3      -9.359   1.360   1.039  1.00 94.34           N  \\nATOM     27  CZ  ARG A   3      -9.286   1.822   2.284  1.00 94.34           C  \\nATOM     28  NH1 ARG A   3      -8.503   2.854   2.578  1.00 94.34           N  \\nATOM     29  NH2 ARG A   3      -9.999   1.249   3.242  1.00 94.34           N  \\nATOM     30  N   CYS A   4      -7.296   1.288  -5.691  1.00 93.93           N  \\nATOM     31  CA  CYS A   4      -6.736   1.983  -6.844  1.00 93.93           C  \\nATOM     32  C   CYS A   4      -7.157   3.447  -6.856  1.00 93.93           C  \\nATOM     33  O   CYS A   4      -8.293   3.774  -6.506  1.00 93.93           O  \\nATOM     34  CB  CYS A   4      -7.173   1.307  -8.143  1.00 93.93           C  \\nATOM     35  SG  CYS A   4      -6.617  -0.405  -8.295  1.00 93.93           S  \\nATOM     36  N   LEU A   5      -6.251   4.262  -7.004  1.00 92.07           N  \\nATOM     37  CA  LEU A   5      -6.516   5.694  -7.081  1.00 92.07           C  \\nATOM     38  C   LEU A   5      -5.970   6.279  -8.379  1.00 92.07           C  \\nATOM     39  O   LEU A   5      -4.866   5.933  -8.805  1.00 92.07           O  \\nATOM     40  CB  LEU A   5      -5.899   6.418  -5.882  1.00 92.07           C  \\nATOM     41  CG  LEU A   5      -6.205   7.912  -5.761  1.00 92.07           C  \\nATOM     42  CD1 LEU A   5      -7.600   8.122  -5.182  1.00 92.07           C  \\nATOM     43  CD2 LEU A   5      -5.154   8.606  -4.901  1.00 92.07           C  \\nATOM     44  N   CYS A   6      -6.710   7.156  -9.084  1.00 95.31           N  \\nATOM     45  CA  CYS A   6      -6.327   7.793 -10.339  1.00 95.31           C  \\nATOM     46  C   CYS A   6      -6.136   9.293 -10.154  1.00 95.31           C  \\nATOM     47  O   CYS A   6      -7.033   9.982  -9.666  1.00 95.31           O  \\nATOM     48  CB  CYS A   6      -7.381   7.533 -11.415  1.00 95.31           C  \\nATOM     49  SG  CYS A   6      -7.645   5.782 -11.768  1.00 95.31           S  \\nATOM     50  N   ARG A   7      -5.008   9.721 -10.367  1.00 93.64           N  \\nATOM     51  CA  ARG A   7      -4.687  11.143 -10.301  1.00 93.64           C  \\nATOM     52  C   ARG A   7      -3.997  11.608 -11.579  1.00 93.64           C  \\nATOM     53  O   ARG A   7      -3.045  10.978 -12.041  1.00 93.64           O  \\nATOM     54  CB  ARG A   7      -3.801  11.439  -9.089  1.00 93.64           C  \\nATOM     55  CG  ARG A   7      -4.039  12.808  -8.472  1.00 93.64           C  \\nATOM     56  CD  ARG A   7      -2.886  13.229  -7.571  1.00 93.64           C  \\nATOM     57  NE  ARG A   7      -3.207  13.038  -6.159  1.00 93.64           N  \\nATOM     58  CZ  ARG A   7      -2.988  13.937  -5.204  1.00 93.64           C  \\nATOM     59  NH1 ARG A   7      -2.440  15.112  -5.491  1.00 93.64           N  \\nATOM     60  NH2 ARG A   7      -3.320  13.659  -3.951  1.00 93.64           N  \\nATOM     61  N   ARG A   8      -4.411  12.708 -12.132  1.00 94.95           N  \\nATOM     62  CA  ARG A   8      -3.879  13.348 -13.330  1.00 94.95           C  \\nATOM     63  C   ARG A   8      -3.709  12.339 -14.461  1.00 94.95           C  \\nATOM     64  O   ARG A   8      -2.711  12.370 -15.183  1.00 94.95           O  \\nATOM     65  CB  ARG A   8      -2.541  14.026 -13.028  1.00 94.95           C  \\nATOM     66  CG  ARG A   8      -2.661  15.266 -12.156  1.00 94.95           C  \\nATOM     67  CD  ARG A   8      -1.303  15.895 -11.880  1.00 94.95           C  \\nATOM     68  NE  ARG A   8      -1.428  17.292 -11.476  1.00 94.95           N  \\nATOM     69  CZ  ARG A   8      -0.442  18.025 -10.966  1.00 94.95           C  \\nATOM     70  NH1 ARG A   8       0.767  17.505 -10.786  1.00 94.95           N  \\nATOM     71  NH2 ARG A   8      -0.666  19.288 -10.634  1.00 94.95           N  \\nATOM     72  N   GLY A   9      -4.618  11.285 -14.489  1.00 92.71           N  \\nATOM     73  CA  GLY A   9      -4.626  10.347 -15.600  1.00 92.71           C  \\nATOM     74  C   GLY A   9      -3.761   9.125 -15.355  1.00 92.71           C  \\nATOM     75  O   GLY A   9      -3.574   8.301 -16.252  1.00 92.71           O  \\nATOM     76  N   VAL A  10      -3.051   9.164 -14.233  1.00 95.49           N  \\nATOM     77  CA  VAL A  10      -2.243   8.010 -13.853  1.00 95.49           C  \\nATOM     78  C   VAL A  10      -2.934   7.243 -12.728  1.00 95.49           C  \\nATOM     79  O   VAL A  10      -3.330   7.832 -11.719  1.00 95.49           O  \\nATOM     80  CB  VAL A  10      -0.822   8.431 -13.417  1.00 95.49           C  \\nATOM     81  CG1 VAL A  10       0.023   7.206 -13.073  1.00 95.49           C  \\nATOM     82  CG2 VAL A  10      -0.150   9.256 -14.514  1.00 95.49           C  \\nATOM     83  N   CYS A  11      -3.111   5.897 -12.924  1.00 94.78           N  \\nATOM     84  CA  CYS A  11      -3.758   5.075 -11.907  1.00 94.78           C  \\nATOM     85  C   CYS A  11      -2.741   4.195 -11.189  1.00 94.78           C  \\nATOM     86  O   CYS A  11      -1.878   3.590 -11.827  1.00 94.78           O  \\nATOM     87  CB  CYS A  11      -4.847   4.205 -12.533  1.00 94.78           C  \\nATOM     88  SG  CYS A  11      -6.197   5.149 -13.273  1.00 94.78           S  \\nATOM     89  N   ARG A  12      -2.717   4.305  -9.902  1.00 94.62           N  \\nATOM     90  CA  ARG A  12      -1.837   3.452  -9.110  1.00 94.62           C  \\nATOM     91  C   ARG A  12      -2.627   2.663  -8.072  1.00 94.62           C  \\nATOM     92  O   ARG A  12      -3.551   3.194  -7.452  1.00 94.62           O  \\nATOM     93  CB  ARG A  12      -0.755   4.288  -8.423  1.00 94.62           C  \\nATOM     94  CG  ARG A  12       0.492   4.496  -9.267  1.00 94.62           C  \\nATOM     95  CD  ARG A  12       1.606   5.165  -8.473  1.00 94.62           C  \\nATOM     96  NE  ARG A  12       2.605   5.770  -9.350  1.00 94.62           N  \\nATOM     97  CZ  ARG A  12       3.375   6.804  -9.022  1.00 94.62           C  \\nATOM     98  NH1 ARG A  12       3.274   7.371  -7.826  1.00 94.62           N  \\nATOM     99  NH2 ARG A  12       4.251   7.275  -9.897  1.00 94.62           N  \\nATOM    100  N   CYS A  13      -2.374   1.437  -8.051  1.00 94.97           N  \\nATOM    101  CA  CYS A  13      -3.036   0.572  -7.082  1.00 94.97           C  \\nATOM    102  C   CYS A  13      -2.109   0.249  -5.916  1.00 94.97           C  \\nATOM    103  O   CYS A  13      -0.904   0.074  -6.106  1.00 94.97           O  \\nATOM    104  CB  CYS A  13      -3.502  -0.722  -7.748  1.00 94.97           C  \\nATOM    105  SG  CYS A  13      -4.652  -0.463  -9.117  1.00 94.97           S  \\nATOM    106  N   ILE A  14      -2.562   0.316  -4.766  1.00 90.99           N  \\nATOM    107  CA  ILE A  14      -1.790   0.026  -3.563  1.00 90.99           C  \\nATOM    108  C   ILE A  14      -2.461  -1.099  -2.777  1.00 90.99           C  \\nATOM    109  O   ILE A  14      -3.683  -1.104  -2.610  1.00 90.99           O  \\nATOM    110  CB  ILE A  14      -1.634   1.281  -2.675  1.00 90.99           C  \\nATOM    111  CG1 ILE A  14      -0.890   2.384  -3.436  1.00 90.99           C  \\nATOM    112  CG2 ILE A  14      -0.913   0.933  -1.369  1.00 90.99           C  \\nATOM    113  CD1 ILE A  14      -0.977   3.756  -2.780  1.00 90.99           C  \\nATOM    114  N   CYS A  15      -1.723  -2.123  -2.329  1.00 93.25           N  \\nATOM    115  CA  CYS A  15      -2.222  -3.263  -1.569  1.00 93.25           C  \\nATOM    116  C   CYS A  15      -1.701  -3.236  -0.138  1.00 93.25           C  \\nATOM    117  O   CYS A  15      -0.538  -2.904   0.098  1.00 93.25           O  \\nATOM    118  CB  CYS A  15      -1.819  -4.574  -2.244  1.00 93.25           C  \\nATOM    119  SG  CYS A  15      -2.331  -4.692  -3.972  1.00 93.25           S  \\nATOM    120  N   THR A  16      -2.491  -3.157   0.726  1.00 85.70           N  \\nATOM    121  CA  THR A  16      -2.070  -3.257   2.119  1.00 85.70           C  \\nATOM    122  C   THR A  16      -2.141  -4.702   2.604  1.00 85.70           C  \\nATOM    123  O   THR A  16      -2.982  -5.477   2.141  1.00 85.70           O  \\nATOM    124  CB  THR A  16      -2.934  -2.364   3.028  1.00 85.70           C  \\nATOM    125  OG1 THR A  16      -4.312  -2.726   2.874  1.00 85.70           O  \\nATOM    126  CG2 THR A  16      -2.765  -0.891   2.674  1.00 85.70           C  \\nATOM    127  N   ARG A  17      -0.970  -5.190   2.998  1.00 80.74           N  \\nATOM    128  CA  ARG A  17      -0.916  -6.558   3.504  1.00 80.74           C  \\nATOM    129  C   ARG A  17      -1.970  -6.785   4.582  1.00 80.74           C  \\nATOM    130  O   ARG A  17      -2.168  -5.935   5.453  1.00 80.74           O  \\nATOM    131  CB  ARG A  17       0.476  -6.873   4.057  1.00 80.74           C  \\nATOM    132  CG  ARG A  17       1.533  -7.078   2.984  1.00 80.74           C  \\nATOM    133  CD  ARG A  17       2.843  -7.585   3.573  1.00 80.74           C  \\nATOM    134  NE  ARG A  17       3.915  -7.586   2.581  1.00 80.74           N  \\nATOM    135  CZ  ARG A  17       5.026  -6.859   2.665  1.00 80.74           C  \\nATOM    136  NH1 ARG A  17       5.234  -6.055   3.702  1.00 80.74           N  \\nATOM    137  NH2 ARG A  17       5.937  -6.936   1.706  1.00 80.74           N  \\nTER     138      ARG A  17                                                       \\nEND   \\n\",\"pdb\");\n\tviewer_16788868218654912.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n\tviewer_16788868218654912.zoomTo();\nviewer_16788868218654912.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_16788868218654912\"  style=\"position: relative; width: 640px; height: 480px\">\n",
       "        <p id=\"3dmolwarning_16788868218654912\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
       "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
       "}\n",
       "\n",
       "var viewer_16788868218654912 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_16788868218654912\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_16788868218654912 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788868218654912\"),{backgroundColor:\"white\"});\n",
       "viewer_16788868218654912.zoomTo();\n",
       "\tviewer_16788868218654912.addModel(\"ATOM      1  N   GLY A   0      -5.961  -8.547   1.644  1.00 69.46           N  \\nATOM      2  CA  GLY A   0      -5.091  -7.570   1.010  1.00 69.46           C  \\nATOM      3  C   GLY A   0      -5.847  -6.544   0.186  1.00 69.46           C  \\nATOM      4  O   GLY A   0      -6.463  -6.886  -0.826  1.00 69.46           O  \\nATOM      5  N   ASP A   1      -6.574  -5.729   0.964  1.00 87.58           N  \\nATOM      6  CA  ASP A   1      -7.395  -4.698   0.337  1.00 87.58           C  \\nATOM      7  C   ASP A   1      -6.552  -3.794  -0.560  1.00 87.58           C  \\nATOM      8  O   ASP A   1      -5.546  -3.236  -0.117  1.00 87.58           O  \\nATOM      9  CB  ASP A   1      -8.112  -3.863   1.400  1.00 87.58           C  \\nATOM     10  CG  ASP A   1      -9.364  -4.535   1.937  1.00 87.58           C  \\nATOM     11  OD1 ASP A   1     -10.354  -4.670   1.185  1.00 87.58           O  \\nATOM     12  OD2 ASP A   1      -9.362  -4.930   3.123  1.00 87.58           O  \\nATOM     13  N   CYS A   2      -6.778  -3.978  -1.816  1.00 94.46           N  \\nATOM     14  CA  CYS A   2      -6.119  -3.070  -2.749  1.00 94.46           C  \\nATOM     15  C   CYS A   2      -7.039  -1.916  -3.128  1.00 94.46           C  \\nATOM     16  O   CYS A   2      -8.243  -2.109  -3.308  1.00 94.46           O  \\nATOM     17  CB  CYS A   2      -5.681  -3.819  -4.007  1.00 94.46           C  \\nATOM     18  SG  CYS A   2      -4.554  -5.192  -3.681  1.00 94.46           S  \\nATOM     19  N   ARG A   3      -6.616  -0.784  -3.032  1.00 94.34           N  \\nATOM     20  CA  ARG A   3      -7.346   0.404  -3.463  1.00 94.34           C  \\nATOM     21  C   ARG A   3      -6.634   1.093  -4.623  1.00 94.34           C  \\nATOM     22  O   ARG A   3      -5.412   1.251  -4.601  1.00 94.34           O  \\nATOM     23  CB  ARG A   3      -7.518   1.381  -2.298  1.00 94.34           C  \\nATOM     24  CG  ARG A   3      -8.419   0.865  -1.188  1.00 94.34           C  \\nATOM     25  CD  ARG A   3      -8.623   1.906  -0.097  1.00 94.34           C  \\nATOM     26  NE  ARG A   3      -9.359   1.360   1.039  1.00 94.34           N  \\nATOM     27  CZ  ARG A   3      -9.286   1.822   2.284  1.00 94.34           C  \\nATOM     28  NH1 ARG A   3      -8.503   2.854   2.578  1.00 94.34           N  \\nATOM     29  NH2 ARG A   3      -9.999   1.249   3.242  1.00 94.34           N  \\nATOM     30  N   CYS A   4      -7.296   1.288  -5.691  1.00 93.93           N  \\nATOM     31  CA  CYS A   4      -6.736   1.983  -6.844  1.00 93.93           C  \\nATOM     32  C   CYS A   4      -7.157   3.447  -6.856  1.00 93.93           C  \\nATOM     33  O   CYS A   4      -8.293   3.774  -6.506  1.00 93.93           O  \\nATOM     34  CB  CYS A   4      -7.173   1.307  -8.143  1.00 93.93           C  \\nATOM     35  SG  CYS A   4      -6.617  -0.405  -8.295  1.00 93.93           S  \\nATOM     36  N   LEU A   5      -6.251   4.262  -7.004  1.00 92.07           N  \\nATOM     37  CA  LEU A   5      -6.516   5.694  -7.081  1.00 92.07           C  \\nATOM     38  C   LEU A   5      -5.970   6.279  -8.379  1.00 92.07           C  \\nATOM     39  O   LEU A   5      -4.866   5.933  -8.805  1.00 92.07           O  \\nATOM     40  CB  LEU A   5      -5.899   6.418  -5.882  1.00 92.07           C  \\nATOM     41  CG  LEU A   5      -6.205   7.912  -5.761  1.00 92.07           C  \\nATOM     42  CD1 LEU A   5      -7.600   8.122  -5.182  1.00 92.07           C  \\nATOM     43  CD2 LEU A   5      -5.154   8.606  -4.901  1.00 92.07           C  \\nATOM     44  N   CYS A   6      -6.710   7.156  -9.084  1.00 95.31           N  \\nATOM     45  CA  CYS A   6      -6.327   7.793 -10.339  1.00 95.31           C  \\nATOM     46  C   CYS A   6      -6.136   9.293 -10.154  1.00 95.31           C  \\nATOM     47  O   CYS A   6      -7.033   9.982  -9.666  1.00 95.31           O  \\nATOM     48  CB  CYS A   6      -7.381   7.533 -11.415  1.00 95.31           C  \\nATOM     49  SG  CYS A   6      -7.645   5.782 -11.768  1.00 95.31           S  \\nATOM     50  N   ARG A   7      -5.008   9.721 -10.367  1.00 93.64           N  \\nATOM     51  CA  ARG A   7      -4.687  11.143 -10.301  1.00 93.64           C  \\nATOM     52  C   ARG A   7      -3.997  11.608 -11.579  1.00 93.64           C  \\nATOM     53  O   ARG A   7      -3.045  10.978 -12.041  1.00 93.64           O  \\nATOM     54  CB  ARG A   7      -3.801  11.439  -9.089  1.00 93.64           C  \\nATOM     55  CG  ARG A   7      -4.039  12.808  -8.472  1.00 93.64           C  \\nATOM     56  CD  ARG A   7      -2.886  13.229  -7.571  1.00 93.64           C  \\nATOM     57  NE  ARG A   7      -3.207  13.038  -6.159  1.00 93.64           N  \\nATOM     58  CZ  ARG A   7      -2.988  13.937  -5.204  1.00 93.64           C  \\nATOM     59  NH1 ARG A   7      -2.440  15.112  -5.491  1.00 93.64           N  \\nATOM     60  NH2 ARG A   7      -3.320  13.659  -3.951  1.00 93.64           N  \\nATOM     61  N   ARG A   8      -4.411  12.708 -12.132  1.00 94.95           N  \\nATOM     62  CA  ARG A   8      -3.879  13.348 -13.330  1.00 94.95           C  \\nATOM     63  C   ARG A   8      -3.709  12.339 -14.461  1.00 94.95           C  \\nATOM     64  O   ARG A   8      -2.711  12.370 -15.183  1.00 94.95           O  \\nATOM     65  CB  ARG A   8      -2.541  14.026 -13.028  1.00 94.95           C  \\nATOM     66  CG  ARG A   8      -2.661  15.266 -12.156  1.00 94.95           C  \\nATOM     67  CD  ARG A   8      -1.303  15.895 -11.880  1.00 94.95           C  \\nATOM     68  NE  ARG A   8      -1.428  17.292 -11.476  1.00 94.95           N  \\nATOM     69  CZ  ARG A   8      -0.442  18.025 -10.966  1.00 94.95           C  \\nATOM     70  NH1 ARG A   8       0.767  17.505 -10.786  1.00 94.95           N  \\nATOM     71  NH2 ARG A   8      -0.666  19.288 -10.634  1.00 94.95           N  \\nATOM     72  N   GLY A   9      -4.618  11.285 -14.489  1.00 92.71           N  \\nATOM     73  CA  GLY A   9      -4.626  10.347 -15.600  1.00 92.71           C  \\nATOM     74  C   GLY A   9      -3.761   9.125 -15.355  1.00 92.71           C  \\nATOM     75  O   GLY A   9      -3.574   8.301 -16.252  1.00 92.71           O  \\nATOM     76  N   VAL A  10      -3.051   9.164 -14.233  1.00 95.49           N  \\nATOM     77  CA  VAL A  10      -2.243   8.010 -13.853  1.00 95.49           C  \\nATOM     78  C   VAL A  10      -2.934   7.243 -12.728  1.00 95.49           C  \\nATOM     79  O   VAL A  10      -3.330   7.832 -11.719  1.00 95.49           O  \\nATOM     80  CB  VAL A  10      -0.822   8.431 -13.417  1.00 95.49           C  \\nATOM     81  CG1 VAL A  10       0.023   7.206 -13.073  1.00 95.49           C  \\nATOM     82  CG2 VAL A  10      -0.150   9.256 -14.514  1.00 95.49           C  \\nATOM     83  N   CYS A  11      -3.111   5.897 -12.924  1.00 94.78           N  \\nATOM     84  CA  CYS A  11      -3.758   5.075 -11.907  1.00 94.78           C  \\nATOM     85  C   CYS A  11      -2.741   4.195 -11.189  1.00 94.78           C  \\nATOM     86  O   CYS A  11      -1.878   3.590 -11.827  1.00 94.78           O  \\nATOM     87  CB  CYS A  11      -4.847   4.205 -12.533  1.00 94.78           C  \\nATOM     88  SG  CYS A  11      -6.197   5.149 -13.273  1.00 94.78           S  \\nATOM     89  N   ARG A  12      -2.717   4.305  -9.902  1.00 94.62           N  \\nATOM     90  CA  ARG A  12      -1.837   3.452  -9.110  1.00 94.62           C  \\nATOM     91  C   ARG A  12      -2.627   2.663  -8.072  1.00 94.62           C  \\nATOM     92  O   ARG A  12      -3.551   3.194  -7.452  1.00 94.62           O  \\nATOM     93  CB  ARG A  12      -0.755   4.288  -8.423  1.00 94.62           C  \\nATOM     94  CG  ARG A  12       0.492   4.496  -9.267  1.00 94.62           C  \\nATOM     95  CD  ARG A  12       1.606   5.165  -8.473  1.00 94.62           C  \\nATOM     96  NE  ARG A  12       2.605   5.770  -9.350  1.00 94.62           N  \\nATOM     97  CZ  ARG A  12       3.375   6.804  -9.022  1.00 94.62           C  \\nATOM     98  NH1 ARG A  12       3.274   7.371  -7.826  1.00 94.62           N  \\nATOM     99  NH2 ARG A  12       4.251   7.275  -9.897  1.00 94.62           N  \\nATOM    100  N   CYS A  13      -2.374   1.437  -8.051  1.00 94.97           N  \\nATOM    101  CA  CYS A  13      -3.036   0.572  -7.082  1.00 94.97           C  \\nATOM    102  C   CYS A  13      -2.109   0.249  -5.916  1.00 94.97           C  \\nATOM    103  O   CYS A  13      -0.904   0.074  -6.106  1.00 94.97           O  \\nATOM    104  CB  CYS A  13      -3.502  -0.722  -7.748  1.00 94.97           C  \\nATOM    105  SG  CYS A  13      -4.652  -0.463  -9.117  1.00 94.97           S  \\nATOM    106  N   ILE A  14      -2.562   0.316  -4.766  1.00 90.99           N  \\nATOM    107  CA  ILE A  14      -1.790   0.026  -3.563  1.00 90.99           C  \\nATOM    108  C   ILE A  14      -2.461  -1.099  -2.777  1.00 90.99           C  \\nATOM    109  O   ILE A  14      -3.683  -1.104  -2.610  1.00 90.99           O  \\nATOM    110  CB  ILE A  14      -1.634   1.281  -2.675  1.00 90.99           C  \\nATOM    111  CG1 ILE A  14      -0.890   2.384  -3.436  1.00 90.99           C  \\nATOM    112  CG2 ILE A  14      -0.913   0.933  -1.369  1.00 90.99           C  \\nATOM    113  CD1 ILE A  14      -0.977   3.756  -2.780  1.00 90.99           C  \\nATOM    114  N   CYS A  15      -1.723  -2.123  -2.329  1.00 93.25           N  \\nATOM    115  CA  CYS A  15      -2.222  -3.263  -1.569  1.00 93.25           C  \\nATOM    116  C   CYS A  15      -1.701  -3.236  -0.138  1.00 93.25           C  \\nATOM    117  O   CYS A  15      -0.538  -2.904   0.098  1.00 93.25           O  \\nATOM    118  CB  CYS A  15      -1.819  -4.574  -2.244  1.00 93.25           C  \\nATOM    119  SG  CYS A  15      -2.331  -4.692  -3.972  1.00 93.25           S  \\nATOM    120  N   THR A  16      -2.491  -3.157   0.726  1.00 85.70           N  \\nATOM    121  CA  THR A  16      -2.070  -3.257   2.119  1.00 85.70           C  \\nATOM    122  C   THR A  16      -2.141  -4.702   2.604  1.00 85.70           C  \\nATOM    123  O   THR A  16      -2.982  -5.477   2.141  1.00 85.70           O  \\nATOM    124  CB  THR A  16      -2.934  -2.364   3.028  1.00 85.70           C  \\nATOM    125  OG1 THR A  16      -4.312  -2.726   2.874  1.00 85.70           O  \\nATOM    126  CG2 THR A  16      -2.765  -0.891   2.674  1.00 85.70           C  \\nATOM    127  N   ARG A  17      -0.970  -5.190   2.998  1.00 80.74           N  \\nATOM    128  CA  ARG A  17      -0.916  -6.558   3.504  1.00 80.74           C  \\nATOM    129  C   ARG A  17      -1.970  -6.785   4.582  1.00 80.74           C  \\nATOM    130  O   ARG A  17      -2.168  -5.935   5.453  1.00 80.74           O  \\nATOM    131  CB  ARG A  17       0.476  -6.873   4.057  1.00 80.74           C  \\nATOM    132  CG  ARG A  17       1.533  -7.078   2.984  1.00 80.74           C  \\nATOM    133  CD  ARG A  17       2.843  -7.585   3.573  1.00 80.74           C  \\nATOM    134  NE  ARG A  17       3.915  -7.586   2.581  1.00 80.74           N  \\nATOM    135  CZ  ARG A  17       5.026  -6.859   2.665  1.00 80.74           C  \\nATOM    136  NH1 ARG A  17       5.234  -6.055   3.702  1.00 80.74           N  \\nATOM    137  NH2 ARG A  17       5.937  -6.936   1.706  1.00 80.74           N  \\nTER     138      ARG A  17                                                       \\nEND   \\n\",\"pdb\");\n",
       "\tviewer_16788868218654912.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n",
       "\tviewer_16788868218654912.zoomTo();\n",
       "viewer_16788868218654912.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: PDB file predicted:  ./output_model_B/~~EEEEEETTEEEEEE~~_99800_0_0.pdb Error:  0.1111111111111111\n",
      "Cond: ~~EEEEEETTEEEEEE~~\n",
      "Pred: ~EEEEEEETTEEEEEEE~\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################\n",
      "####################################################\n",
      "####################################################\n",
      "FINAL RESULT at 0:  ./output_model_B/~~EEEEEETTEEEEEE~~_99800_0_0.pdb Error:  0.1111111111111111\n",
      "Seq:  GDCRCLCRRGVCRCICTR\n",
      "Cond: ~~EEEEEETTEEEEEE~~\n",
      "Pred: ~EEEEEEETTEEEEEEE~\n",
      "FINAL FILE NAME at 0:  ./output_model_B/~~EEEEEETTEEEEEE~~_99800_0_0_FINAL.pdb\n",
      "####################################################\n",
      "####################################################\n",
      "####################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./output_model_B/~~EEEEEETTEEEEEE~~_99800_0_0.pdb',\n",
       " 0.1111111111111111,\n",
       " '~~EEEEEETTEEEEEE~~',\n",
       " '~EEEEEEETTEEEEEEE~')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_adaptive (model_B,  seq='~~EEEEEETTEEEEEE~~',flag=99800, errorthreshold=0.8, \n",
    "                                             maxiter=10)\n",
    "                  \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9bfa2267-7cbe-426b-ba5b-b6e500ac55a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing 1 samples...from image conditingig x_data  ...\n",
      "['~~HHHHHHHHHHHHHHHHHHHH~~']\n",
      "Device:  cuda:0\n",
      "X_cond= None\n",
      "Conditioning target sequence provided via x_data ... ['~~HHHHHHHHHHHHHHHHHHHH~~']\n",
      "x_data from target sequence= tensor([[[0.2222, 0.2222, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "          0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "          0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.2222, 0.2222,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0') torch.Size([1, 1, 128])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7c707955ef4ec2a8188cfc2c61e00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e751b43e0f5487a8264d694ed68b66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling time step:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAypElEQVR4nO2de7RkZXnmn3fvXXVufYGGAwpIuicBMt09gExjcARCxOESLySaTMQk6giSZGliXIkuHdeS5Zo1rmSSFRN1BuwRopNRZIZg4qgYlMC0iUJsLsEGRDAgNoJ96Ia+nFtV7f3OH3t/+1bf3rV3VXWfs+nntxarz6naVfVVdfOc5zzf+36vqCoIIYQ0D2elF0AIIWQ4KOCEENJQKOCEENJQKOCEENJQKOCEENJQvCP5Yscff7xu3LjxSL4kIYQ0nnvvvfc5VZ3N335EBXzjxo3YuXPnkXxJQghpPCLyQ9vtjFAIIaShUMAJIaShUMAJIaShHNEMnBDy4qTb7WL37t1YWlpa6aU0msnJSZxyyilotVqVrqeAE0JGZvfu3Vi7di02btwIEVnp5TQSVcXevXuxe/dubNq0qdJjBkYoInKjiOwRkV25239XRL4nIg+JyH8dcs2EkBcBS0tLOO644yjeIyAiOO6442r9FlMlA/8MgMtyL/QLAK4AcJaqbgHwpzXWSQh5EULxHp26n+FAAVfVHQD25W7+HQB/pKrL0TV7ar1qTe545Ce47q4fHM6XGBv75jv4yoPPVL7+uUPL+Nqu6tcTQohh2CqU0wFcICL3iMj/E5Fziy4UkWtEZKeI7Jybmxvqxe56dA7/45v/MuRSjyxfvP9pvOvz9+HgUrfS9bfcuxu/87n7sNT1D/PKCHlx47ouzj77bGzduhW/+qu/ioWFhaGf6+1vfztuueUWAMDVV1+Nhx9+uPDau+66C9/61rdqv8bGjRvx3HPPDb1GYHgB9wBsAHAegPcB+N9S4P1VdbuqblPVbbOzfZ2glXAdQc8PhlzqkaXTC9e5WFGQ55d7UAW6DXl/hKxWpqam8MADD2DXrl1ot9u4/vrrM/f3er2hnvfTn/40Nm/eXHj/sAI+DoYV8N0AbtWQfwIQADh+fMvK4jkCP2jG5KAgmnC03K0myIudUOgD6jchY+OCCy7A448/jrvuugsXXHAB3vCGN2Dz5s3wfR/ve9/7cO655+LMM8/Epz71KQBhBci73/1unHHGGXjNa16DPXuSVPiiiy6KjwD52te+hnPOOQdnnXUWLr74Yjz55JO4/vrr8bGPfQxnn302vvnNb2Jubg5vetObcO655+Lcc8/FP/7jPwIA9u7di0suuQRbtmzB1VdfjXFMQxu2jPBvAPwCgDtF5HQAbQCj/S5QgusKeg0R8J4fCXivmgM3Tt3naDvyIuEj//chPPzjA2N9zs0nrcO1r99S6dper4fbbrsNl10W1l7cd9992LVrFzZt2oTt27dj/fr1+M53voPl5WW86lWvwiWXXIL7778fjz76KB5++GH85Cc/webNm/GOd7wj87xzc3N45zvfiR07dmDTpk3Yt28fNmzYgN/+7d/GmjVr8Id/+IcAgLe85S1473vfi/PPPx9PPfUULr30UjzyyCP4yEc+gvPPPx8f/vCH8ZWvfAU33HDDyJ/LQAEXkZsAXATgeBHZDeBaADcCuDEqLewAeJsexuGaTXLgRoiXqjpwI+ANeX+ErFYWFxdx9tlnAwgd+FVXXYVvfetbeMUrXhHXVd9+++148MEH43x7//79eOyxx7Bjxw5ceeWVcF0XJ510El796lf3Pf/dd9+NCy+8MH6uDRs2WNfxjW98I5OZHzhwAIcOHcKOHTtw6623AgBe+9rX4thjjx35PQ8UcFW9suCu3xj51SviSnMceBAYB15NwM3mZUAHTl4kVHXK48Zk4HlmZmbir1UVn/jEJ3DppZdmrvnqV786tnUEQYC7774bk5OTY3vOIhpxForrhMsMGiDi5gfNcsVNTJOB04ETcvi59NJLcd1116HbDavEvv/972N+fh4XXnghbr75Zvi+j2eeeQZ33nln32PPO+887NixA0888QQAYN++sLp67dq1OHjwYHzdJZdcgk984hPx9+aHyoUXXojPf/7zAIDbbrsNzz///MjvpxEC7rlhgUsTXHi8iVnRgTNCIeTIcfXVV2Pz5s0455xzsHXrVvzWb/0Wer0efvmXfxmnnXYaNm/ejLe+9a145Stf2ffY2dlZbN++HW984xtx1lln4dd+7dcAAK9//evxxS9+Md7E/PjHP46dO3fizDPPxObNm+NqmGuvvRY7duzAli1bcOutt+LUU08d+f004iwU1wkFvAki5wd1NzGDzOMIIcNx6NChvtsuuugiXHTRRfH3juPgox/9KD760Y/2XfvJT37S+rx33XVX/PXll1+Oyy+/PHP/6aefjgcffDBz280339z3PMcddxxuv/32srdQm2Y4cMc48NVfa2eEuOom5lKHVSiEkOFohIA78mJ24KYOfPW/N0LI6qIRAl43A+/5QWFruqpifnlwR9Zyzx+qO9IfNgOnAycN5zBWEh811P0MGyHgJgOv6lI//veP403X2Vtb/+6hZ/GK//INPD/fKX2Oqz+7E//5y8XnHxQRlxFWjVC4iUleBExOTmLv3r0U8REw54HXKT9sxCZmkoFX+8fx4xcW8eMXFq33Pbt/CfMdHw8+vR8/f3rx2Sw/fmERE179n2+9OAOvFqHEdeCrP94npJBTTjkFu3fvxrAH1pEQM5GnKo0QcFMHXtWl9vygUOzN7bsGCLgfKLp+fTdRp5Gn6wfxazBCIU2m1WpVniJDxkcjIpS6DrwXaHwmSR5Tp/3Qj/eXPoevOlSskWTggx142qUzQiGE1KURAu7EdeDVcoaer4Ulh+aHwEMDDtvxfR1qE7NXo4wwfeQsW+kJIXVphIB7sYBXu74XhNGEbUPFRBw/3LuA/YvFQxd81aE6P4MaZYRLneQNFf3GQAghRTRCwN2ajTxxrmwR4LQolx156Qc61BAJv0YGTgdOCBmFRgi4V7OV3gi9zUGnSxHLcvBhNzH9GmWEi8zACSEj0AgBd2tuYhrhtWXYvUDhOYIT102U5uC9oDhHLyM+D7xChGJOIkw/jhBCqtIIAfeGKCMM/+y/3leF6wi2nrS+1IEHJZUsZdRx4OkqFLbSE0LqMlDAReRGEdkTTd/J3/cHIqIictjmYQJApN+VBdU49a7FQft+6MC3nLQOj+85lHHB+eewPX4QQY0yQkYohJBRqOLAPwPgsvyNIvIyAJcAeGrMa+rDOPCqG30mQily4I4j2HLyegQKPPKsPUYJdDgHnszErJCBd7iJSQgZnoECrqo7AOyz3PUxAO8HcNiVp24GXhqhRBn41pPXAyiuB+8N24kZz8Ss68BrvxQh5ChnqAxcRK4A8LSq/nOFa68RkZ0isnPYcxK8uo08JRFKLwgz8JPWhwfGPHdwue+aIFCoDnf+eJ0ywkwnJh04IaQmtQVcRKYB/CcAH65yvapuV9Vtqrptdrb47JEyYgde0RF3Sxx4EAm4iMB1xCrSRkxH2sSsKeDcxCSE1GUYB/7TADYB+GcReRLAKQDuE5GXjHNhaeqOVOsNKCN0owERLVesMYl5nVHOA68boTRh3ichZHVR+zRCVf0ugBPM95GIb1PV58a4rgxxhFIxZhjUyONGAyJajmMVaSPgw4iqebpqm5jJNXTghJC6VCkjvAnAtwGcISK7ReSqw7+sLHUdeFKFMsCBe3YBN8LtB/bzVMowOX2nFwx87CIzcELICAx04Kp65YD7N45tNQWYMsLKdeCRKFvjkaiRJ3xeKczJDV1f0fak8lrTP2SWewEmW27htUtdHxOeg+VewDpwQkhtGtGJaSKPyg48jkDsjTxGwFuug06JAy96jjLSSxzUjbnY8bF20oseRwEnhNSjEQJee6DDwFb68G233AIHrlkHXoe04A/qxlzs+piZCAWcDpwQUpdGCLgj1evAg0BjF1y0QemlHHhZBg7Yc/Ty1wei5Q7cyFzs+phpU8AJIcPRCAGvc5xsunnH5tj9QOMJP57rWB12kIlQ6m5iKqaj3HtQKeFS18eaCUYohJDhaISAmwy8ipimI5FBDrztykAHXrcW3FfFVOSqBzrwjo+ZCTdaV62XIYSQZgh4HQeeFnBbvt0LglQjj2Pf6Ey7+JoZuB8optuhKNfJwOnACSF1aYSA1znMKhuh9ItzECTP57mCbs8WsyRf161CyQj4gCqUdITCmZiEkLo0QsDrDHTIRigFDnxgGWFyW90qlCDQ2FUPmsqz1A2SKhQ6cEJITRoh4JHeVnPgfjr+sB1UhYyAF7n05DnqlhFWc+CqisWuj+m2CxG20hNC6tMIATcnB1YRud6AChI/48DtEUrGgdeNUDSdgRc/tusr/EAx2XLhOUIHTgipTSMEHEB09GuVCGVQGWE6A3esAp3eUKzrwINA49rusjJCcw7KZMuFI9V+OBFCSJrGCLjnSKVGnm6mCsVeYWKqUNpFjTwDnqOMXqCYquDAjbhPtVy4jrCRhxBSm8YIeGUHPmAD0k8dJ1t0mFU6zujWEFbjos3GZFkZoZmHOdV24AojFEJIfRol4JU6MdPu2VrjPfg42fTr1HHgRoSnWoM3MRdTDtypmO8TQkiaxgi4V1HAMxl4gbuOz0JxyifyAPXKCM3j2p4D15HSMsJ0Bu5yE5MQMgSNEfCqDrw3QHzzx8kOdOA1qlDM4zxHMOk5pQ58qZNy4CJspSeE1KbKRJ4bRWSPiOxK3fYnIvI9EXlQRL4oIscc1lUibOapXQdeMpUeCKtQ7O32w1WhGBftOoKJllu6iRlHKG0XrlPtpEVCCElTxYF/BsBludu+DmCrqp4J4PsAPjjmdfVR2YEP6MQMUhN52q6g4/ePPstO5KkurOZxjggmPKdSGeFUyw03ManfhJCaDBRwVd0BYF/utttVtRd9ezfCyfSHFa9yFUr5BmTegQP9Lfrp56hT3mce5zqCyUEOvJPKwF3hYVaEkNqMIwN/B4Dbiu4UkWtEZKeI7Jybmxv6RZyKdeC9CueBpzNwoN+pByOWEbqORLMuix34UjpCEdaBE0LqM5KAi8iHAPQAfK7oGlXdrqrbVHXb7Ozs0K9VvQpFo7UVnweeHCcb/pnvxhy2kSeTgUfDiotYijY4TRkhq1AIIXUZOJW+CBF5O4DXAbhY8yHyYaB6HXgijNYywlQjT+zAc0LrD9lKb651RTDhuZVb6V220hNChmAoAReRywC8H8DPq+rCeJdkp24GPtVyBzbyeAWTfjJ14DWqQ4JMFYqDQ8u9wmsXu35cL85WekLIMFQpI7wJwLcBnCEiu0XkKgCfBLAWwNdF5AERuf4wr7NGFUoouJMt114HrtmhxgDQyTvwYcsIMxm4W96J2fHjjk1HuIlJCKnPQAeuqldabr7hMKylFM+x12znMaI91e534EGgUEU81LhVwYHXysBNGWHkwMs6MZe6PiZb4Q8QOnBCyDA0phPTcapNrTGiPWVx4ObxeQee3+zMRij1G3k8s4k54CyU2IFXjIcIISRNYwTcc5xah1mFm5h2YXajEW1mVFuZgA/lwKVaHfhkJOCucKgxIaQ+jRHw6gMdwmsm227f9UmjTfh924vKCH37deF54cNm4OV14ItdPz43vOoPJ0IISdMYAa860KEXBBCxi2+RA8+7bOOGJzz7zMwi0odZDdrEXMpEKNk5nIQQUoXGCLhbMHwhT9dXtBwHLVeKI5RoSHJcheLbG3kmCmrJizDC70QOvOMHhfXd6Qycx8kSQoahUQJetYzQcyU8abCgusSNhDuuQinY7Jzw6kYo0VqjDBzo/+FgWOz4mGwnZYSMUAghdWmWgFeqQgnrvMNhDUUOfFAVSji53nOlVoRirjUZOFA82DhdB+46rAMnhNSnMQJe9SyUrh+g5Tqh+A4oIzSdmP1ZeSiqRTMzizBabzoxgeLBxoeWe1gTzc7kYVaEkGFojIC7FRt5er6mIpScs/aTjBoINzqBAgcuUjixp4jkMCtg0iuei6mqWOj4mJlI6sAp4ISQujRGwCs78CCA5zjWeZf9DjyqQskLfRBeE0YodTLw8HkcSTvw/gil4wfoBYrpduLAGaEQQurSGAF3K4ppz1e0jAO3OGugv5W+28tHKAEcR+A5NR14dKnnOJiIHPiSxYHPL4eiPtNOMnB2YhJC6tIcAZfqdeCeycD7qlDCP718hJJ34NGBVy1Ljl5GchYK4k1MmwOfj04pnDEZuMPjZAkh9WmOgFfexAzF13b8bLpKBEgilL7zwAONHfgwjTxmpBpg38Sc7/QLOOvACSF1aYyAV5/IE1WhRO3p6VkT/WWE9tMIe+aHgNufo5eRP8wKsJcRxhFKJOCOCDsxCSG1aYyAV87Ag7AKpWUpEUwaeXLngeez8mhyfctSyVJGZip9SRlhHKHEGXi94cmEEAJUG+hwo4jsEZFdqds2iMjXReSx6M9jD+8ya9aBO461wqSokaevXjwafFy3Djw9ld5sYtoy8IUoQomrUBihEEKGoIoD/wyAy3K3fQDAHap6GoA7ou8PK67T3xpvI64Dd4oduLnPdcQ6/NgIeN068CCTgUcOvKQKZU0mQqGAE0LqMVDAVXUHgH25m68A8Nno688C+KXxLqsf45rzQrfU9fGdJ5PldQOF5zopd93vwE0ZIYBIpC0OXIaoA9d+B27NwI0Dn+BhVoSQ4Rk2Az9RVZ+Jvn4WwIlFF4rINSKyU0R2zs3NDflyxQOIv/rdZ/AfPvVtzB1cDu/3A7SiDcj89flGHgCFZ6aYYcNDzcSU1CamNQPvd+DMwAkhdRl5E1PDMo9C9VHV7aq6TVW3zc7ODv06pvQvL3T7F7tQBQ4udQGEEYrrCFqWaTs9mwP3+mOSOEKp3cjTX0Zor0LpwZGkVpx14ISQYRhWwH8iIi8FgOjPPeNbkh3jmvNVIabKYzESym6QHGYFZDcog6DfgYfdlv0t98O10icC7jqCtufE60oz3+lhpu1BoljIVrNOCCGDGFbAvwTgbdHXbwPwt+NZTjFFDtw4XPNn+jArICv4vVSZn6Ht2iMUZ5hNTM06/KmWi6WO3YGbGnBzPc9CIYTUpUoZ4U0Avg3gDBHZLSJXAfgjAP9eRB4D8Jro+8OK69gz8NiBd8I/e35ymBWQrUKJHbibcuDWM1NS3ZxDlBF6KQG3O3A/3sAEeJwsIWQ4vEEXqOqVBXddPOa1lGIEPJ8VmzK9JEJJDrMCshFKL7XJaGhZui17gcIR+5G0Zfg5hz/VdrFoKSNcSJ0FDhgHHh4zK6m1EUJIGY3pxPQKHPhS1CizGEcoZqRa5MBtjTx9ZYQWBx51c3b9bDt+GUHu+SdbLhatEYqP6XbWgQMATTghpA6NEXAzST4fNRgHbrLm8BwTJ65C6VkbeZK3XSTgruPE11WNN/IOf6rlFNaBz7QTBx79ssAYhRBSi8YIeJEDX8458LAKJVUHbm3kST2v9dhZhSvFtedFBKoQSW1itgsycMsmpnk8IYRUpTECnlShlJcR+nEnpolQbI08WQfesRwn6zpO4WmFRZgOTsNUUYSSGqcGJI6dDpwQUocGCnj29nQZoaqi62vYien0t9L3LA68VeTAHVifowxTfmiYbLlxRp9mfjkfoUTvjQ6cEFKDxgl4WSNPnHGnGnmsZYSDMnCNcvSCqfVFmPJDg60OPAjCgcbTE/0Czm5MQkgdGiPgXkEjjxHwpY6f1GG7khxmZWnkSccc1k5MM5GnYOhxEb7mIhRLBm6+n0lXoRTk+4QQUkZjBLywkaebbGIaJ91ynGTT0+LA3VQjT9uzd2KaRp78c5QR5CIUWyNPfh4mkNSN04ETQurQGAEvKulLIpQgFtq0A7cdZpV34LZOTEfsz1FGLxehTLZcLHWDjDDPd8w4tX4HzgycEFKHxgi4W+CGYwfe8eOmnXQGnnbsQeq8bkPReeDmMKv8c5QRaM6Bt/sHGyfj1FIZOKtQCCFD0DgBz9dKxxl414/FvbAKxbcJeH+E0ktNpQeqO3BbGSGATIxijVDiTcxKL0MIIQAaKOB9rfSpDDyJUOwVJKaGPKXfBZ2YATwnGYxcNQPvReeIG8xYtYyAx/Mw0xFK9LqMUAghNWiMgHuDGnlSEUrLFWvZoTnnO31glOf2nzgYDzWuWYUS9Am4G6/NkJ/GAySbmIxQCCF1aIyA2zLwnh/EjjwdoYQ13Cb+yJ5GmM6oAaDtOugUTuSpWQeu2XhmyjKVJ55Ib6sDpwMnhNSgMQJuNhTTLjUtvOkywvRU+vT1Qa5KxFzb14kZT+TpPxCrDD8IsgLe7s/ADxkHzk1MQsiINEbAjcilxXYpOolQJMrAo/syEUqujNDNnbfdch34gWZK/ZJGnv4jacso3MRMRSgL0SbmlKWRhwJOCKnDSAIuIu8VkYdEZJeI3CQik+NaWB5bzGBOIlw/1cJix4/F2nMciETneecceLqJB0ASteTODfdSg5GrO3D0nYUC5Bx4p4e266DtJR89BZwQMgxDC7iInAzg9wBsU9WtAFwAbx7XwvJ4FjE1Z4EfM9XCci+ITxU0zjnfpGN34NmcW1URKKKJPP0uvowwQkm+Ny47k4EvZ08iBBLRZxUKIaQOo0YoHoApEfEATAP48ehLsuNaMnBz0t/66TYA4GAUTxhX7eXGpQWarRIB+k8cTIY+iPVI2jLCTczkI7VFKPPLPUy3s5PsXLbSE0KGYGgBV9WnAfwpgKcAPANgv6renr9ORK4RkZ0isnNubm7ohdoGOqQdOAAcXOplrm3lZlr2/H4Bb0VRhtkQTY6ctTcDlRFEgyAMtiqU+U52HibACIUQMhyjRCjHArgCwCYAJwGYEZHfyF+nqttVdZuqbpudnR16obaBDqYG/JjpUMAPLXUBpBx4bqq8b3Hg7VyzTqCJA/dqNvL4uTrwpAolWfNCbiI9kKoDZ4RCCKnBKBHKawA8oapzqtoFcCuAfzeeZfVjK7Uzm5h9DtxNHHg3NxOzKELp5hy464h1g7OM/PNPeP2dmIdywxzMawFspSeE1GMUAX8KwHkiMi1ha+PFAB4Zz7L6cS0HS5kywmNyGbgR5bDGO7eJWRChGKH3U+el1D1ONu/wRSQc6jBgE5Ot9ISQYRglA78HwC0A7gPw3ei5to9pXX3YGnNiBz5tHLiJUCR+TP488HwjT9JtGW1iZiKU+odZObkql6l2di6mzYHzPHBCyDB4gy8pRlWvBXDtmNZSiu0wq3gTMxLwA3GEEgpv/qCqnkVgW7luSz+1iTnMUOP8D4j8UIeFTnYiPVB81jkhhJTRmE5Mm8jFm5hTUYQSCbhx1fk2+SDQOB+Pnzf6vmMpIxxmqHE+oplsObnjZC2bmNHfAkeqEULq0BgBN7qYzcDtEYoXV6H0O/B8I0/btdeBOyK1hxoHao9QzGDjTi9Axw+KNzGZgRNCatAYARcJzzcJbA58OuvAkyqUXAZua+TJnVqYTLaX+DWrHifbszj8SS+JUBbjcWr2Rh5GKISQOjRGwAFEYmo/CwVIbWI6iQMf2MiTO7Cql3Lg8WvWGWps28SMBPxQx4xTs7fS04ETQurQKAH3HMk08ix1A7RdJ55uYxy4m8rAuwMaeeJa78jNJ4080UaoIzXOA7dl4EkVyoJlnBpAB04IGY5GCbjNgU+0HEx4DkTCLkcgcdX5VnrbJmN+8EMyNzO838s9Rxk2h5+uAz8UC3i+DpwCTgipT6MEPHTg2Qx8wnPjhhkgFEMzMq2vlT7QzGFTAFKT57MO3FzXcqs78ED7N0nTZYTmN4S+OnBGKISQIWiUgLt5Ae8Gcbu6OXs7XYedrwP3c4dNAUkVijmKNmmlR/R8zkhlhOlGnrmDywCA2bUT2fcVRyiVXoYQQgA0XMCXen48+d048FbqQO58HXiv1IGbKpQgei3H+hxlBNo/c3Oy5cYt/3OHQgE/YV127kUcodCBE0Jq0CgBD6tK8g48FG4j5OkyvtA95yby5N5xK9cub1ywccV5F19Gr6ATs+MH8APFngPLmG67hcfJspWeEFKHRgl4X4QSbWICydGtXsphh/l1upEnyNwPJCWH8SZm7MDtOXoZ9rNQwudf6vrYc3AJJ+TiE8A+75MQQgbRKAH38lUoqQw8iVASAc1XrQSK/ioUL3uYlSk4iceyuU71CMWWgafmYu45uIwT1vaPDTU/U+jACSF1aJSAu7k68OWeH29expuYbvEmZi8IBo5UMw7ciSOUmp2YlgwcCLswnzu43LeBad4XwAycEFKPBgp4voww58BTEUn/cbIWBx4fZtU/kcf2HGXYNjHTg433FAi4w0YeQsgQvAgEPBTIOANPb2LmZ2IGQV+dtohEIh058NRAB/Mcdc4Dt9WBA8De+Q4OLfdwwrpiB84IhRBSh0YJeD4DX+r6fQ48v4mZvt4Pksk+adJRS9LII9bnKEJVrRm7WddTexcAwJqBu5yJSQgZgpEEXESOEZFbROR7IvKIiLxyXAuzYXPg+Qy8lSsjVE2iCd/iwIHsmSnpmZjmOao08vi5xxkmo98MfrhvHgCsVSgOHTghZAhGmsgD4C8AfE1Vf0VE2gCmx7CmQvJ13ctpBx5HKNlGHiCsMHEd19opCYTdmN3ceeBpB16lld5Xu4DHDnzfIgBYI5TwvQkdOCGkFkM7cBFZD+BCADcAgKp2VPWFMa3LijUDb+UjlHQVSr7L0i7gXurc8FjAJeXAc1UoN/7DE/j9L9yfua3IgScRSujAZ9fYBdxxhK30hJBajBKhbAIwB+AvReR+Efm0iMzkLxKRa0Rkp4jsnJubG+HlIgFXc2pggF6gmDSbmLZW+r4Swf4yP/OYrp8/CyU1li3nwO/94fO443t7Mrflhd9gop0f7luA5wiOjYZP9L03ER5mRQipxSgC7gE4B8B1qvpyAPMAPpC/SFW3q+o2Vd02Ozs7wstlG3PMNB7jwCctVSj5kWi2Mr/wOgfd6HmDvgjFiYc9GBa7Pg4u9eJjYsPHhX/2lRFGAv7CQhezayesrx+/t4rlioQQAowm4LsB7FbVe6Lvb0Eo6IeN9ECHWMDNWSheMoUnvt7MuwwGOXCJBzqYHxBldeDmdME9B5bj2/xc/bhhsp2sx7aBaXCEx8kSQuoxtICr6rMAfiQiZ0Q3XQzg4bGsqoC0SzXuN7+Jma1CiTJwXxEECrWU+YXXJTl3vowwrAPPCXj02nsOLsW3xR2cuedvu048kHnWUkKYfm9s5CGE1GHUKpTfBfC5qALlXwD8x9GXVIznJiJnHLjJmONNTDddB56cNBhXiVjKCFueE3di5ht5bK30S7GAJw7cXGJrFJpquZjv+IUVKOb1WIVCCKnDSAKuqg8A2DaepQzGkUTkzEDj/lb6dCdmUoUSbzLaGnlSnZh9DjxXugikHPiBxIEnZYT9655qhwJeVIFi3hvrwAkhdWhcJ2bswLuDNzE9J+XAC6pEgPIqlPyRtEDiwM2ABgDwY+fe/5Ga3xIGOnAKOCGkBo0ScDflhpMMvCxCSTLwokYbIIxQuvk68HQZYVB9E9PqwI2AD8rAGaEQQmrQKAHPOPA4Ay+LUJIqFN8vEXBH+jsxU408fqDQlLiaEWnpDNw8Lj/QAUg2WMuqUFyHEQohpB6NEnDXtdSB951GmHLgTlIHXlTmB4QRSl8nZipCMc8BhE1BHb9YwPMTf4CKEYoIWAZOCKlDowQ8Wwee3cS0DXSIHbifbGLaGmk8N+vAHQmrRzLPEb3uUi/Jw+dSZYSJ8Pev2/x2cHzZJmZuWAUhhAyiUQLuSBKhmBgjX0aYGehg3HMQ9DXopGmnui3DZp/sUAggceAm/z5upo29852+6hVrhNJysWGmnWnzz+MKNzEJIfUYtQ78iJLNwLMOvOUKLtvyEmzbeGx8vblvuRvE+bJNYCdaTvwDIWy3T9/npl6vFW+ennrcNPbOd7B3voMT100mPyAsZYoXnH48XrK+eAMT4GFWhJD6NErAMxl4N5uBiwiu/81/m7l+ph2+vYVOr1Rgp9seFpZ7AMK4Je3AZ6JsfWHZB9YmNeCnbpjG/U+9gD0HlnHiusnSTcxf/7mfGvzeHLbSE0Lq0agIJe3Al4wDbxW/hemJUHznO34qo+6/fqbtYqHrIwgUgWaPnJ2OfgjMd0KBNxHKT20Ijz437fT5BqC6MEIhhNSlUQLuOg56UUlf4sCL38KaiUh8l3uljTwzEx5UQ3edn1yfPEco3LEDPy48OddUohSdB14Vx+FxsoSQejRKwM2GYqBhGWHbc+JqERtTLRciwEJawC0COz2RuGw/N7k+cfGRA48E/GXHTgFImnnKfkBUfW904ISQOjRKwI2w+oFiueeXum8gzMVn2h4OLfulAr7GiPSy3zc30zjwhciBL0URyrqpFo6dbsURysgOnBEKIaQmjRXwpW4y0LiM6baLhU6vtJEnzrmXLQ687cb3AYkDn2q5OGHtJOZMhDJqBs4IhRBSk0YJeHy+dxBUcuBAmG+Hm5j287qBdLVK5MBT18zkNzGNgLddzK6dSDLwklb9KvAwK0JIXRol4NkIJago4G7srAG7A5+ZSFy2r9lrZlIboUBShTLZcnHC2ok+B24rI6wCIxRCSF1GFnARcaOhxl8ex4LKSBy4YrnrxzXgZUy3Pcwv95KJOQVVKIDZxAwyLr3tOWi5gvlIuM0ZLFMtF7PrQgFX1b5ZmnXhaYSEkLqMw4G/B8AjY3iegRhhDSIHPllSA25YM+FFwlzcyJN22WEjj/Tdv5By4K4jaLmCE9ZOouMHeGGhW9qqX+m9CTsxCSH1GEnAReQUAK8F8OnxLKecrAMPKjpwFwupKhSrA28nVSiBat81ppIFCDPwsDxR4uNh9xxcTs5CGdqBg8fJEkJqMaoD/3MA7wdQ6B1F5BoR2SkiO+fm5kZ6MdNF6QeKA0vduEKkjJl2zoGXVKGYlvu8SzeVLEAo4Kb6ZTYS8LmDyyPXgTNCIYTUZWgBF5HXAdijqveWXaeq21V1m6pum52dHfblACTiu9j18YO5QzjtxLUDHzMz4UX13cUZddtz0HaduF68z4FPeDgURShLHR9T7fBjO2a6BQA4sNTtG8VWF87EJITUZRQH/ioAbxCRJwF8AcCrReR/jWVVBRhxfOSZA+j6iq0nrxv4mJkJF/Opw6yKBHZ6IqoXD2wZuIuFTjZCAYB1k6GA71/sjryJ6dGBE0JqMrSAq+oHVfUUVd0I4M0A/l5Vf2NsK7NghPWBH70AANhy0vqBjzHnnBgHXbTJGObcoYDnRXgmqmQBsgK+fipy4IvdkRt5HNaBE0Jq0qg6cLNB+ODu/Vgz4cUnApZhNigPLHYzz9F33USy2dkn4FElCxBWoZgMfLrtwnVkLA7cZYRCCKnJWARcVe9S1deN47nKMO5519P7sfmkdZUqPkyJ4IGlAQ7clBuqTcDd5CyUrh/P3xQRrJ9qYf9iKgPnJiYh5AjRKAduhHW5F2BrhfgESCpMYgdeILAmJimKUA5ZIhQgjFEOLCVVLsOWETJCIYTUpVECnp6Us+WkwRuYQNImf9A4cEsjD2BKBX3rJuZ028NyL0DPDzJlhACwbtILI5SSw7KqwIEOhJC6NErA085468nVHLiJUPZHDrwo4lgzkWxi9pcRJpN9FjvZUxDXTbVwYHH0MkIeZkUIqUujBNy45wnPwU/PzlR6jDlN8MBSJOClZYS+tZHH/BBY6PTCDNwi4GVDk6vgiID6TQipQ6ME3Ijjz750HTy32tKNezYZeJGAm2adoKCRBwjPSlnsJo08gMnAu6WnHVbBdUAHTgipRaME3Ijj1or5N5A4cJOBFwp420OnF2C5F/Q38kRVJ/sXu/ADzTrwyVZ0e/F541VwHYdVKISQWjRLwKNoo0oDjyEpIxzswM11eRE29z13qAMAmQx8/VQLXV9xaNkfOv8O18XDrAgh9WiUgP/sS9bhfZeegdef9dLKjzHneQ924Em1Sr8DNwIeDm+Yaqcz8PC+5xc6Q9eAA1EVCh04IaQGjRJw1xG86xd+BmujM0iqYmrBgWwpYuaaieQaN3eNmUy/N3Lg+TpwANg33xnJgTuOQBVQijghpCKNEvBhWZMS5yKNNZPpgTDOsD1+r3HguQwcAF5YGE3AjXvnRiYhpCpHhYCbc8NdRyAFMUeZSzePjzPwtsWBL3QKfzhUweTuPQo4IaQiR4WAm03Isow669L7OzGBVAZuiVCen+9WLm20Ydx7wAiFEFKRo0TAEwdeRHq6T76Rx3UEUy3XKuDrIgE/tNwbuokHYIRCCKnPUSHgxkGXCfhMiQMP73exdz7axGxnz0IxjGDAUwObh38OQsjRxVEh4CYeqSrgtm7KmQkPLyyEteRpB+65TlyCWFThUgXzmiwlJIRU5agQ8PQmZuE1KVG2dVOmNznTjTxAkoOPoN/xazJCIYRUZZShxi8TkTtF5GEReUhE3jPOhY2TKg7ccSQWepsDT5cZpiMUIMnBR23kAbiJSQipzigOvAfgD1R1M4DzALxLRDaPZ1njJc7ABwhsWVaeceBe9mOLBXzEVnqADpwQUp1Rhho/o6r3RV8fBPAIgJPHtbBxUqUKBUhctu064+JbrvSVC5pmnpE6MVmFQgipyVgycBHZCODlAO6x3HeNiOwUkZ1zc3PjeLnamA3Komk8BuOybRGKiVfy+TeQysBHiVCYgRNCajKygIvIGgB/DeD3VfVA/n5V3a6q21R12+zs7KgvNxTxJuYAgTVO3V5GGIr7lEXAzYFWo0UorEIhhNRjJAEXkRZC8f6cqt46niWNnyqbmEC5Uzfint/ABBIHPuwwByD5ocEjZQkhVRmlCkUA3ADgEVX9s/EtafxUaeQBkmNjbQ7cPIfNgSdlhHTghJAjxygO/FUAfhPAq0Xkgei/XxzTusZKdQdeVkYYPoctA483MZmBE0KOIN7gS+yo6j8AGOH8vSPHdMUqFOOy7Y08UYRS4sDHcZwsW+kJIVU5Kjoxqzpwc12ZA7dl4OOpA2eEQgipx1Eh4FWrUMqc+nRJFco4HDhb6QkhdTlKBLzeJqbtupmSOvCxlBGylZ4QUpOjQsDNed5VywhtTj2uA2/3f2Trx3AWisNWekJITY4KAQfCCpPBDrw4QpkpKSOcarnwHBmtjJCt9ISQmhxFAu5Vd+DW88CLq1BEBOunWiM18rCMkBBSl6NGwGfXTMRRR+E1aycAwHrdmkkPky0HG2ba1se+ZP1kXA8+DA6rUAghNRm6DrxpfPIt56A14DCrf/3SdfjK752PzS9d13ffhOfiy797AU45dsr62O1v3ZYZClEX497ZSk8IqcpRI+AvWT9Z6botJ60vvO9nTlhTeN/Jx9iFvSo8TpYQUpejJkJZ7ZgMnGWEhJCqUMBXCckm5govhBDSGCjgq4Q4QqEDJ4RUhAK+SnC5iUkIqQkFfJXARh5CSF0o4KsEttITQupCAV8l8DhZQkhdRp2JeZmIPCoij4vIB8a1qKMRttITQuoyykxMF8B/A3A5gM0ArhSRzeNa2NEGj5MlhNRllE7MVwB4XFX/BQBE5AsArgDw8DgWdrRhHPjH73gcf/XtH67waggh4+ajb/w3OHfjhrE+5ygCfjKAH6W+3w3g5/IXicg1AK4BgFNPPXWEl3txs36qhXdesAlPv7C40kshhBwGbCeZjsphPwtFVbcD2A4A27ZtYz5QgIjgQ69lAkUIqc4om5hPA3hZ6vtTotsIIYQcAUYR8O8AOE1ENolIG8CbAXxpPMsihBAyiKEjFFXtici7AfwdABfAjar60NhWRgghpJSRMnBV/SqAr45pLYQQQmrATkxCCGkoFHBCCGkoFHBCCGkoFHBCCGkookfw7A0RmQMwbJ/48QCeG+NyjjRc/8rC9a8sXP9o/JSqzuZvPKICPgoislNVt630OoaF619ZuP6Vhes/PDBCIYSQhkIBJ4SQhtIkAd++0gsYEa5/ZeH6Vxau/zDQmAycEEJIliY5cEIIISko4IQQ0lAaIeBNG54sIi8TkTtF5GEReUhE3hPdvkFEvi4ij0V/HrvSay1CRFwRuV9Evhx9v0lE7on+Dm6OjhBelYjIMSJyi4h8T0QeEZFXNuyzf2/072aXiNwkIpOr/fMXkRtFZI+I7ErdZv3MJeTj0Xt5UETOWbmVF679T6J/Pw+KyBdF5JjUfR+M1v6oiFy6IouOWPUC3tDhyT0Af6CqmwGcB+Bd0Zo/AOAOVT0NwB3R96uV9wB4JPX9HwP4mKr+DIDnAVy1Iquqxl8A+Jqq/iyAsxC+j0Z89iJyMoDfA7BNVbciPKr5zVj9n/9nAFyWu63oM78cwGnRf9cAuO4IrbGIz6B/7V8HsFVVzwTwfQAfBIDo/+M3A9gSPea/Rxq1Iqx6AUdqeLKqdgCY4cmrFlV9RlXvi74+iFBATka47s9Gl30WwC+tyAIHICKnAHgtgE9H3wuAVwO4JbpkNa99PYALAdwAAKraUdUX0JDPPsIDMCUiHoBpAM9glX/+qroDwL7czUWf+RUA/qeG3A3gGBF56RFZqAXb2lX1dlXtRd/ejXDiGBCu/QuquqyqTwB4HKFGrQhNEHDb8OSTV2gttRGRjQBeDuAeACeq6jPRXc8COHGl1jWAPwfwfgBB9P1xAF5I/YNezX8HmwDMAfjLKAL6tIjMoCGfvao+DeBPATyFULj3A7gXzfn80xR95k37f/odAG6Lvl5Va2+CgDcWEVkD4K8B/L6qHkjfp2H95qqr4RSR1wHYo6r3rvRahsQDcA6A61T15QDmkYtLVutnDwBRTnwFwh9EJwGYQf+v941jNX/mZYjIhxBGop9b6bXYaIKAN3J4soi0EIr351T11ujmn5hfFaM/96zU+kp4FYA3iMiTCOOqVyPMlI+JfqUHVvffwW4Au1X1nuj7WxAKehM+ewB4DYAnVHVOVbsAbkX4d9KUzz9N0WfeiP+nReTtAF4H4Nc1aZhZVWtvgoA3bnhylBnfAOARVf2z1F1fAvC26Ou3AfjbI722QajqB1X1FFXdiPCz/ntV/XUAdwL4leiyVbl2AFDVZwH8SETOiG66GMDDaMBnH/EUgPNEZDr6d2TW34jPP0fRZ/4lAG+NqlHOA7A/FbWsCkTkMoQx4htUdSF115cAvFlEJkRkE8KN2H9aiTUCAFR11f8H4BcR7gT/AMCHVno9FdZ7PsJfFx8E8ED03y8izJLvAPAYgG8A2LDSax3wPi4C8OXo63+F8B/q4wD+D4CJlV5fybrPBrAz+vz/BsCxTfrsAXwEwPcA7ALwVwAmVvvnD+AmhJl9F+FvQVcVfeYABGFl2Q8AfBdhxc1qW/vjCLNu8//v9anrPxSt/VEAl6/k2tlKTwghDaUJEQohhBALFHBCCGkoFHBCCGkoFHBCCGkoFHBCCGkoFHBCCGkoFHBCCGko/x+J8DOYEgzRQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n",
      "For None or ~~HHHHHHHHHHHHHHHHHHHH~~, predicted sequence YKEIAFALFQALFALSELYIAVRY\n",
      "Writing FASTA file:  ./output_model_B/fasta_in_99800_0.fasta\n",
      "Now run OmegaFold.... on device=cuda:0\n",
      "INFO:root:Loading weights from /home/mbuehler/.cache/omegafold_ckpt/model.pt\n",
      "INFO:root:Constructing OmegaFold\n",
      "INFO:root:Reading ./output_model_B/fasta_in_99800_0.fasta\n",
      "INFO:root:Predicting 1th chain in ./output_model_B/fasta_in_99800_0.fasta\n",
      "INFO:root:24 residues in this chain.\n",
      "INFO:root:Finished prediction in 16.59 seconds.\n",
      "INFO:root:Saving prediction to ./output_model_B/temp_99800_0.pdb\n",
      "INFO:root:Saved\n",
      "INFO:root:Done!\n",
      "Done OmegaFold\n",
      "Resulting PDB file...:  ./output_model_B/temp_99800_0.PDB\n",
      "Properly named PDB file produced: ./output_model_B/~~HHHHHHHHHHHHHHHHHHHH~~_99800_0_0.pdb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x10 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"3dmolviewer_16788869358843505\"  style=\"position: relative; width: 640px; height: 480px\">\n        <p id=\"3dmolwarning_16788869358843505\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    //this is to ignore the existence of requirejs amd\n    var savedexports, savedmodule;\n    if (typeof exports !== 'undefined') savedexports = exports;\n    else exports = {}\n    if (typeof module !== 'undefined') savedmodule = module;\n    else module = {}\n\n    var tag = document.createElement('script');\n    tag.src = uri;\n    tag.async = true;\n    tag.onload = () => {\n        exports = savedexports;\n        module = savedmodule;\n        resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('script')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n});\n};\n\nif(typeof $3Dmolpromise === 'undefined') {\n$3Dmolpromise = null;\n  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n}\n\nvar viewer_16788869358843505 = null;\nvar warn = document.getElementById(\"3dmolwarning_16788869358843505\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n$3Dmolpromise.then(function() {\nviewer_16788869358843505 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788869358843505\"),{backgroundColor:\"white\"});\nviewer_16788869358843505.zoomTo();\n\tviewer_16788869358843505.addModel(\"ATOM      1  N   TYR A   0      -8.358 -10.391   6.874  1.00 80.28           N  \\nATOM      2  CA  TYR A   0      -7.021  -9.912   7.203  1.00 80.28           C  \\nATOM      3  C   TYR A   0      -6.139  -9.858   5.961  1.00 80.28           C  \\nATOM      4  O   TYR A   0      -5.269  -8.993   5.846  1.00 80.28           O  \\nATOM      5  CB  TYR A   0      -6.374 -10.809   8.263  1.00 80.28           C  \\nATOM      6  CG  TYR A   0      -5.065 -10.276   8.792  1.00 80.28           C  \\nATOM      7  CD1 TYR A   0      -3.851 -10.693   8.252  1.00 80.28           C  \\nATOM      8  CD2 TYR A   0      -5.039  -9.355   9.834  1.00 80.28           C  \\nATOM      9  CE1 TYR A   0      -2.642 -10.206   8.738  1.00 80.28           C  \\nATOM     10  CE2 TYR A   0      -3.836  -8.861  10.327  1.00 80.28           C  \\nATOM     11  CZ  TYR A   0      -2.645  -9.292   9.773  1.00 80.28           C  \\nATOM     12  OH  TYR A   0      -1.451  -8.806  10.258  1.00 80.28           O  \\nATOM     13  N   LYS A   1      -6.530 -10.709   4.950  1.00 93.56           N  \\nATOM     14  CA  LYS A   1      -5.757 -10.746   3.712  1.00 93.56           C  \\nATOM     15  C   LYS A   1      -6.035  -9.516   2.853  1.00 93.56           C  \\nATOM     16  O   LYS A   1      -5.120  -8.957   2.246  1.00 93.56           O  \\nATOM     17  CB  LYS A   1      -6.067 -12.018   2.922  1.00 93.56           C  \\nATOM     18  CG  LYS A   1      -5.509 -13.288   3.549  1.00 93.56           C  \\nATOM     19  CD  LYS A   1      -5.809 -14.512   2.693  1.00 93.56           C  \\nATOM     20  CE  LYS A   1      -5.318 -15.792   3.356  1.00 93.56           C  \\nATOM     21  NZ  LYS A   1      -5.597 -16.994   2.514  1.00 93.56           N  \\nATOM     22  N   GLU A   2      -7.282  -9.089   3.018  1.00 95.78           N  \\nATOM     23  CA  GLU A   2      -7.665  -7.961   2.173  1.00 95.78           C  \\nATOM     24  C   GLU A   2      -7.024  -6.664   2.660  1.00 95.78           C  \\nATOM     25  O   GLU A   2      -6.540  -5.865   1.856  1.00 95.78           O  \\nATOM     26  CB  GLU A   2      -9.188  -7.812   2.132  1.00 95.78           C  \\nATOM     27  CG  GLU A   2      -9.900  -8.971   1.450  1.00 95.78           C  \\nATOM     28  CD  GLU A   2      -9.507  -9.144  -0.008  1.00 95.78           C  \\nATOM     29  OE1 GLU A   2      -9.506 -10.293  -0.505  1.00 95.78           O  \\nATOM     30  OE2 GLU A   2      -9.196  -8.121  -0.659  1.00 95.78           O  \\nATOM     31  N   ILE A   3      -6.923  -6.604   3.981  1.00 96.87           N  \\nATOM     32  CA  ILE A   3      -6.362  -5.386   4.555  1.00 96.87           C  \\nATOM     33  C   ILE A   3      -4.856  -5.344   4.303  1.00 96.87           C  \\nATOM     34  O   ILE A   3      -4.306  -4.293   3.965  1.00 96.87           O  \\nATOM     35  CB  ILE A   3      -6.655  -5.288   6.069  1.00 96.87           C  \\nATOM     36  CG1 ILE A   3      -8.160  -5.126   6.312  1.00 96.87           C  \\nATOM     37  CG2 ILE A   3      -5.871  -4.132   6.697  1.00 96.87           C  \\nATOM     38  CD1 ILE A   3      -8.581  -5.352   7.758  1.00 96.87           C  \\nATOM     39  N   ALA A   4      -4.273  -6.525   4.389  1.00 97.31           N  \\nATOM     40  CA  ALA A   4      -2.834  -6.595   4.145  1.00 97.31           C  \\nATOM     41  C   ALA A   4      -2.502  -6.211   2.706  1.00 97.31           C  \\nATOM     42  O   ALA A   4      -1.551  -5.466   2.459  1.00 97.31           O  \\nATOM     43  CB  ALA A   4      -2.309  -7.995   4.455  1.00 97.31           C  \\nATOM     44  N   PHE A   5      -3.389  -6.726   1.808  1.00 97.37           N  \\nATOM     45  CA  PHE A   5      -3.154  -6.417   0.403  1.00 97.37           C  \\nATOM     46  C   PHE A   5      -3.306  -4.922   0.144  1.00 97.37           C  \\nATOM     47  O   PHE A   5      -2.490  -4.323  -0.559  1.00 97.37           O  \\nATOM     48  CB  PHE A   5      -4.117  -7.204  -0.491  1.00 97.37           C  \\nATOM     49  CG  PHE A   5      -3.904  -6.975  -1.963  1.00 97.37           C  \\nATOM     50  CD1 PHE A   5      -4.782  -6.181  -2.691  1.00 97.37           C  \\nATOM     51  CD2 PHE A   5      -2.825  -7.555  -2.619  1.00 97.37           C  \\nATOM     52  CE1 PHE A   5      -4.587  -5.967  -4.054  1.00 97.37           C  \\nATOM     53  CE2 PHE A   5      -2.624  -7.345  -3.981  1.00 97.37           C  \\nATOM     54  CZ  PHE A   5      -3.506  -6.552  -4.696  1.00 97.37           C  \\nATOM     55  N   ALA A   6      -4.268  -4.274   0.764  1.00 97.61           N  \\nATOM     56  CA  ALA A   6      -4.506  -2.846   0.574  1.00 97.61           C  \\nATOM     57  C   ALA A   6      -3.346  -2.018   1.120  1.00 97.61           C  \\nATOM     58  O   ALA A   6      -2.917  -1.048   0.491  1.00 97.61           O  \\nATOM     59  CB  ALA A   6      -5.814  -2.431   1.244  1.00 97.61           C  \\nATOM     60  N   LEU A   7      -2.754  -2.461   2.236  1.00 97.23           N  \\nATOM     61  CA  LEU A   7      -1.649  -1.725   2.840  1.00 97.23           C  \\nATOM     62  C   LEU A   7      -0.396  -1.820   1.975  1.00 97.23           C  \\nATOM     63  O   LEU A   7       0.303  -0.824   1.777  1.00 97.23           O  \\nATOM     64  CB  LEU A   7      -1.355  -2.258   4.245  1.00 97.23           C  \\nATOM     65  CG  LEU A   7      -2.296  -1.793   5.357  1.00 97.23           C  \\nATOM     66  CD1 LEU A   7      -2.075  -2.620   6.619  1.00 97.23           C  \\nATOM     67  CD2 LEU A   7      -2.096  -0.309   5.642  1.00 97.23           C  \\nATOM     68  N   PHE A   8      -0.191  -3.027   1.393  1.00 97.42           N  \\nATOM     69  CA  PHE A   8       0.966  -3.215   0.526  1.00 97.42           C  \\nATOM     70  C   PHE A   8       0.837  -2.372  -0.738  1.00 97.42           C  \\nATOM     71  O   PHE A   8       1.807  -1.752  -1.178  1.00 97.42           O  \\nATOM     72  CB  PHE A   8       1.129  -4.693   0.157  1.00 97.42           C  \\nATOM     73  CG  PHE A   8       2.066  -5.444   1.064  1.00 97.42           C  \\nATOM     74  CD1 PHE A   8       3.442  -5.295   0.942  1.00 97.42           C  \\nATOM     75  CD2 PHE A   8       1.570  -6.300   2.038  1.00 97.42           C  \\nATOM     76  CE1 PHE A   8       4.311  -5.989   1.780  1.00 97.42           C  \\nATOM     77  CE2 PHE A   8       2.433  -6.997   2.879  1.00 97.42           C  \\nATOM     78  CZ  PHE A   8       3.803  -6.841   2.748  1.00 97.42           C  \\nATOM     79  N   GLN A   9      -0.384  -2.366  -1.282  1.00 97.23           N  \\nATOM     80  CA  GLN A   9      -0.609  -1.573  -2.486  1.00 97.23           C  \\nATOM     81  C   GLN A   9      -0.407  -0.086  -2.211  1.00 97.23           C  \\nATOM     82  O   GLN A   9       0.186   0.626  -3.024  1.00 97.23           O  \\nATOM     83  CB  GLN A   9      -2.015  -1.819  -3.036  1.00 97.23           C  \\nATOM     84  CG  GLN A   9      -2.253  -1.209  -4.410  1.00 97.23           C  \\nATOM     85  CD  GLN A   9      -3.590  -1.608  -5.006  1.00 97.23           C  \\nATOM     86  OE1 GLN A   9      -3.812  -2.777  -5.340  1.00 97.23           O  \\nATOM     87  NE2 GLN A   9      -4.491  -0.641  -5.144  1.00 97.23           N  \\nATOM     88  N   ALA A  10      -0.822   0.395  -1.035  1.00 97.35           N  \\nATOM     89  CA  ALA A  10      -0.667   1.802  -0.673  1.00 97.35           C  \\nATOM     90  C   ALA A  10       0.803   2.157  -0.471  1.00 97.35           C  \\nATOM     91  O   ALA A  10       1.262   3.208  -0.924  1.00 97.35           O  \\nATOM     92  CB  ALA A  10      -1.466   2.117   0.589  1.00 97.35           C  \\nATOM     93  N   LEU A  11       1.587   1.260   0.148  1.00 97.26           N  \\nATOM     94  CA  LEU A  11       3.010   1.492   0.374  1.00 97.26           C  \\nATOM     95  C   LEU A  11       3.765   1.567  -0.949  1.00 97.26           C  \\nATOM     96  O   LEU A  11       4.611   2.445  -1.136  1.00 97.26           O  \\nATOM     97  CB  LEU A  11       3.600   0.384   1.250  1.00 97.26           C  \\nATOM     98  CG  LEU A  11       5.052   0.573   1.694  1.00 97.26           C  \\nATOM     99  CD1 LEU A  11       5.183   1.819   2.563  1.00 97.26           C  \\nATOM    100  CD2 LEU A  11       5.547  -0.661   2.441  1.00 97.26           C  \\nATOM    101  N   PHE A  12       3.409   0.687  -1.865  1.00 97.22           N  \\nATOM    102  CA  PHE A  12       4.052   0.678  -3.174  1.00 97.22           C  \\nATOM    103  C   PHE A  12       3.742   1.960  -3.938  1.00 97.22           C  \\nATOM    104  O   PHE A  12       4.628   2.543  -4.566  1.00 97.22           O  \\nATOM    105  CB  PHE A  12       3.601  -0.539  -3.987  1.00 97.22           C  \\nATOM    106  CG  PHE A  12       4.425  -0.782  -5.223  1.00 97.22           C  \\nATOM    107  CD1 PHE A  12       3.930  -0.457  -6.479  1.00 97.22           C  \\nATOM    108  CD2 PHE A  12       5.694  -1.337  -5.127  1.00 97.22           C  \\nATOM    109  CE1 PHE A  12       4.690  -0.680  -7.625  1.00 97.22           C  \\nATOM    110  CE2 PHE A  12       6.459  -1.564  -6.268  1.00 97.22           C  \\nATOM    111  CZ  PHE A  12       5.955  -1.236  -7.515  1.00 97.22           C  \\nATOM    112  N   ALA A  13       2.527   2.447  -3.852  1.00 97.38           N  \\nATOM    113  CA  ALA A  13       2.129   3.664  -4.554  1.00 97.38           C  \\nATOM    114  C   ALA A  13       2.850   4.884  -3.989  1.00 97.38           C  \\nATOM    115  O   ALA A  13       3.327   5.736  -4.744  1.00 97.38           O  \\nATOM    116  CB  ALA A  13       0.617   3.857  -4.468  1.00 97.38           C  \\nATOM    117  N   LEU A  14       3.079   4.898  -2.669  1.00 96.89           N  \\nATOM    118  CA  LEU A  14       3.759   6.024  -2.038  1.00 96.89           C  \\nATOM    119  C   LEU A  14       5.241   6.036  -2.398  1.00 96.89           C  \\nATOM    120  O   LEU A  14       5.817   7.099  -2.640  1.00 96.89           O  \\nATOM    121  CB  LEU A  14       3.592   5.968  -0.518  1.00 96.89           C  \\nATOM    122  CG  LEU A  14       2.225   6.382   0.030  1.00 96.89           C  \\nATOM    123  CD1 LEU A  14       2.148   6.105   1.527  1.00 96.89           C  \\nATOM    124  CD2 LEU A  14       1.956   7.854  -0.261  1.00 96.89           C  \\nATOM    125  N   SER A  15       5.828   4.849  -2.515  1.00 95.70           N  \\nATOM    126  CA  SER A  15       7.238   4.769  -2.882  1.00 95.70           C  \\nATOM    127  C   SER A  15       7.464   5.244  -4.314  1.00 95.70           C  \\nATOM    128  O   SER A  15       8.420   5.972  -4.588  1.00 95.70           O  \\nATOM    129  CB  SER A  15       7.754   3.338  -2.724  1.00 95.70           C  \\nATOM    130  OG  SER A  15       7.649   2.912  -1.376  1.00 95.70           O  \\nATOM    131  N   GLU A  16       6.489   4.912  -5.170  1.00 95.84           N  \\nATOM    132  CA  GLU A  16       6.613   5.341  -6.560  1.00 95.84           C  \\nATOM    133  C   GLU A  16       6.468   6.855  -6.685  1.00 95.84           C  \\nATOM    134  O   GLU A  16       7.195   7.492  -7.449  1.00 95.84           O  \\nATOM    135  CB  GLU A  16       5.572   4.638  -7.435  1.00 95.84           C  \\nATOM    136  CG  GLU A  16       5.949   3.214  -7.816  1.00 95.84           C  \\nATOM    137  CD  GLU A  16       5.176   2.688  -9.014  1.00 95.84           C  \\nATOM    138  OE1 GLU A  16       5.502   1.587  -9.512  1.00 95.84           O  \\nATOM    139  OE2 GLU A  16       4.237   3.385  -9.461  1.00 95.84           O  \\nATOM    140  N   LEU A  17       5.486   7.376  -5.954  1.00 95.02           N  \\nATOM    141  CA  LEU A  17       5.283   8.821  -5.989  1.00 95.02           C  \\nATOM    142  C   LEU A  17       6.511   9.555  -5.462  1.00 95.02           C  \\nATOM    143  O   LEU A  17       6.899  10.593  -6.004  1.00 95.02           O  \\nATOM    144  CB  LEU A  17       4.051   9.209  -5.168  1.00 95.02           C  \\nATOM    145  CG  LEU A  17       3.670  10.690  -5.175  1.00 95.02           C  \\nATOM    146  CD1 LEU A  17       3.217  11.114  -6.568  1.00 95.02           C  \\nATOM    147  CD2 LEU A  17       2.581  10.968  -4.145  1.00 95.02           C  \\nATOM    148  N   TYR A  18       7.109   9.018  -4.410  1.00 96.02           N  \\nATOM    149  CA  TYR A  18       8.309   9.617  -3.837  1.00 96.02           C  \\nATOM    150  C   TYR A  18       9.447   9.634  -4.849  1.00 96.02           C  \\nATOM    151  O   TYR A  18      10.131  10.648  -5.008  1.00 96.02           O  \\nATOM    152  CB  TYR A  18       8.740   8.858  -2.578  1.00 96.02           C  \\nATOM    153  CG  TYR A  18      10.026   9.367  -1.974  1.00 96.02           C  \\nATOM    154  CD1 TYR A  18      11.220   8.666  -2.135  1.00 96.02           C  \\nATOM    155  CD2 TYR A  18      10.051  10.548  -1.240  1.00 96.02           C  \\nATOM    156  CE1 TYR A  18      12.407   9.130  -1.578  1.00 96.02           C  \\nATOM    157  CE2 TYR A  18      11.233  11.021  -0.679  1.00 96.02           C  \\nATOM    158  CZ  TYR A  18      12.404  10.307  -0.853  1.00 96.02           C  \\nATOM    159  OH  TYR A  18      13.576  10.770  -0.300  1.00 96.02           O  \\nATOM    160  N   ILE A  19       9.575   8.573  -5.604  1.00 95.36           N  \\nATOM    161  CA  ILE A  19      10.655   8.468  -6.578  1.00 95.36           C  \\nATOM    162  C   ILE A  19      10.384   9.407  -7.752  1.00 95.36           C  \\nATOM    163  O   ILE A  19      11.304  10.043  -8.271  1.00 95.36           O  \\nATOM    164  CB  ILE A  19      10.824   7.016  -7.081  1.00 95.36           C  \\nATOM    165  CG1 ILE A  19      11.302   6.109  -5.941  1.00 95.36           C  \\nATOM    166  CG2 ILE A  19      11.792   6.964  -8.266  1.00 95.36           C  \\nATOM    167  CD1 ILE A  19      11.209   4.622  -6.254  1.00 95.36           C  \\nATOM    168  N   ALA A  20       9.126   9.566  -8.084  1.00 95.81           N  \\nATOM    169  CA  ALA A  20       8.744  10.371  -9.241  1.00 95.81           C  \\nATOM    170  C   ALA A  20       8.928  11.859  -8.959  1.00 95.81           C  \\nATOM    171  O   ALA A  20       9.326  12.620  -9.844  1.00 95.81           O  \\nATOM    172  CB  ALA A  20       7.298  10.082  -9.636  1.00 95.81           C  \\nATOM    173  N   VAL A  21       8.621  12.188  -7.687  1.00 94.06           N  \\nATOM    174  CA  VAL A  21       8.692  13.598  -7.317  1.00 94.06           C  \\nATOM    175  C   VAL A  21      10.153  14.030  -7.206  1.00 94.06           C  \\nATOM    176  O   VAL A  21      10.498  15.165  -7.542  1.00 94.06           O  \\nATOM    177  CB  VAL A  21       7.953  13.874  -5.988  1.00 94.06           C  \\nATOM    178  CG1 VAL A  21       8.275  15.275  -5.472  1.00 94.06           C  \\nATOM    179  CG2 VAL A  21       6.446  13.702  -6.171  1.00 94.06           C  \\nATOM    180  N   ARG A  22      10.949  13.058  -6.837  1.00 85.75           N  \\nATOM    181  CA  ARG A  22      12.340  13.475  -6.691  1.00 85.75           C  \\nATOM    182  C   ARG A  22      13.064  13.445  -8.032  1.00 85.75           C  \\nATOM    183  O   ARG A  22      14.016  14.199  -8.247  1.00 85.75           O  \\nATOM    184  CB  ARG A  22      13.066  12.582  -5.683  1.00 85.75           C  \\nATOM    185  CG  ARG A  22      12.728  12.887  -4.233  1.00 85.75           C  \\nATOM    186  CD  ARG A  22      13.840  13.668  -3.546  1.00 85.75           C  \\nATOM    187  NE  ARG A  22      13.572  13.848  -2.122  1.00 85.75           N  \\nATOM    188  CZ  ARG A  22      13.565  15.021  -1.494  1.00 85.75           C  \\nATOM    189  NH1 ARG A  22      13.812  16.146  -2.156  1.00 85.75           N  \\nATOM    190  NH2 ARG A  22      13.308  15.070  -0.195  1.00 85.75           N  \\nATOM    191  N   TYR A  23      12.585  12.507  -8.806  1.00 67.51           N  \\nATOM    192  CA  TYR A  23      13.269  12.441 -10.092  1.00 67.51           C  \\nATOM    193  C   TYR A  23      12.505  13.220 -11.157  1.00 67.51           C  \\nATOM    194  O   TYR A  23      13.108  13.799 -12.063  1.00 67.51           O  \\nATOM    195  CB  TYR A  23      13.443  10.985 -10.535  1.00 67.51           C  \\nATOM    196  CG  TYR A  23      14.479  10.228  -9.740  1.00 67.51           C  \\nATOM    197  CD1 TYR A  23      15.835  10.341 -10.041  1.00 67.51           C  \\nATOM    198  CD2 TYR A  23      14.105   9.399  -8.688  1.00 67.51           C  \\nATOM    199  CE1 TYR A  23      16.794   9.644  -9.312  1.00 67.51           C  \\nATOM    200  CE2 TYR A  23      15.055   8.698  -7.952  1.00 67.51           C  \\nATOM    201  CZ  TYR A  23      16.395   8.827  -8.271  1.00 67.51           C  \\nATOM    202  OH  TYR A  23      17.340   8.135  -7.547  1.00 67.51           O  \\nTER     203      TYR A  23                                                       \\nEND   \\n\",\"pdb\");\n\tviewer_16788869358843505.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n\tviewer_16788869358843505.zoomTo();\nviewer_16788869358843505.render();\n});\n</script>",
      "text/html": [
       "<div id=\"3dmolviewer_16788869358843505\"  style=\"position: relative; width: 640px; height: 480px\">\n",
       "        <p id=\"3dmolwarning_16788869358843505\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the 3dmol extension: <br>\n",
       "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    //this is to ignore the existence of requirejs amd\n",
       "    var savedexports, savedmodule;\n",
       "    if (typeof exports !== 'undefined') savedexports = exports;\n",
       "    else exports = {}\n",
       "    if (typeof module !== 'undefined') savedmodule = module;\n",
       "    else module = {}\n",
       "\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    tag.async = true;\n",
       "    tag.onload = () => {\n",
       "        exports = savedexports;\n",
       "        module = savedmodule;\n",
       "        resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "});\n",
       "};\n",
       "\n",
       "if(typeof $3Dmolpromise === 'undefined') {\n",
       "$3Dmolpromise = null;\n",
       "  $3Dmolpromise = loadScriptAsync('https://3dmol.org/build/3Dmol.js');\n",
       "}\n",
       "\n",
       "var viewer_16788869358843505 = null;\n",
       "var warn = document.getElementById(\"3dmolwarning_16788869358843505\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "$3Dmolpromise.then(function() {\n",
       "viewer_16788869358843505 = $3Dmol.createViewer(document.getElementById(\"3dmolviewer_16788869358843505\"),{backgroundColor:\"white\"});\n",
       "viewer_16788869358843505.zoomTo();\n",
       "\tviewer_16788869358843505.addModel(\"ATOM      1  N   TYR A   0      -8.358 -10.391   6.874  1.00 80.28           N  \\nATOM      2  CA  TYR A   0      -7.021  -9.912   7.203  1.00 80.28           C  \\nATOM      3  C   TYR A   0      -6.139  -9.858   5.961  1.00 80.28           C  \\nATOM      4  O   TYR A   0      -5.269  -8.993   5.846  1.00 80.28           O  \\nATOM      5  CB  TYR A   0      -6.374 -10.809   8.263  1.00 80.28           C  \\nATOM      6  CG  TYR A   0      -5.065 -10.276   8.792  1.00 80.28           C  \\nATOM      7  CD1 TYR A   0      -3.851 -10.693   8.252  1.00 80.28           C  \\nATOM      8  CD2 TYR A   0      -5.039  -9.355   9.834  1.00 80.28           C  \\nATOM      9  CE1 TYR A   0      -2.642 -10.206   8.738  1.00 80.28           C  \\nATOM     10  CE2 TYR A   0      -3.836  -8.861  10.327  1.00 80.28           C  \\nATOM     11  CZ  TYR A   0      -2.645  -9.292   9.773  1.00 80.28           C  \\nATOM     12  OH  TYR A   0      -1.451  -8.806  10.258  1.00 80.28           O  \\nATOM     13  N   LYS A   1      -6.530 -10.709   4.950  1.00 93.56           N  \\nATOM     14  CA  LYS A   1      -5.757 -10.746   3.712  1.00 93.56           C  \\nATOM     15  C   LYS A   1      -6.035  -9.516   2.853  1.00 93.56           C  \\nATOM     16  O   LYS A   1      -5.120  -8.957   2.246  1.00 93.56           O  \\nATOM     17  CB  LYS A   1      -6.067 -12.018   2.922  1.00 93.56           C  \\nATOM     18  CG  LYS A   1      -5.509 -13.288   3.549  1.00 93.56           C  \\nATOM     19  CD  LYS A   1      -5.809 -14.512   2.693  1.00 93.56           C  \\nATOM     20  CE  LYS A   1      -5.318 -15.792   3.356  1.00 93.56           C  \\nATOM     21  NZ  LYS A   1      -5.597 -16.994   2.514  1.00 93.56           N  \\nATOM     22  N   GLU A   2      -7.282  -9.089   3.018  1.00 95.78           N  \\nATOM     23  CA  GLU A   2      -7.665  -7.961   2.173  1.00 95.78           C  \\nATOM     24  C   GLU A   2      -7.024  -6.664   2.660  1.00 95.78           C  \\nATOM     25  O   GLU A   2      -6.540  -5.865   1.856  1.00 95.78           O  \\nATOM     26  CB  GLU A   2      -9.188  -7.812   2.132  1.00 95.78           C  \\nATOM     27  CG  GLU A   2      -9.900  -8.971   1.450  1.00 95.78           C  \\nATOM     28  CD  GLU A   2      -9.507  -9.144  -0.008  1.00 95.78           C  \\nATOM     29  OE1 GLU A   2      -9.506 -10.293  -0.505  1.00 95.78           O  \\nATOM     30  OE2 GLU A   2      -9.196  -8.121  -0.659  1.00 95.78           O  \\nATOM     31  N   ILE A   3      -6.923  -6.604   3.981  1.00 96.87           N  \\nATOM     32  CA  ILE A   3      -6.362  -5.386   4.555  1.00 96.87           C  \\nATOM     33  C   ILE A   3      -4.856  -5.344   4.303  1.00 96.87           C  \\nATOM     34  O   ILE A   3      -4.306  -4.293   3.965  1.00 96.87           O  \\nATOM     35  CB  ILE A   3      -6.655  -5.288   6.069  1.00 96.87           C  \\nATOM     36  CG1 ILE A   3      -8.160  -5.126   6.312  1.00 96.87           C  \\nATOM     37  CG2 ILE A   3      -5.871  -4.132   6.697  1.00 96.87           C  \\nATOM     38  CD1 ILE A   3      -8.581  -5.352   7.758  1.00 96.87           C  \\nATOM     39  N   ALA A   4      -4.273  -6.525   4.389  1.00 97.31           N  \\nATOM     40  CA  ALA A   4      -2.834  -6.595   4.145  1.00 97.31           C  \\nATOM     41  C   ALA A   4      -2.502  -6.211   2.706  1.00 97.31           C  \\nATOM     42  O   ALA A   4      -1.551  -5.466   2.459  1.00 97.31           O  \\nATOM     43  CB  ALA A   4      -2.309  -7.995   4.455  1.00 97.31           C  \\nATOM     44  N   PHE A   5      -3.389  -6.726   1.808  1.00 97.37           N  \\nATOM     45  CA  PHE A   5      -3.154  -6.417   0.403  1.00 97.37           C  \\nATOM     46  C   PHE A   5      -3.306  -4.922   0.144  1.00 97.37           C  \\nATOM     47  O   PHE A   5      -2.490  -4.323  -0.559  1.00 97.37           O  \\nATOM     48  CB  PHE A   5      -4.117  -7.204  -0.491  1.00 97.37           C  \\nATOM     49  CG  PHE A   5      -3.904  -6.975  -1.963  1.00 97.37           C  \\nATOM     50  CD1 PHE A   5      -4.782  -6.181  -2.691  1.00 97.37           C  \\nATOM     51  CD2 PHE A   5      -2.825  -7.555  -2.619  1.00 97.37           C  \\nATOM     52  CE1 PHE A   5      -4.587  -5.967  -4.054  1.00 97.37           C  \\nATOM     53  CE2 PHE A   5      -2.624  -7.345  -3.981  1.00 97.37           C  \\nATOM     54  CZ  PHE A   5      -3.506  -6.552  -4.696  1.00 97.37           C  \\nATOM     55  N   ALA A   6      -4.268  -4.274   0.764  1.00 97.61           N  \\nATOM     56  CA  ALA A   6      -4.506  -2.846   0.574  1.00 97.61           C  \\nATOM     57  C   ALA A   6      -3.346  -2.018   1.120  1.00 97.61           C  \\nATOM     58  O   ALA A   6      -2.917  -1.048   0.491  1.00 97.61           O  \\nATOM     59  CB  ALA A   6      -5.814  -2.431   1.244  1.00 97.61           C  \\nATOM     60  N   LEU A   7      -2.754  -2.461   2.236  1.00 97.23           N  \\nATOM     61  CA  LEU A   7      -1.649  -1.725   2.840  1.00 97.23           C  \\nATOM     62  C   LEU A   7      -0.396  -1.820   1.975  1.00 97.23           C  \\nATOM     63  O   LEU A   7       0.303  -0.824   1.777  1.00 97.23           O  \\nATOM     64  CB  LEU A   7      -1.355  -2.258   4.245  1.00 97.23           C  \\nATOM     65  CG  LEU A   7      -2.296  -1.793   5.357  1.00 97.23           C  \\nATOM     66  CD1 LEU A   7      -2.075  -2.620   6.619  1.00 97.23           C  \\nATOM     67  CD2 LEU A   7      -2.096  -0.309   5.642  1.00 97.23           C  \\nATOM     68  N   PHE A   8      -0.191  -3.027   1.393  1.00 97.42           N  \\nATOM     69  CA  PHE A   8       0.966  -3.215   0.526  1.00 97.42           C  \\nATOM     70  C   PHE A   8       0.837  -2.372  -0.738  1.00 97.42           C  \\nATOM     71  O   PHE A   8       1.807  -1.752  -1.178  1.00 97.42           O  \\nATOM     72  CB  PHE A   8       1.129  -4.693   0.157  1.00 97.42           C  \\nATOM     73  CG  PHE A   8       2.066  -5.444   1.064  1.00 97.42           C  \\nATOM     74  CD1 PHE A   8       3.442  -5.295   0.942  1.00 97.42           C  \\nATOM     75  CD2 PHE A   8       1.570  -6.300   2.038  1.00 97.42           C  \\nATOM     76  CE1 PHE A   8       4.311  -5.989   1.780  1.00 97.42           C  \\nATOM     77  CE2 PHE A   8       2.433  -6.997   2.879  1.00 97.42           C  \\nATOM     78  CZ  PHE A   8       3.803  -6.841   2.748  1.00 97.42           C  \\nATOM     79  N   GLN A   9      -0.384  -2.366  -1.282  1.00 97.23           N  \\nATOM     80  CA  GLN A   9      -0.609  -1.573  -2.486  1.00 97.23           C  \\nATOM     81  C   GLN A   9      -0.407  -0.086  -2.211  1.00 97.23           C  \\nATOM     82  O   GLN A   9       0.186   0.626  -3.024  1.00 97.23           O  \\nATOM     83  CB  GLN A   9      -2.015  -1.819  -3.036  1.00 97.23           C  \\nATOM     84  CG  GLN A   9      -2.253  -1.209  -4.410  1.00 97.23           C  \\nATOM     85  CD  GLN A   9      -3.590  -1.608  -5.006  1.00 97.23           C  \\nATOM     86  OE1 GLN A   9      -3.812  -2.777  -5.340  1.00 97.23           O  \\nATOM     87  NE2 GLN A   9      -4.491  -0.641  -5.144  1.00 97.23           N  \\nATOM     88  N   ALA A  10      -0.822   0.395  -1.035  1.00 97.35           N  \\nATOM     89  CA  ALA A  10      -0.667   1.802  -0.673  1.00 97.35           C  \\nATOM     90  C   ALA A  10       0.803   2.157  -0.471  1.00 97.35           C  \\nATOM     91  O   ALA A  10       1.262   3.208  -0.924  1.00 97.35           O  \\nATOM     92  CB  ALA A  10      -1.466   2.117   0.589  1.00 97.35           C  \\nATOM     93  N   LEU A  11       1.587   1.260   0.148  1.00 97.26           N  \\nATOM     94  CA  LEU A  11       3.010   1.492   0.374  1.00 97.26           C  \\nATOM     95  C   LEU A  11       3.765   1.567  -0.949  1.00 97.26           C  \\nATOM     96  O   LEU A  11       4.611   2.445  -1.136  1.00 97.26           O  \\nATOM     97  CB  LEU A  11       3.600   0.384   1.250  1.00 97.26           C  \\nATOM     98  CG  LEU A  11       5.052   0.573   1.694  1.00 97.26           C  \\nATOM     99  CD1 LEU A  11       5.183   1.819   2.563  1.00 97.26           C  \\nATOM    100  CD2 LEU A  11       5.547  -0.661   2.441  1.00 97.26           C  \\nATOM    101  N   PHE A  12       3.409   0.687  -1.865  1.00 97.22           N  \\nATOM    102  CA  PHE A  12       4.052   0.678  -3.174  1.00 97.22           C  \\nATOM    103  C   PHE A  12       3.742   1.960  -3.938  1.00 97.22           C  \\nATOM    104  O   PHE A  12       4.628   2.543  -4.566  1.00 97.22           O  \\nATOM    105  CB  PHE A  12       3.601  -0.539  -3.987  1.00 97.22           C  \\nATOM    106  CG  PHE A  12       4.425  -0.782  -5.223  1.00 97.22           C  \\nATOM    107  CD1 PHE A  12       3.930  -0.457  -6.479  1.00 97.22           C  \\nATOM    108  CD2 PHE A  12       5.694  -1.337  -5.127  1.00 97.22           C  \\nATOM    109  CE1 PHE A  12       4.690  -0.680  -7.625  1.00 97.22           C  \\nATOM    110  CE2 PHE A  12       6.459  -1.564  -6.268  1.00 97.22           C  \\nATOM    111  CZ  PHE A  12       5.955  -1.236  -7.515  1.00 97.22           C  \\nATOM    112  N   ALA A  13       2.527   2.447  -3.852  1.00 97.38           N  \\nATOM    113  CA  ALA A  13       2.129   3.664  -4.554  1.00 97.38           C  \\nATOM    114  C   ALA A  13       2.850   4.884  -3.989  1.00 97.38           C  \\nATOM    115  O   ALA A  13       3.327   5.736  -4.744  1.00 97.38           O  \\nATOM    116  CB  ALA A  13       0.617   3.857  -4.468  1.00 97.38           C  \\nATOM    117  N   LEU A  14       3.079   4.898  -2.669  1.00 96.89           N  \\nATOM    118  CA  LEU A  14       3.759   6.024  -2.038  1.00 96.89           C  \\nATOM    119  C   LEU A  14       5.241   6.036  -2.398  1.00 96.89           C  \\nATOM    120  O   LEU A  14       5.817   7.099  -2.640  1.00 96.89           O  \\nATOM    121  CB  LEU A  14       3.592   5.968  -0.518  1.00 96.89           C  \\nATOM    122  CG  LEU A  14       2.225   6.382   0.030  1.00 96.89           C  \\nATOM    123  CD1 LEU A  14       2.148   6.105   1.527  1.00 96.89           C  \\nATOM    124  CD2 LEU A  14       1.956   7.854  -0.261  1.00 96.89           C  \\nATOM    125  N   SER A  15       5.828   4.849  -2.515  1.00 95.70           N  \\nATOM    126  CA  SER A  15       7.238   4.769  -2.882  1.00 95.70           C  \\nATOM    127  C   SER A  15       7.464   5.244  -4.314  1.00 95.70           C  \\nATOM    128  O   SER A  15       8.420   5.972  -4.588  1.00 95.70           O  \\nATOM    129  CB  SER A  15       7.754   3.338  -2.724  1.00 95.70           C  \\nATOM    130  OG  SER A  15       7.649   2.912  -1.376  1.00 95.70           O  \\nATOM    131  N   GLU A  16       6.489   4.912  -5.170  1.00 95.84           N  \\nATOM    132  CA  GLU A  16       6.613   5.341  -6.560  1.00 95.84           C  \\nATOM    133  C   GLU A  16       6.468   6.855  -6.685  1.00 95.84           C  \\nATOM    134  O   GLU A  16       7.195   7.492  -7.449  1.00 95.84           O  \\nATOM    135  CB  GLU A  16       5.572   4.638  -7.435  1.00 95.84           C  \\nATOM    136  CG  GLU A  16       5.949   3.214  -7.816  1.00 95.84           C  \\nATOM    137  CD  GLU A  16       5.176   2.688  -9.014  1.00 95.84           C  \\nATOM    138  OE1 GLU A  16       5.502   1.587  -9.512  1.00 95.84           O  \\nATOM    139  OE2 GLU A  16       4.237   3.385  -9.461  1.00 95.84           O  \\nATOM    140  N   LEU A  17       5.486   7.376  -5.954  1.00 95.02           N  \\nATOM    141  CA  LEU A  17       5.283   8.821  -5.989  1.00 95.02           C  \\nATOM    142  C   LEU A  17       6.511   9.555  -5.462  1.00 95.02           C  \\nATOM    143  O   LEU A  17       6.899  10.593  -6.004  1.00 95.02           O  \\nATOM    144  CB  LEU A  17       4.051   9.209  -5.168  1.00 95.02           C  \\nATOM    145  CG  LEU A  17       3.670  10.690  -5.175  1.00 95.02           C  \\nATOM    146  CD1 LEU A  17       3.217  11.114  -6.568  1.00 95.02           C  \\nATOM    147  CD2 LEU A  17       2.581  10.968  -4.145  1.00 95.02           C  \\nATOM    148  N   TYR A  18       7.109   9.018  -4.410  1.00 96.02           N  \\nATOM    149  CA  TYR A  18       8.309   9.617  -3.837  1.00 96.02           C  \\nATOM    150  C   TYR A  18       9.447   9.634  -4.849  1.00 96.02           C  \\nATOM    151  O   TYR A  18      10.131  10.648  -5.008  1.00 96.02           O  \\nATOM    152  CB  TYR A  18       8.740   8.858  -2.578  1.00 96.02           C  \\nATOM    153  CG  TYR A  18      10.026   9.367  -1.974  1.00 96.02           C  \\nATOM    154  CD1 TYR A  18      11.220   8.666  -2.135  1.00 96.02           C  \\nATOM    155  CD2 TYR A  18      10.051  10.548  -1.240  1.00 96.02           C  \\nATOM    156  CE1 TYR A  18      12.407   9.130  -1.578  1.00 96.02           C  \\nATOM    157  CE2 TYR A  18      11.233  11.021  -0.679  1.00 96.02           C  \\nATOM    158  CZ  TYR A  18      12.404  10.307  -0.853  1.00 96.02           C  \\nATOM    159  OH  TYR A  18      13.576  10.770  -0.300  1.00 96.02           O  \\nATOM    160  N   ILE A  19       9.575   8.573  -5.604  1.00 95.36           N  \\nATOM    161  CA  ILE A  19      10.655   8.468  -6.578  1.00 95.36           C  \\nATOM    162  C   ILE A  19      10.384   9.407  -7.752  1.00 95.36           C  \\nATOM    163  O   ILE A  19      11.304  10.043  -8.271  1.00 95.36           O  \\nATOM    164  CB  ILE A  19      10.824   7.016  -7.081  1.00 95.36           C  \\nATOM    165  CG1 ILE A  19      11.302   6.109  -5.941  1.00 95.36           C  \\nATOM    166  CG2 ILE A  19      11.792   6.964  -8.266  1.00 95.36           C  \\nATOM    167  CD1 ILE A  19      11.209   4.622  -6.254  1.00 95.36           C  \\nATOM    168  N   ALA A  20       9.126   9.566  -8.084  1.00 95.81           N  \\nATOM    169  CA  ALA A  20       8.744  10.371  -9.241  1.00 95.81           C  \\nATOM    170  C   ALA A  20       8.928  11.859  -8.959  1.00 95.81           C  \\nATOM    171  O   ALA A  20       9.326  12.620  -9.844  1.00 95.81           O  \\nATOM    172  CB  ALA A  20       7.298  10.082  -9.636  1.00 95.81           C  \\nATOM    173  N   VAL A  21       8.621  12.188  -7.687  1.00 94.06           N  \\nATOM    174  CA  VAL A  21       8.692  13.598  -7.317  1.00 94.06           C  \\nATOM    175  C   VAL A  21      10.153  14.030  -7.206  1.00 94.06           C  \\nATOM    176  O   VAL A  21      10.498  15.165  -7.542  1.00 94.06           O  \\nATOM    177  CB  VAL A  21       7.953  13.874  -5.988  1.00 94.06           C  \\nATOM    178  CG1 VAL A  21       8.275  15.275  -5.472  1.00 94.06           C  \\nATOM    179  CG2 VAL A  21       6.446  13.702  -6.171  1.00 94.06           C  \\nATOM    180  N   ARG A  22      10.949  13.058  -6.837  1.00 85.75           N  \\nATOM    181  CA  ARG A  22      12.340  13.475  -6.691  1.00 85.75           C  \\nATOM    182  C   ARG A  22      13.064  13.445  -8.032  1.00 85.75           C  \\nATOM    183  O   ARG A  22      14.016  14.199  -8.247  1.00 85.75           O  \\nATOM    184  CB  ARG A  22      13.066  12.582  -5.683  1.00 85.75           C  \\nATOM    185  CG  ARG A  22      12.728  12.887  -4.233  1.00 85.75           C  \\nATOM    186  CD  ARG A  22      13.840  13.668  -3.546  1.00 85.75           C  \\nATOM    187  NE  ARG A  22      13.572  13.848  -2.122  1.00 85.75           N  \\nATOM    188  CZ  ARG A  22      13.565  15.021  -1.494  1.00 85.75           C  \\nATOM    189  NH1 ARG A  22      13.812  16.146  -2.156  1.00 85.75           N  \\nATOM    190  NH2 ARG A  22      13.308  15.070  -0.195  1.00 85.75           N  \\nATOM    191  N   TYR A  23      12.585  12.507  -8.806  1.00 67.51           N  \\nATOM    192  CA  TYR A  23      13.269  12.441 -10.092  1.00 67.51           C  \\nATOM    193  C   TYR A  23      12.505  13.220 -11.157  1.00 67.51           C  \\nATOM    194  O   TYR A  23      13.108  13.799 -12.063  1.00 67.51           O  \\nATOM    195  CB  TYR A  23      13.443  10.985 -10.535  1.00 67.51           C  \\nATOM    196  CG  TYR A  23      14.479  10.228  -9.740  1.00 67.51           C  \\nATOM    197  CD1 TYR A  23      15.835  10.341 -10.041  1.00 67.51           C  \\nATOM    198  CD2 TYR A  23      14.105   9.399  -8.688  1.00 67.51           C  \\nATOM    199  CE1 TYR A  23      16.794   9.644  -9.312  1.00 67.51           C  \\nATOM    200  CE2 TYR A  23      15.055   8.698  -7.952  1.00 67.51           C  \\nATOM    201  CZ  TYR A  23      16.395   8.827  -8.271  1.00 67.51           C  \\nATOM    202  OH  TYR A  23      17.340   8.135  -7.547  1.00 67.51           O  \\nTER     203      TYR A  23                                                       \\nEND   \\n\",\"pdb\");\n",
       "\tviewer_16788869358843505.setStyle({\"cartoon\": {\"colorscheme\": {\"prop\": \"b\", \"gradient\": \"roygb\", \"min\": 50, \"max\": 90}}});\n",
       "\tviewer_16788869358843505.zoomTo();\n",
       "viewer_16788869358843505.render();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: PDB file predicted:  ./output_model_B/~~HHHHHHHHHHHHHHHHHHHH~~_99800_0_0.pdb Error:  0.08333333333333333\n",
      "Cond: ~~HHHHHHHHHHHHHHHHHHHH~~\n",
      "Pred: ~HHHHHHHHHHHHHHHHHHHHHH~\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################\n",
      "####################################################\n",
      "####################################################\n",
      "FINAL RESULT at 0:  ./output_model_B/~~HHHHHHHHHHHHHHHHHHHH~~_99800_0_0.pdb Error:  0.08333333333333333\n",
      "Seq:  YKEIAFALFQALFALSELYIAVRY\n",
      "Cond: ~~HHHHHHHHHHHHHHHHHHHH~~\n",
      "Pred: ~HHHHHHHHHHHHHHHHHHHHHH~\n",
      "FINAL FILE NAME at 0:  ./output_model_B/~~HHHHHHHHHHHHHHHHHHHH~~_99800_0_0_FINAL.pdb\n",
      "####################################################\n",
      "####################################################\n",
      "####################################################\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./output_model_B/~~HHHHHHHHHHHHHHHHHHHH~~_99800_0_0.pdb',\n",
       " 0.08333333333333333,\n",
       " '~~HHHHHHHHHHHHHHHHHHHH~~',\n",
       " '~HHHHHHHHHHHHHHHHHHHHHH~')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterate_adaptive (model_B,  seq='~~HHHHHHHHHHHHHHHHHHHH~~',flag=99800, errorthreshold=0.1, \n",
    "                                             maxiter=10)\n",
    "                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
